{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7794e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LYTKYEKDDSIRKQRVKAVELFSLM\n",
      "GIGVINFAYYLAKHGKRYSDGSANN\n",
      "HMQIINEINTRFKTLVEKTWPGDEK\n",
      "ILEANLLPPPEPKESWRRIMDELSV\n",
      "TYFGELSRMTQFKDKSARYAENINA\n",
      "KEILGDEADQYVKVPDTLDVWFDSG\n",
      "AIQFAWELLTSEKWFALPKERLWVT\n",
      "AALASVKGWVSAKLQOOOOOOOOOO\n",
      "PIQETITFDDFAKVDLRVALIENAE\n",
      "ERGKVIADYEERKAKIKADAEEAAR\n",
      "RAALGVLRIIVEKNLNLDLQTLTEE\n",
      "IRQIIDEDLASGKHTTVHTRFPPEP\n",
      "KVISVQEMHAQIKOOOOOOOOOOOO\n",
      "OOOOOOOOOMKIKTRFAPSPTGYLH\n",
      "WDAAQSLLATYIKLNVARHQQGQPL\n",
      "CGTAMDSYLIDPKRKLHVCGNNPTC\n",
      "DAREAFLNITVTKDSRTRYSEAGHP\n",
      "MATGSYPWIPPIKGSDTQDCFVYRT\n",
      "EIYKRLIVSEDNKTLLGAVLVGDTS\n",
      "TFIATSPMHIATKLRSTLDEVIERA\n",
      "ISGLYERVPNIDKAIISVHTHDDLG\n",
      "RNGLRPARYVITKDKLITCASEVGI\n",
      "ADVIQIKVAQGAKPGEGGQLPGDKV\n",
      "PAPCDYAITAIQKFLETDIPVFGIC\n",
      "LPEQVRTNADLEKMVDTSDEWIVTR\n",
      "LVDDERWARFNEKLENIERERQRLK\n",
      "AAGDEVTVVRDEKKAREVALYRQGK\n",
      "QLGIVSLREALEKAEEAGVDLVEIS\n",
      "QLGIVSLREALEKAEEAGVDLVEIS Q 127\n",
      "VGEDWISLDMHGKRPKAVNVRTAPH\n",
      "OOOMSLLNVPAGKDLPEDIYVVIEI\n",
      "OOOOOOOOOOOMKPYQRQFIEFALS\n",
      "FGRPQRVAQEMQKEIALILQREIKD\n",
      "AAALGQIEKQFGKGSIMRLGEDRSM\n",
      "HTTIGKVDFDADKLKENLEALLVAL\n",
      "KQYDINEAIALLKELATAKFVESVD\n",
      "VRQHVIYKEAKIKOOOOOOOOOOOO\n",
      "RAKYQRQLARAIKRARYLSLLPYTD\n",
      "AFAVIVKAAEAAKQAOOOOOOOOOO\n",
      "FQVNQLLDILRAKLLKRGIEGSSLD\n",
      "TIFRELEVFVRSKLKEYQYQEVKGP\n",
      "LKAMGEMKNGEAKOOOOOOOOOOOO\n",
      "YLAVKRRIQPGDKMAGRHGNKGVIS\n",
      "OOMKTLGEFIVEKQHEFSHATGELT\n",
      "LEKKLQYVNEALKDEHWICGQRFTI\n",
      "IAELGRQITERYKDSGSDMVLVGLL\n",
      "KILKDLDEDIRGKDVLIVEDIIDSG\n",
      "SNGKSASAKSLFKLQTLGLTQGTVV\n",
      "APSQEEAVIAFGKFKLNLGTREMFR\n",
      "ANNDMQELEARLKEAREAGARHVLI\n",
      "AERGYLADVELSKIGSFEAALLAYV\n",
      "MAVAHFSPVNDLKHLNIMITAGPTR\n",
      "NNALHLFWQDGDKVLPLERKELLGQ\n",
      "QIDLYAVDGDEYKFLCIAKGGGSAN\n",
      "QIDLYAVDGDEYKFLCIAKGGGSAN Q 152\n",
      "VGDLQRSIDFYTKVLGMKLLRTSEN\n",
      "MEEVKQSNRLVIKTROOOOOOOOOO\n",
      "NDRRCLHLQLTEKGHEFLREVLPPQ\n",
      "KTLLPVLDTMLYKFDDNEIITSAID\n",
      "RWVNALVSELNDKEQHGSQWKFDVH\n",
      "FKDKVKGEWDKIKKDMOOOOOOOOO\n",
      "TIAIAINLFNPQKIVIAGEITEADK\n",
      "LPQELRQAIEHIKAHVTAETPKGKH\n",
      "EEVVEIRGGQRRKSERKFFPGYVLV\n",
      "FLGDGEMDEPESKGAITIATREKLD\n",
      "MQSMQFPAELIEKVCGTIOOOOOOO\n",
      "PGDPIIAHVSPGKGLVIHHESCRNI\n",
      "DTLHLEGKELEFKVIKLDQKRNNVV\n",
      "GGSAEEEAAAYIKEHVTKPVVGYIA\n",
      "VTEIAKKLNRSIKTISSQKKSAMMK\n",
      "TVALIAGGHTLGKTHGAGPTSNVGP\n",
      "NADWVIDGEQQPKSLFKMIKNTFET\n",
      "GDPETQPIMLRMKSDLVELCLAACE\n",
      "EAIGVLEQQSDLKGLLLRSNKAAFI\n",
      "VLFDMAREVNRLKAEDMAAANAMAS\n",
      "GGLDSSIISAITKKYAARRVEDQER\n",
      "SGSRDKGLHGKLKAGVCYSMLDTIN\n",
      "EILQWQRERLVAKLEDAQVQLENNR\n",
      "TTWRKLDETTRNKITDAASAAALMT\n",
      "DTALVHIAAAYHKPTLAFYPNSRTP\n",
      "QFTDDLIARNLLKDVTRVVVDVYGS\n",
      "QFTDDLIARNLLKDVTRVVVDVYGS Q 178\n",
      "SQIEIALDQGEVKAGEFAEPICELE\n",
      "EAMAMAKRVSKLKNANRFFVASDVH\n",
      "TEMMRYMHSLERKDLALNQAMIPLG\n",
      "SHLNTGRPYNADKPNKYTSRYFDEA\n",
      "PLGEEEVALARQKLGWHHPPFEIPK\n",
      "TPSHNPPEDGGIKYNPPNGGPADTN\n",
      "IGPDWYGTDVHHKTLGIVGMGRIGM\n",
      "QLETILNYIDIGKKEGADVLTGGRR\n",
      "QLETILNYIDIGKKEGADVLTGGRR Q 186\n",
      "QEIVDSMTIETYKQISENTKIISQK\n",
      "QEIVDSMTIETYKQISENTKIISQK Q 187\n",
      "LAQEEVWIRQGIKARRTRNEGRVRA\n",
      "GYDPIFFVPSEGKTAAELTREEKSA\n",
      "OOOOOOOOOOMQKVVLATGNVGKVR\n",
      "RSACTYVGASRLKELTKRTTFIRVQ\n",
      "KVRFFKSNSETIKOOOOOOOOOOOO\n",
      "MKVITLTGKDGGKMAGTADIEIRVP\n",
      "MAGVVIHAAFVYKLGDWFARDTRNF\n",
      "PHKSPEVFNLIMKRRAIAGSMIGGI\n",
      "GFGARHNASNSLKDIAELVPFAHRY\n",
      "NIFQSDHPVAMMKAVQAVVHHNETA\n",
      "KVALAQAQGQLAKDKATLANARRDL\n",
      "FEIVNNESDPRFKEYWTEYFQIMKR\n",
      "(200, 1, 25)\n",
      "[[[11  7 13 ...  9 10 13]]\n",
      "\n",
      " [[10  4 11 ... 12 16 11]]\n",
      "\n",
      " [[10  1  8 ...  6  6 20]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 3 10 14 ...  7 17  1]]\n",
      "\n",
      " [[12 20  1 ...  2  4 11]]\n",
      "\n",
      " [[14  7 10 ... 13 12  2]]]\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "r_test_x = []\n",
    "r_test_y = []\n",
    "posit_1 = 1;\n",
    "negat_0 = 0;\n",
    "\n",
    "# define universe of possible input values\n",
    "alphabet = 'OARNDCQEGHILKMFPSTWYV'\n",
    "# define a mapping of chars to integers\n",
    "char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
    "\n",
    "i = 0\n",
    "#-------------------------TEST DATASET----------------------------------------\n",
    "#for positive sequence\n",
    "def innertest1():\n",
    "    #Input\n",
    "    data = seq_record.seq\n",
    "    #rint(data) \n",
    "    # integer encode input data\n",
    "    for char in data:\n",
    "        if char not in alphabet:\n",
    "            return\n",
    "    integer_encoded = [char_to_int[char] for char in data]\n",
    "    r_test_x.append(integer_encoded)\n",
    "    r_test_y.append(posit_1)\n",
    "for seq_record in SeqIO.parse(\"./Datasets/independent_data/ecoli_test.fasta\", \"fasta\"):\n",
    "#for seq_record in SeqIO.parse(\"./Datasets/training_data/mus_train.fasta\", \"fasta\"):\n",
    "    innertest1()\n",
    "    i += 1\n",
    "\n",
    "\n",
    "#for negative sequence\n",
    "def innertest2():\n",
    "    #Input\n",
    "    data = seq_record.seq\n",
    "    print(data) \n",
    "    # integer encode input data\n",
    "    for char in data:\n",
    "        if char not in alphabet:\n",
    "#             print(data, i)\n",
    "            return\n",
    "    integer_encoded = [char_to_int[char] for char in data]\n",
    "    if integer_encoded[0] == 6: print(data, int_to_char[6], len(r_test_x))\n",
    "    r_test_x.append(integer_encoded) \n",
    "    r_test_y.append(negat_0)\n",
    "#for seq_record in SeqIO.parse(\"./Datasets/independent_data/mus_train_neg.fasta\", \"fasta\"):\n",
    "for seq_record in SeqIO.parse(\"./Datasets/independent_data/ecoli_test_neg.fasta\", \"fasta\"):\n",
    "    innertest2()\n",
    "# Changing to array (matrix)    \n",
    "r_test_x = np.array(r_test_x)\n",
    "r_test_y = np.array(r_test_y)\n",
    "\n",
    "# Balancing test dataset\n",
    "# Testing Data Balancing by undersampling####################################\n",
    "# rus = RandomUnderSampler(random_state=7)\n",
    "# x_res3, y_res3 = rus.fit_resample(r_test_x, r_test_y)\n",
    "# #Shuffling\n",
    "# r_test_x, r_test_y = shuffle(x_res3, y_res3, random_state=7)\n",
    "# r_test_x = np.array(r_test_x)\n",
    "# r_test_y = np.array(r_test_y)\n",
    "\n",
    "r_test_x = np.expand_dims(r_test_x, 1)\n",
    "print(r_test_x.shape)\n",
    "print(r_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abaf4669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DLMal(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DLMal, self).__init__()\n",
    "        self.embedding = nn.Embedding(25,21)\n",
    "        self.conv1 = nn.Conv2d(1, 64, (15, 3))\n",
    "        self.dropout1 = nn.Dropout(0.6)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3)\n",
    "        self.dropout2 = nn.Dropout(0.6)\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(4096, 768)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(768, 256)\n",
    "        self.dropout4 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(256, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        #print(x.shape)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        #print(x.shape)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.maxpool(x)\n",
    "        #print(x.shape)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout4(x)\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b562dc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  7 13  1  6  3  1  1  2 11  8 18 12  1  7 12 20  4  1  2 11  9  9 10\n",
      "  13]]\n",
      "['L', 'E', 'M', 'A', 'Q', 'N', 'A', 'A', 'R', 'L', 'G', 'W', 'K', 'A', 'E', 'K', 'V', 'D', 'A', 'R', 'L', 'H', 'H', 'I', 'M']\n",
      "tensor([[0.4768, 0.5232]], grad_fn=<SoftmaxBackward>)\n",
      "[[14  7 10 20  3  3  7 16  4 15  2 14 12  7 19 18 17  7 19 14  6 10 13 12\n",
      "   2]]\n",
      "['F', 'E', 'I', 'V', 'N', 'N', 'E', 'S', 'D', 'P', 'R', 'F', 'K', 'E', 'Y', 'W', 'T', 'E', 'Y', 'F', 'Q', 'I', 'M', 'K', 'R']\n",
      "tensor([[0.8321, 0.1679]], grad_fn=<SoftmaxBackward>)\n",
      "['I', 'D', 'L', 'F', 'R', 'T', 'L', 'I', 'Q', 'A', 'V', 'A', 'K', 'V', 'T', 'G', 'A', 'T', 'D', 'L', 'S', 'N', 'K', 'S', 'L'] [[0.76452476 0.23547527]]\n",
      "['A', 'A', 'A', 'N', 'K', 'R', 'V', 'S', 'N', 'I', 'L', 'A', 'K', 'S', 'D', 'E', 'V', 'L', 'S', 'D', 'R', 'V', 'N', 'A', 'S'] [[0.5012771 0.498723 ]]\n",
      "['K', 'Y', 'V', 'L', 'A', 'R', 'T', 'D', 'T', 'A', 'T', 'D', 'K', 'D', 'Y', 'L', 'D', 'I', 'E', 'R', 'V', 'I', 'G', 'H', 'E'] [[0.6416199  0.35838005]]\n",
      "['D', 'E', 'F', 'A', 'D', 'G', 'A', 'S', 'Y', 'L', 'Q', 'G', 'K', 'K', 'V', 'V', 'I', 'V', 'G', 'C', 'G', 'A', 'Q', 'G', 'L'] [[0.7972047 0.2027953]]\n",
      "['O', 'O', 'O', 'M', 'T', 'D', 'K', 'T', 'S', 'L', 'S', 'Y', 'K', 'D', 'A', 'G', 'V', 'D', 'I', 'D', 'A', 'G', 'N', 'A', 'L'] [[0.68933755 0.3106624 ]]\n",
      "['K', 'I', 'R', 'F', 'P', 'E', 'H', 'C', 'G', 'I', 'G', 'I', 'K', 'P', 'C', 'S', 'E', 'E', 'G', 'T', 'K', 'R', 'L', 'V', 'R'] [[0.5675486  0.43245143]]\n",
      "['N', 'I', 'T', 'R', 'T', 'F', 'V', 'H', 'P', 'T', 'S', 'N', 'K', 'Q', 'L', 'C', 'F', 'M', 'Q', 'H', 'I', 'I', 'E', 'T', 'L'] [[0.86220217 0.13779779]]\n",
      "['F', 'D', 'V', 'Y', 'T', 'P', 'D', 'I', 'L', 'R', 'C', 'R', 'K', 'S', 'G', 'V', 'L', 'T', 'G', 'L', 'P', 'D', 'A', 'Y', 'G'] [[0.6268069  0.37319317]]\n",
      "['T', 'E', 'R', 'I', 'L', 'F', 'Y', 'T', 'G', 'V', 'N', 'H', 'K', 'I', 'G', 'E', 'V', 'H', 'D', 'G', 'A', 'A', 'T', 'M', 'D'] [[0.62909883 0.37090108]]\n",
      "['I', 'R', 'M', 'G', 'S', 'E', 'V', 'F', 'H', 'H', 'L', 'A', 'K', 'V', 'L', 'K', 'A', 'K', 'G', 'M', 'N', 'T', 'A', 'V', 'G'] [[0.5575302  0.44246972]]\n",
      "['A', 'A', 'I', 'A', 'E', 'A', 'R', 'E', 'H', 'G', 'D', 'L', 'K', 'E', 'N', 'A', 'E', 'Y', 'H', 'A', 'A', 'R', 'E', 'Q', 'Q'] [[0.507031   0.49296898]]\n",
      "['S', 'Y', 'W', 'Y', 'P', 'V', 'R', 'Q', 'V', 'V', 'S', 'F', 'K', 'R', 'D', 'V', 'Y', 'R', 'R', 'V', 'M', 'K', 'E', 'F', 'A'] [[0.5281227  0.47187725]]\n",
      "['L', 'D', 'N', 'L', 'H', 'V', 'A', 'M', 'V', 'G', 'D', 'L', 'K', 'Y', 'G', 'R', 'T', 'V', 'H', 'S', 'L', 'T', 'Q', 'A', 'L'] [[0.5757622  0.42423782]]\n",
      "['R', 'D', 'D', 'L', 'N', 'L', 'V', 'L', 'A', 'T', 'A', 'A', 'K', 'L', 'K', 'A', 'N', 'P', 'Q', 'P', 'E', 'L', 'L', 'K', 'H'] [[0.74516964 0.25483033]]\n",
      "['V', 'Q', 'L', 'N', 'S', 'L', 'S', 'G', 'F', 'C', 'L', 'T', 'K', 'L', 'D', 'V', 'L', 'D', 'G', 'L', 'K', 'E', 'V', 'K', 'L'] [[0.9763104  0.02368968]]\n",
      "['V', 'T', 'Y', 'P', 'Y', 'V', 'T', 'I', 'D', 'V', 'S', 'S', 'K', 'S', 'H', 'P', 'F', 'Y', 'T', 'G', 'K', 'L', 'R', 'T', 'V'] [[0.632337   0.36766306]]\n",
      "['F', 'L', 'V', 'P', 'Q', 'G', 'K', 'A', 'V', 'P', 'A', 'T', 'K', 'K', 'N', 'I', 'E', 'F', 'F', 'E', 'A', 'R', 'R', 'A', 'E'] [[0.50864846 0.49135152]]\n",
      "['O', 'O', 'O', 'O', 'O', 'M', 'Q', 'V', 'I', 'L', 'L', 'D', 'K', 'V', 'A', 'N', 'L', 'G', 'S', 'L', 'G', 'D', 'Q', 'V', 'N'] [[0.5516597  0.44834027]]\n",
      "['K', 'I', 'N', 'A', 'L', 'E', 'T', 'V', 'T', 'I', 'A', 'S', 'K', 'A', 'G', 'D', 'E', 'G', 'K', 'L', 'F', 'G', 'S', 'I', 'G'] [[0.62473303 0.37526694]]\n",
      "['H', 'L', 'R', 'L', 'V', 'D', 'I', 'V', 'E', 'P', 'T', 'E', 'K', 'T', 'V', 'D', 'A', 'L', 'M', 'R', 'L', 'D', 'L', 'A', 'A'] [[0.5824293 0.4175707]]\n",
      "['G', 'Y', 'G', 'A', 'I', 'L', 'R', 'Y', 'R', 'G', 'R', 'E', 'K', 'T', 'F', 'S', 'A', 'G', 'Y', 'T', 'R', 'T', 'T', 'N', 'N'] [[0.5712364  0.42876363]]\n",
      "['I', 'T', 'V', 'N', 'K', 'N', 'S', 'V', 'P', 'N', 'D', 'P', 'K', 'S', 'P', 'F', 'V', 'T', 'S', 'G', 'I', 'R', 'V', 'G', 'T'] [[0.7151761 0.2848239]]\n",
      "['L', 'L', 'L', 'G', 'E', 'V', 'I', 'R', 'T', 'N', 'E', 'L', 'K', 'A', 'D', 'E', 'E', 'R', 'V', 'K', 'G', 'L', 'I', 'E', 'E'] [[0.53572536 0.46427467]]\n",
      "['A', 'N', 'I', 'K', 'G', 'L', 'T', 'F', 'T', 'Y', 'E', 'P', 'K', 'V', 'L', 'R', 'H', 'F', 'T', 'A', 'K', 'L', 'K', 'E', 'V'] [[0.5403609  0.45963907]]\n",
      "['L', 'S', 'K', 'E', 'R', 'R', 'D', 'I', 'S', 'K', 'K', 'L', 'K', 'A', 'M', 'G', 'E', 'M', 'K', 'N', 'G', 'E', 'A', 'K', 'O'] [[0.5322684  0.46773154]]\n",
      "['K', 'D', 'N', 'L', 'F', 'V', 'R', 'I', 'D', 'R', 'R', 'R', 'K', 'L', 'P', 'A', 'T', 'I', 'I', 'L', 'R', 'A', 'L', 'N', 'Y'] [[0.7358588  0.26414117]]\n",
      "['S', 'N', 'P', 'V', 'T', 'G', 'N', 'T', 'C', 'D', 'N', 'V', 'K', 'Q', 'R', 'A', 'A', 'L', 'I', 'D', 'C', 'L', 'A', 'P', 'D'] [[0.5313567  0.46864325]]\n",
      "['Q', 'N', 'E', 'V', 'A', 'T', 'R', 'F', 'N', 'T', 'M', 'T', 'K', 'K', 'A', 'D', 'E', 'I', 'Q', 'I', 'Y', 'K', 'Y', 'V', 'V'] [[0.58317924 0.4168208 ]]\n",
      "['H', 'E', 'G', 'H', 'V', 'A', 'A', 'E', 'V', 'I', 'A', 'G', 'K', 'K', 'H', 'Y', 'F', 'D', 'P', 'K', 'V', 'I', 'P', 'S', 'I'] [[0.54198575 0.45801428]]\n",
      "['L', 'L', 'L', 'F', 'K', 'N', 'G', 'E', 'V', 'A', 'A', 'T', 'K', 'V', 'G', 'A', 'L', 'S', 'K', 'G', 'Q', 'L', 'K', 'E', 'F'] [[0.6460099  0.35399005]]\n",
      "['T', 'S', 'A', 'Y', 'A', 'T', 'K', 'F', 'A', 'G', 'L', 'V', 'K', 'D', 'F', 'N', 'C', 'E', 'D', 'I', 'I', 'S', 'R', 'K', 'E'] [[0.5763835 0.4236165]]\n",
      "['M', 'Q', 'L', 'N', 'S', 'T', 'E', 'I', 'S', 'E', 'L', 'I', 'K', 'Q', 'R', 'I', 'A', 'Q', 'F', 'N', 'V', 'V', 'S', 'E', 'A'] [[0.80367756 0.19632247]]\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'M', 'A', 'E', 'M', 'K', 'N', 'L', 'K', 'I', 'E', 'V', 'V', 'R', 'Y', 'N', 'P', 'E'] [[0.56455797 0.435442  ]]\n",
      "['E', 'I', 'T', 'S', 'T', 'D', 'D', 'F', 'Y', 'R', 'L', 'G', 'K', 'E', 'L', 'A', 'L', 'Q', 'S', 'G', 'L', 'A', 'H', 'K', 'G'] [[0.59870607 0.40129393]]\n",
      "['G', 'Q', 'R', 'I', 'Q', 'N', 'L', 'R', 'N', 'V', 'M', 'S', 'K', 'T', 'G', 'K', 'T', 'A', 'A', 'I', 'L', 'L', 'D', 'T', 'K'] [[0.63380444 0.36619556]]\n",
      "['I', 'Q', 'E', 'S', 'H', 'V', 'H', 'D', 'V', 'T', 'I', 'T', 'K', 'E', 'S', 'P', 'N', 'Y', 'R', 'L', 'G', 'S', 'O', 'O', 'O'] [[0.60064596 0.39935407]]\n",
      "['A', 'L', 'A', 'Q', 'E', 'G', 'G', 'I', 'G', 'F', 'I', 'H', 'K', 'N', 'M', 'S', 'I', 'E', 'R', 'Q', 'A', 'E', 'E', 'V', 'R'] [[0.70526665 0.29473338]]\n",
      "['D', 'L', 'N', 'L', 'L', 'Q', 'F', 'L', 'Q', 'K', 'L', 'A', 'K', 'E', 'S', 'G', 'F', 'D', 'G', 'E', 'L', 'A', 'D', 'L', 'T'] [[0.5456452 0.4543548]]\n",
      "['M', 'T', 'F', 'T', 'I', 'E', 'P', 'M', 'V', 'N', 'A', 'G', 'K', 'K', 'E', 'I', 'R', 'T', 'M', 'K', 'D', 'G', 'W', 'T', 'V'] [[0.54039234 0.4596076 ]]\n",
      "['Q', 'R', 'G', 'Y', 'Q', 'A', 'G', 'I', 'A', 'G', 'R', 'S', 'K', 'E', 'M', 'C', 'P', 'Y', 'Q', 'T', 'L', 'N', 'Q', 'R', 'S'] [[0.5311239  0.46887615]]\n",
      "['E', 'L', 'T', 'R', 'T', 'L', 'N', 'D', 'A', 'V', 'E', 'V', 'K', 'H', 'A', 'D', 'N', 'T', 'L', 'T', 'F', 'G', 'P', 'R', 'D'] [[0.66685766 0.33314228]]\n",
      "['R', 'L', 'V', 'H', 'G', 'E', 'E', 'G', 'L', 'Q', 'A', 'A', 'K', 'R', 'I', 'T', 'E', 'C', 'L', 'F', 'S', 'G', 'S', 'L', 'S'] [[0.517991   0.48200908]]\n",
      "['D', 'S', 'Y', 'I', 'P', 'E', 'P', 'E', 'R', 'A', 'I', 'D', 'K', 'P', 'F', 'L', 'L', 'P', 'I', 'E', 'D', 'V', 'F', 'S', 'I'] [[0.80449605 0.195504  ]]\n",
      "['L', 'S', 'T', 'G', 'G', 'T', 'A', 'R', 'L', 'L', 'A', 'E', 'K', 'G', 'L', 'P', 'V', 'T', 'E', 'V', 'S', 'D', 'Y', 'T', 'G'] [[0.51951426 0.48048577]]\n",
      "['Q', 'R', 'Y', 'W', 'L', 'V', 'D', 'P', 'L', 'D', 'G', 'T', 'K', 'E', 'F', 'I', 'K', 'R', 'N', 'G', 'E', 'F', 'T', 'V', 'N'] [[0.5122537  0.48774633]]\n",
      "['I', 'G', 'T', 'V', 'I', 'D', 'N', 'D', 'N', 'C', 'T', 'S', 'K', 'F', 'S', 'R', 'F', 'F', 'A', 'T', 'R', 'E', 'E', 'A', 'E'] [[0.91512007 0.08487996]]\n",
      "['F', 'A', 'T', 'R', 'E', 'E', 'A', 'E', 'S', 'F', 'M', 'T', 'K', 'L', 'K', 'E', 'L', 'A', 'A', 'A', 'T', 'S', 'S', 'A', 'D'] [[0.6271365  0.37286347]]\n",
      "['N', 'F', 'I', 'A', 'T', 'I', 'E', 'E', 'R', 'Q', 'G', 'L', 'K', 'V', 'S', 'C', 'P', 'E', 'E', 'I', 'A', 'F', 'R', 'K', 'G'] [[0.56152713 0.43847284]]\n",
      "['T', 'E', 'G', 'L', 'T', 'A', 'E', 'Q', 'I', 'R', 'R', 'G', 'K', 'T', 'V', 'V', 'V', 'E', 'G', 'C', 'E', 'E', 'K', 'L', 'A'] [[0.5264339  0.47356606]]\n",
      "['G', 'I', 'G', 'V', 'I', 'N', 'F', 'A', 'Y', 'Y', 'L', 'A', 'K', 'H', 'G', 'K', 'R', 'Y', 'S', 'D', 'G', 'S', 'A', 'N', 'N'] [[0.4944837 0.5055163]]\n",
      "['A', 'A', 'L', 'A', 'S', 'V', 'K', 'G', 'W', 'V', 'S', 'A', 'K', 'L', 'Q', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] [[0.40075356 0.59924644]]\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'M', 'K', 'I', 'K', 'T', 'R', 'F', 'A', 'P', 'S', 'P', 'T', 'G', 'Y', 'L', 'H'] [[0.40434226 0.5956577 ]]\n",
      "['D', 'A', 'R', 'E', 'A', 'F', 'L', 'N', 'I', 'T', 'V', 'T', 'K', 'D', 'S', 'R', 'T', 'R', 'Y', 'S', 'E', 'A', 'G', 'H', 'P'] [[0.43387595 0.566124  ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E', 'I', 'Y', 'K', 'R', 'L', 'I', 'V', 'S', 'E', 'D', 'N', 'K', 'T', 'L', 'L', 'G', 'A', 'V', 'L', 'V', 'G', 'D', 'T', 'S'] [[0.4339227 0.5660773]]\n",
      "['A', 'D', 'V', 'I', 'Q', 'I', 'K', 'V', 'A', 'Q', 'G', 'A', 'K', 'P', 'G', 'E', 'G', 'G', 'Q', 'L', 'P', 'G', 'D', 'K', 'V'] [[0.38388747 0.6161126 ]]\n",
      "['L', 'V', 'D', 'D', 'E', 'R', 'W', 'A', 'R', 'F', 'N', 'E', 'K', 'L', 'E', 'N', 'I', 'E', 'R', 'E', 'R', 'Q', 'R', 'L', 'K'] [[0.41932496 0.580675  ]]\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'M', 'K', 'P', 'Y', 'Q', 'R', 'Q', 'F', 'I', 'E', 'F', 'A', 'L', 'S'] [[0.3146222  0.68537784]]\n",
      "['F', 'G', 'R', 'P', 'Q', 'R', 'V', 'A', 'Q', 'E', 'M', 'Q', 'K', 'E', 'I', 'A', 'L', 'I', 'L', 'Q', 'R', 'E', 'I', 'K', 'D'] [[0.42036837 0.5796316 ]]\n",
      "['A', 'A', 'A', 'L', 'G', 'Q', 'I', 'E', 'K', 'Q', 'F', 'G', 'K', 'G', 'S', 'I', 'M', 'R', 'L', 'G', 'E', 'D', 'R', 'S', 'M'] [[0.16856337 0.83143663]]\n",
      "['H', 'T', 'T', 'I', 'G', 'K', 'V', 'D', 'F', 'D', 'A', 'D', 'K', 'L', 'K', 'E', 'N', 'L', 'E', 'A', 'L', 'L', 'V', 'A', 'L'] [[0.42605308 0.57394695]]\n",
      "['R', 'A', 'K', 'Y', 'Q', 'R', 'Q', 'L', 'A', 'R', 'A', 'I', 'K', 'R', 'A', 'R', 'Y', 'L', 'S', 'L', 'L', 'P', 'Y', 'T', 'D'] [[0.44282535 0.5571746 ]]\n",
      "['A', 'F', 'A', 'V', 'I', 'V', 'K', 'A', 'A', 'E', 'A', 'A', 'K', 'Q', 'A', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] [[0.48406607 0.51593393]]\n",
      "['T', 'I', 'F', 'R', 'E', 'L', 'E', 'V', 'F', 'V', 'R', 'S', 'K', 'L', 'K', 'E', 'Y', 'Q', 'Y', 'Q', 'E', 'V', 'K', 'G', 'P'] [[0.42656204 0.5734379 ]]\n",
      "['Y', 'L', 'A', 'V', 'K', 'R', 'R', 'I', 'Q', 'P', 'G', 'D', 'K', 'M', 'A', 'G', 'R', 'H', 'G', 'N', 'K', 'G', 'V', 'I', 'S'] [[0.23893595 0.76106405]]\n",
      "['S', 'N', 'G', 'K', 'S', 'A', 'S', 'A', 'K', 'S', 'L', 'F', 'K', 'L', 'Q', 'T', 'L', 'G', 'L', 'T', 'Q', 'G', 'T', 'V', 'V'] [[0.40511462 0.5948854 ]]\n",
      "['V', 'G', 'D', 'L', 'Q', 'R', 'S', 'I', 'D', 'F', 'Y', 'T', 'K', 'V', 'L', 'G', 'M', 'K', 'L', 'L', 'R', 'T', 'S', 'E', 'N'] [[0.47562268 0.5243773 ]]\n",
      "['V', 'T', 'E', 'I', 'A', 'K', 'K', 'L', 'N', 'R', 'S', 'I', 'K', 'T', 'I', 'S', 'S', 'Q', 'K', 'K', 'S', 'A', 'M', 'M', 'K'] [[0.09525556 0.90474445]]\n",
      "['G', 'G', 'L', 'D', 'S', 'S', 'I', 'I', 'S', 'A', 'I', 'T', 'K', 'K', 'Y', 'A', 'A', 'R', 'R', 'V', 'E', 'D', 'Q', 'E', 'R'] [[0.4918822 0.5081178]]\n",
      "['S', 'G', 'S', 'R', 'D', 'K', 'G', 'L', 'H', 'G', 'K', 'L', 'K', 'A', 'G', 'V', 'C', 'Y', 'S', 'M', 'L', 'D', 'T', 'I', 'N'] [[0.10899194 0.891008  ]]\n",
      "['T', 'T', 'W', 'R', 'K', 'L', 'D', 'E', 'T', 'T', 'R', 'N', 'K', 'I', 'T', 'D', 'A', 'A', 'S', 'A', 'A', 'A', 'L', 'M', 'T'] [[0.47837228 0.5216277 ]]\n",
      "['E', 'A', 'M', 'A', 'M', 'A', 'K', 'R', 'V', 'S', 'K', 'L', 'K', 'N', 'A', 'N', 'R', 'F', 'F', 'V', 'A', 'S', 'D', 'V', 'H'] [[0.23786815 0.7621318 ]]\n",
      "['T', 'E', 'M', 'M', 'R', 'Y', 'M', 'H', 'S', 'L', 'E', 'R', 'K', 'D', 'L', 'A', 'L', 'N', 'Q', 'A', 'M', 'I', 'P', 'L', 'G'] [[0.47417167 0.52582836]]\n",
      "['Q', 'E', 'I', 'V', 'D', 'S', 'M', 'T', 'I', 'E', 'T', 'Y', 'K', 'Q', 'I', 'S', 'E', 'N', 'T', 'K', 'I', 'I', 'S', 'Q', 'K'] [[0.47211614 0.5278839 ]]\n",
      "['G', 'Y', 'D', 'P', 'I', 'F', 'F', 'V', 'P', 'S', 'E', 'G', 'K', 'T', 'A', 'A', 'E', 'L', 'T', 'R', 'E', 'E', 'K', 'S', 'A'] [[0.37209007 0.62790996]]\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'M', 'Q', 'K', 'V', 'V', 'L', 'A', 'T', 'G', 'N', 'V', 'G', 'K', 'V', 'R'] [[0.44706875 0.5529313 ]]\n",
      "['M', 'K', 'V', 'I', 'T', 'L', 'T', 'G', 'K', 'D', 'G', 'G', 'K', 'M', 'A', 'G', 'T', 'A', 'D', 'I', 'E', 'I', 'R', 'V', 'P'] [[0.41831362 0.58168644]]\n",
      "['P', 'H', 'K', 'S', 'P', 'E', 'V', 'F', 'N', 'L', 'I', 'M', 'K', 'R', 'R', 'A', 'I', 'A', 'G', 'S', 'M', 'I', 'G', 'G', 'I'] [[0.3976331 0.6023669]]\n",
      "['K', 'V', 'A', 'L', 'A', 'Q', 'A', 'Q', 'G', 'Q', 'L', 'A', 'K', 'D', 'K', 'A', 'T', 'L', 'A', 'N', 'A', 'R', 'R', 'D', 'L'] [[0.31687072 0.6831293 ]]\n",
      "acc: 61.0\n",
      "sn: 63.74999999999999\n",
      "sp: 59.166666666666664\n",
      "mcc: 0.22453655975512468\n"
     ]
    }
   ],
   "source": [
    "PATH = './Path/dlmal_m_net.pth'\n",
    "net = torch.load(PATH, map_location=\"cpu\")\n",
    "net.eval()\n",
    "\n",
    "print(r_test_x[0])\n",
    "print([int_to_char[i] for i in r_test_x[0][0]])\n",
    "y = net(torch.from_numpy(np.array([r_test_x[0]])))\n",
    "print(F.softmax(y, dim=1))\n",
    "\n",
    "print(r_test_x[-1])\n",
    "print([int_to_char[i] for i in r_test_x[-1][0]])\n",
    "y = net(torch.from_numpy(np.array([r_test_x[-1]])))\n",
    "print(F.softmax(y, dim=1))\n",
    "\n",
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "for i in range(len(r_test_x)):\n",
    "    y = net(torch.from_numpy(np.array([r_test_x[i]])))\n",
    "    y = F.softmax(y, dim=1)\n",
    "    y = y.detach().cpu().numpy()\n",
    "    if (y[0][0] > y[0][1] and r_test_y[i] == 0):\n",
    "        TN += 1\n",
    "    elif (y[0][0] < y[0][1] and r_test_y[i] == 1):\n",
    "        TP += 1\n",
    "    elif r_test_y[i] == 0:\n",
    "        FN += 1\n",
    "        print([int_to_char[i] for i in r_test_x[i][0]], y)\n",
    "    else:\n",
    "        FP +=1\n",
    "        print([int_to_char[i] for i in r_test_x[i][0]], y)\n",
    "       \n",
    "print(\"acc:\", (TP+TN)/(TP+TN+FP+FN)*100)\n",
    "print(\"sn:\", (TP)/(TP+FN)*100)\n",
    "print(\"sp:\", TN/(TN+FP)*100)\n",
    "print(\"mcc:\", (TP*TN-FP*FN)/((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))**(1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3d02ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
