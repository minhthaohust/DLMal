{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "269b429f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7170, 1, 25)\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "\n",
    "r_test_x = []\n",
    "r_test_y = []\n",
    "posit_1 = 1;\n",
    "negat_0 = 0;\n",
    "\n",
    "# define universe of possible input values\n",
    "alphabet = 'OARNDCQEGHILKMFPSTWYV'\n",
    "# define a mapping of chars to integers\n",
    "char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
    "\n",
    "i = 0\n",
    "#-------------------------TEST DATASET----------------------------------------\n",
    "#for positive sequence\n",
    "def innertest1():\n",
    "    #Input\n",
    "    data = seq_record.seq\n",
    "    #rint(data) \n",
    "    # integer encode input data\n",
    "    for char in data:\n",
    "        if char not in alphabet:\n",
    "            print(data, i)\n",
    "            return\n",
    "    integer_encoded = [char_to_int[char] for char in data]\n",
    "    r_test_x.append(integer_encoded)\n",
    "    r_test_y.append(posit_1)\n",
    "for seq_record in SeqIO.parse(\"./Datasets/training_data/H_train.fasta\", \"fasta\"):\n",
    "\n",
    "    innertest1()\n",
    "    i += 1\n",
    "    \n",
    "#print(len(r_test_x))\n",
    "\n",
    "#for negative sequence\n",
    "def innertest2():\n",
    "    #Input\n",
    "    data = seq_record.seq\n",
    "    #print(data) \n",
    "    # integer encode input data\n",
    "    for char in data:\n",
    "        if char not in alphabet:\n",
    "            return\n",
    "    integer_encoded = [char_to_int[char] for char in data]\n",
    "    r_test_x.append(integer_encoded) \n",
    "    r_test_y.append(negat_0)\n",
    "\n",
    "for seq_record in SeqIO.parse(\"./Datasets/training_data/H_train_neg.fasta\", \"fasta\"):\n",
    "    innertest2()\n",
    "# Changing to array (matrix)    \n",
    "r_test_x = np.array(r_test_x)\n",
    "r_test_y = np.array(r_test_y)\n",
    "\n",
    "# Balancing test dataset\n",
    "# Testing Data Balancing by undersampling####################################\n",
    "rus = RandomUnderSampler(random_state=7)\n",
    "x_res3, y_res3 = rus.fit_resample(r_test_x, r_test_y)\n",
    "#Shuffling\n",
    "r_test_x, r_test_y = shuffle(x_res3, y_res3, random_state=7)\n",
    "r_test_x = np.array(r_test_x)\n",
    "r_test_y = np.array(r_test_y)\n",
    "\n",
    "#print(r_test_y.shape)\n",
    "r_test_x = np.expand_dims(r_test_x, 1)\n",
    "print(r_test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f122aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0770, -0.0506]], grad_fn=<AddmmBackward>)\n",
      "[1 0 0 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DLMal(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DLMal, self).__init__()\n",
    "        self.embedding = nn.Embedding(25,21)\n",
    "        self.conv1 = nn.Conv2d(1, 64, (15, 3))\n",
    "        self.dropout1 = nn.Dropout(0.6)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3)\n",
    "        self.dropout2 = nn.Dropout(0.6)\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(4096, 768)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(768, 256)\n",
    "        self.dropout4 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(256, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        #print(x.shape)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        #print(x.shape)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.maxpool(x)\n",
    "        #print(x.shape)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout4(x)\n",
    "        return self.fc3(x)\n",
    "net = DLMal()\n",
    "y = net(torch.from_numpy(np.array([r_test_x[0]])))#convert array numpy to tensor\n",
    "print(y)\n",
    "print(r_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0712fc9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] train loss: 0.706 train acc: 0.477\n",
      "[1,     2] train loss: 0.947 train acc: 0.562\n",
      "[1,     3] train loss: 1.066 train acc: 0.539\n",
      "[1,     4] train loss: 0.749 train acc: 0.516\n",
      "[1,     5] train loss: 0.695 train acc: 0.496\n",
      "[1,     6] train loss: 0.696 train acc: 0.492\n",
      "[1,     7] train loss: 0.692 train acc: 0.539\n",
      "[1,     8] train loss: 0.690 train acc: 0.535\n",
      "[1,     9] train loss: 0.701 train acc: 0.484\n",
      "[1,    10] train loss: 0.693 train acc: 0.523\n",
      "[1,    11] train loss: 0.696 train acc: 0.500\n",
      "[1,    12] train loss: 0.691 train acc: 0.535\n",
      "[1,    13] train loss: 0.694 train acc: 0.465\n",
      "[1,    14] train loss: 0.692 train acc: 0.527\n",
      "[1,    15] train loss: 0.692 train acc: 0.520\n",
      "[1,    16] train loss: 0.694 train acc: 0.441\n",
      "[1,    17] train loss: 0.694 train acc: 0.438\n",
      "[1,    18] train loss: 0.693 train acc: 0.469\n",
      "[1,    19] train loss: 0.693 train acc: 0.492\n",
      "[1,    20] train loss: 0.694 train acc: 0.471\n",
      "[1] val loss: 0.693 val acc: 0.504\n",
      "[2,     1] train loss: 0.693 train acc: 0.488\n",
      "[2,     2] train loss: 0.694 train acc: 0.504\n",
      "[2,     3] train loss: 0.693 train acc: 0.535\n",
      "[2,     4] train loss: 0.693 train acc: 0.516\n",
      "[2,     5] train loss: 0.693 train acc: 0.527\n",
      "[2,     6] train loss: 0.693 train acc: 0.543\n",
      "[2,     7] train loss: 0.694 train acc: 0.477\n",
      "[2,     8] train loss: 0.693 train acc: 0.484\n",
      "[2,     9] train loss: 0.693 train acc: 0.535\n",
      "[2,    10] train loss: 0.693 train acc: 0.516\n",
      "[2,    11] train loss: 0.693 train acc: 0.500\n",
      "[2,    12] train loss: 0.694 train acc: 0.465\n",
      "[2,    13] train loss: 0.693 train acc: 0.523\n",
      "[2,    14] train loss: 0.693 train acc: 0.512\n",
      "[2,    15] train loss: 0.694 train acc: 0.465\n",
      "[2,    16] train loss: 0.693 train acc: 0.500\n",
      "[2,    17] train loss: 0.693 train acc: 0.500\n",
      "[2,    18] train loss: 0.694 train acc: 0.496\n",
      "[2,    19] train loss: 0.694 train acc: 0.457\n",
      "[2,    20] train loss: 0.692 train acc: 0.548\n",
      "[2] val loss: 0.693 val acc: 0.504\n",
      "[3,     1] train loss: 0.693 train acc: 0.504\n",
      "[3,     2] train loss: 0.694 train acc: 0.477\n",
      "[3,     3] train loss: 0.693 train acc: 0.512\n",
      "[3,     4] train loss: 0.692 train acc: 0.539\n",
      "[3,     5] train loss: 0.693 train acc: 0.516\n",
      "[3,     6] train loss: 0.693 train acc: 0.531\n",
      "[3,     7] train loss: 0.696 train acc: 0.398\n",
      "[3,     8] train loss: 0.692 train acc: 0.566\n",
      "[3,     9] train loss: 0.695 train acc: 0.414\n",
      "[3,    10] train loss: 0.694 train acc: 0.461\n",
      "[3,    11] train loss: 0.694 train acc: 0.465\n",
      "[3,    12] train loss: 0.692 train acc: 0.551\n",
      "[3,    13] train loss: 0.693 train acc: 0.496\n",
      "[3,    14] train loss: 0.693 train acc: 0.539\n",
      "[3,    15] train loss: 0.693 train acc: 0.516\n",
      "[3,    16] train loss: 0.693 train acc: 0.539\n",
      "[3,    17] train loss: 0.693 train acc: 0.488\n",
      "[3,    18] train loss: 0.694 train acc: 0.477\n",
      "[3,    19] train loss: 0.693 train acc: 0.492\n",
      "[3,    20] train loss: 0.692 train acc: 0.529\n",
      "[3] val loss: 0.693 val acc: 0.504\n",
      "[4,     1] train loss: 0.693 train acc: 0.488\n",
      "[4,     2] train loss: 0.693 train acc: 0.500\n",
      "[4,     3] train loss: 0.693 train acc: 0.504\n",
      "[4,     4] train loss: 0.694 train acc: 0.453\n",
      "[4,     5] train loss: 0.693 train acc: 0.512\n",
      "[4,     6] train loss: 0.693 train acc: 0.520\n",
      "[4,     7] train loss: 0.694 train acc: 0.434\n",
      "[4,     8] train loss: 0.693 train acc: 0.531\n",
      "[4,     9] train loss: 0.693 train acc: 0.496\n",
      "[4,    10] train loss: 0.693 train acc: 0.496\n",
      "[4,    11] train loss: 0.693 train acc: 0.523\n",
      "[4,    12] train loss: 0.693 train acc: 0.539\n",
      "[4,    13] train loss: 0.693 train acc: 0.473\n",
      "[4,    14] train loss: 0.693 train acc: 0.512\n",
      "[4,    15] train loss: 0.693 train acc: 0.477\n",
      "[4,    16] train loss: 0.693 train acc: 0.504\n",
      "[4,    17] train loss: 0.693 train acc: 0.520\n",
      "[4,    18] train loss: 0.694 train acc: 0.504\n",
      "[4,    19] train loss: 0.693 train acc: 0.551\n",
      "[4,    20] train loss: 0.693 train acc: 0.561\n",
      "[4] val loss: 0.693 val acc: 0.504\n",
      "[5,     1] train loss: 0.693 train acc: 0.566\n",
      "[5,     2] train loss: 0.693 train acc: 0.465\n",
      "[5,     3] train loss: 0.693 train acc: 0.469\n",
      "[5,     4] train loss: 0.693 train acc: 0.504\n",
      "[5,     5] train loss: 0.693 train acc: 0.492\n",
      "[5,     6] train loss: 0.693 train acc: 0.504\n",
      "[5,     7] train loss: 0.693 train acc: 0.496\n",
      "[5,     8] train loss: 0.693 train acc: 0.508\n",
      "[5,     9] train loss: 0.693 train acc: 0.520\n",
      "[5,    10] train loss: 0.694 train acc: 0.484\n",
      "[5,    11] train loss: 0.693 train acc: 0.504\n",
      "[5,    12] train loss: 0.693 train acc: 0.492\n",
      "[5,    13] train loss: 0.693 train acc: 0.484\n",
      "[5,    14] train loss: 0.693 train acc: 0.512\n",
      "[5,    15] train loss: 0.693 train acc: 0.508\n",
      "[5,    16] train loss: 0.693 train acc: 0.480\n",
      "[5,    17] train loss: 0.693 train acc: 0.547\n",
      "[5,    18] train loss: 0.694 train acc: 0.465\n",
      "[5,    19] train loss: 0.692 train acc: 0.574\n",
      "[5,    20] train loss: 0.693 train acc: 0.490\n",
      "[5] val loss: 0.693 val acc: 0.504\n",
      "[6,     1] train loss: 0.693 train acc: 0.512\n",
      "[6,     2] train loss: 0.693 train acc: 0.523\n",
      "[6,     3] train loss: 0.693 train acc: 0.523\n",
      "[6,     4] train loss: 0.693 train acc: 0.508\n",
      "[6,     5] train loss: 0.693 train acc: 0.523\n",
      "[6,     6] train loss: 0.692 train acc: 0.535\n",
      "[6,     7] train loss: 0.692 train acc: 0.602\n",
      "[6,     8] train loss: 0.693 train acc: 0.527\n",
      "[6,     9] train loss: 0.693 train acc: 0.523\n",
      "[6,    10] train loss: 0.693 train acc: 0.523\n",
      "[6,    11] train loss: 0.692 train acc: 0.555\n",
      "[6,    12] train loss: 0.694 train acc: 0.492\n",
      "[6,    13] train loss: 0.693 train acc: 0.500\n",
      "[6,    14] train loss: 0.692 train acc: 0.555\n",
      "[6,    15] train loss: 0.693 train acc: 0.527\n",
      "[6,    16] train loss: 0.693 train acc: 0.516\n",
      "[6,    17] train loss: 0.693 train acc: 0.457\n",
      "[6,    18] train loss: 0.693 train acc: 0.512\n",
      "[6,    19] train loss: 0.692 train acc: 0.578\n",
      "[6,    20] train loss: 0.693 train acc: 0.503\n",
      "[6] val loss: 0.692 val acc: 0.555\n",
      "[7,     1] train loss: 0.690 train acc: 0.555\n",
      "[7,     2] train loss: 0.692 train acc: 0.496\n",
      "[7,     3] train loss: 0.692 train acc: 0.543\n",
      "[7,     4] train loss: 0.694 train acc: 0.504\n",
      "[7,     5] train loss: 0.693 train acc: 0.531\n",
      "[7,     6] train loss: 0.694 train acc: 0.500\n",
      "[7,     7] train loss: 0.697 train acc: 0.453\n",
      "[7,     8] train loss: 0.689 train acc: 0.539\n",
      "[7,     9] train loss: 0.694 train acc: 0.469\n",
      "[7,    10] train loss: 0.685 train acc: 0.586\n",
      "[7,    11] train loss: 0.698 train acc: 0.500\n",
      "[7,    12] train loss: 0.695 train acc: 0.488\n",
      "[7,    13] train loss: 0.694 train acc: 0.508\n",
      "[7,    14] train loss: 0.691 train acc: 0.531\n",
      "[7,    15] train loss: 0.686 train acc: 0.570\n",
      "[7,    16] train loss: 0.689 train acc: 0.531\n",
      "[7,    17] train loss: 0.687 train acc: 0.559\n",
      "[7,    18] train loss: 0.694 train acc: 0.500\n",
      "[7,    19] train loss: 0.687 train acc: 0.578\n",
      "[7,    20] train loss: 0.686 train acc: 0.548\n",
      "[7] val loss: 0.688 val acc: 0.591\n",
      "[8,     1] train loss: 0.690 train acc: 0.531\n",
      "[8,     2] train loss: 0.684 train acc: 0.539\n",
      "[8,     3] train loss: 0.690 train acc: 0.547\n",
      "[8,     4] train loss: 0.686 train acc: 0.582\n",
      "[8,     5] train loss: 0.679 train acc: 0.578\n",
      "[8,     6] train loss: 0.688 train acc: 0.531\n",
      "[8,     7] train loss: 0.681 train acc: 0.570\n",
      "[8,     8] train loss: 0.672 train acc: 0.551\n",
      "[8,     9] train loss: 0.694 train acc: 0.555\n",
      "[8,    10] train loss: 0.674 train acc: 0.535\n",
      "[8,    11] train loss: 0.683 train acc: 0.547\n",
      "[8,    12] train loss: 0.675 train acc: 0.570\n",
      "[8,    13] train loss: 0.686 train acc: 0.539\n",
      "[8,    14] train loss: 0.672 train acc: 0.578\n",
      "[8,    15] train loss: 0.700 train acc: 0.562\n",
      "[8,    16] train loss: 0.681 train acc: 0.559\n",
      "[8,    17] train loss: 0.722 train acc: 0.512\n",
      "[8,    18] train loss: 0.690 train acc: 0.582\n",
      "[8,    19] train loss: 0.672 train acc: 0.613\n",
      "[8,    20] train loss: 0.675 train acc: 0.613\n",
      "[8] val loss: 0.681 val acc: 0.599\n",
      "[9,     1] train loss: 0.683 train acc: 0.520\n",
      "[9,     2] train loss: 0.681 train acc: 0.566\n",
      "[9,     3] train loss: 0.680 train acc: 0.520\n",
      "[9,     4] train loss: 0.685 train acc: 0.570\n",
      "[9,     5] train loss: 0.674 train acc: 0.590\n",
      "[9,     6] train loss: 0.681 train acc: 0.543\n",
      "[9,     7] train loss: 0.691 train acc: 0.523\n",
      "[9,     8] train loss: 0.681 train acc: 0.547\n",
      "[9,     9] train loss: 0.677 train acc: 0.605\n",
      "[9,    10] train loss: 0.687 train acc: 0.551\n",
      "[9,    11] train loss: 0.682 train acc: 0.562\n",
      "[9,    12] train loss: 0.682 train acc: 0.590\n",
      "[9,    13] train loss: 0.681 train acc: 0.578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9,    14] train loss: 0.681 train acc: 0.586\n",
      "[9,    15] train loss: 0.665 train acc: 0.598\n",
      "[9,    16] train loss: 0.679 train acc: 0.559\n",
      "[9,    17] train loss: 0.666 train acc: 0.625\n",
      "[9,    18] train loss: 0.697 train acc: 0.527\n",
      "[9,    19] train loss: 0.674 train acc: 0.582\n",
      "[9,    20] train loss: 0.673 train acc: 0.587\n",
      "[9] val loss: 0.674 val acc: 0.590\n",
      "[10,     1] train loss: 0.675 train acc: 0.605\n",
      "[10,     2] train loss: 0.688 train acc: 0.523\n",
      "[10,     3] train loss: 0.662 train acc: 0.574\n",
      "[10,     4] train loss: 0.660 train acc: 0.590\n",
      "[10,     5] train loss: 0.673 train acc: 0.566\n",
      "[10,     6] train loss: 0.668 train acc: 0.594\n",
      "[10,     7] train loss: 0.682 train acc: 0.539\n",
      "[10,     8] train loss: 0.677 train acc: 0.559\n",
      "[10,     9] train loss: 0.650 train acc: 0.617\n",
      "[10,    10] train loss: 0.679 train acc: 0.555\n",
      "[10,    11] train loss: 0.694 train acc: 0.586\n",
      "[10,    12] train loss: 0.677 train acc: 0.551\n",
      "[10,    13] train loss: 0.688 train acc: 0.535\n",
      "[10,    14] train loss: 0.669 train acc: 0.574\n",
      "[10,    15] train loss: 0.679 train acc: 0.594\n",
      "[10,    16] train loss: 0.673 train acc: 0.594\n",
      "[10,    17] train loss: 0.671 train acc: 0.555\n",
      "[10,    18] train loss: 0.677 train acc: 0.598\n",
      "[10,    19] train loss: 0.673 train acc: 0.559\n",
      "[10,    20] train loss: 0.692 train acc: 0.555\n",
      "[10] val loss: 0.674 val acc: 0.586\n",
      "[11,     1] train loss: 0.682 train acc: 0.582\n",
      "[11,     2] train loss: 0.663 train acc: 0.602\n",
      "[11,     3] train loss: 0.680 train acc: 0.555\n",
      "[11,     4] train loss: 0.663 train acc: 0.621\n",
      "[11,     5] train loss: 0.659 train acc: 0.602\n",
      "[11,     6] train loss: 0.673 train acc: 0.566\n",
      "[11,     7] train loss: 0.646 train acc: 0.621\n",
      "[11,     8] train loss: 0.672 train acc: 0.594\n",
      "[11,     9] train loss: 0.664 train acc: 0.590\n",
      "[11,    10] train loss: 0.654 train acc: 0.648\n",
      "[11,    11] train loss: 0.671 train acc: 0.586\n",
      "[11,    12] train loss: 0.676 train acc: 0.559\n",
      "[11,    13] train loss: 0.654 train acc: 0.629\n",
      "[11,    14] train loss: 0.699 train acc: 0.574\n",
      "[11,    15] train loss: 0.716 train acc: 0.512\n",
      "[11,    16] train loss: 0.651 train acc: 0.648\n",
      "[11,    17] train loss: 0.645 train acc: 0.652\n",
      "[11,    18] train loss: 0.698 train acc: 0.543\n",
      "[11,    19] train loss: 0.672 train acc: 0.598\n",
      "[11,    20] train loss: 0.654 train acc: 0.600\n",
      "[11] val loss: 0.673 val acc: 0.592\n",
      "[12,     1] train loss: 0.685 train acc: 0.555\n",
      "[12,     2] train loss: 0.674 train acc: 0.598\n",
      "[12,     3] train loss: 0.671 train acc: 0.582\n",
      "[12,     4] train loss: 0.672 train acc: 0.582\n",
      "[12,     5] train loss: 0.688 train acc: 0.512\n",
      "[12,     6] train loss: 0.655 train acc: 0.559\n",
      "[12,     7] train loss: 0.668 train acc: 0.590\n",
      "[12,     8] train loss: 0.674 train acc: 0.598\n",
      "[12,     9] train loss: 0.661 train acc: 0.598\n",
      "[12,    10] train loss: 0.672 train acc: 0.543\n",
      "[12,    11] train loss: 0.676 train acc: 0.598\n",
      "[12,    12] train loss: 0.663 train acc: 0.590\n",
      "[12,    13] train loss: 0.679 train acc: 0.598\n",
      "[12,    14] train loss: 0.648 train acc: 0.590\n",
      "[12,    15] train loss: 0.673 train acc: 0.590\n",
      "[12,    16] train loss: 0.654 train acc: 0.582\n",
      "[12,    17] train loss: 0.655 train acc: 0.598\n",
      "[12,    18] train loss: 0.657 train acc: 0.594\n",
      "[12,    19] train loss: 0.675 train acc: 0.617\n",
      "[12,    20] train loss: 0.668 train acc: 0.600\n",
      "[12] val loss: 0.658 val acc: 0.612\n",
      "[13,     1] train loss: 0.667 train acc: 0.594\n",
      "[13,     2] train loss: 0.639 train acc: 0.625\n",
      "[13,     3] train loss: 0.660 train acc: 0.594\n",
      "[13,     4] train loss: 0.666 train acc: 0.582\n",
      "[13,     5] train loss: 0.652 train acc: 0.582\n",
      "[13,     6] train loss: 0.660 train acc: 0.617\n",
      "[13,     7] train loss: 0.632 train acc: 0.609\n",
      "[13,     8] train loss: 0.705 train acc: 0.598\n",
      "[13,     9] train loss: 0.659 train acc: 0.621\n",
      "[13,    10] train loss: 0.666 train acc: 0.570\n",
      "[13,    11] train loss: 0.651 train acc: 0.617\n",
      "[13,    12] train loss: 0.680 train acc: 0.551\n",
      "[13,    13] train loss: 0.634 train acc: 0.637\n",
      "[13,    14] train loss: 0.673 train acc: 0.633\n",
      "[13,    15] train loss: 0.652 train acc: 0.621\n",
      "[13,    16] train loss: 0.653 train acc: 0.617\n",
      "[13,    17] train loss: 0.671 train acc: 0.594\n",
      "[13,    18] train loss: 0.664 train acc: 0.566\n",
      "[13,    19] train loss: 0.659 train acc: 0.598\n",
      "[13,    20] train loss: 0.610 train acc: 0.690\n",
      "[13] val loss: 0.651 val acc: 0.635\n",
      "[14,     1] train loss: 0.630 train acc: 0.652\n",
      "[14,     2] train loss: 0.673 train acc: 0.598\n",
      "[14,     3] train loss: 0.689 train acc: 0.562\n",
      "[14,     4] train loss: 0.668 train acc: 0.594\n",
      "[14,     5] train loss: 0.653 train acc: 0.598\n",
      "[14,     6] train loss: 0.666 train acc: 0.590\n",
      "[14,     7] train loss: 0.677 train acc: 0.559\n",
      "[14,     8] train loss: 0.644 train acc: 0.617\n",
      "[14,     9] train loss: 0.673 train acc: 0.586\n",
      "[14,    10] train loss: 0.658 train acc: 0.586\n",
      "[14,    11] train loss: 0.633 train acc: 0.617\n",
      "[14,    12] train loss: 0.646 train acc: 0.555\n",
      "[14,    13] train loss: 0.656 train acc: 0.594\n",
      "[14,    14] train loss: 0.670 train acc: 0.539\n",
      "[14,    15] train loss: 0.674 train acc: 0.594\n",
      "[14,    16] train loss: 0.632 train acc: 0.668\n",
      "[14,    17] train loss: 0.660 train acc: 0.602\n",
      "[14,    18] train loss: 0.646 train acc: 0.648\n",
      "[14,    19] train loss: 0.640 train acc: 0.641\n",
      "[14,    20] train loss: 0.684 train acc: 0.574\n",
      "[14] val loss: 0.649 val acc: 0.635\n",
      "[15,     1] train loss: 0.641 train acc: 0.621\n",
      "[15,     2] train loss: 0.631 train acc: 0.633\n",
      "[15,     3] train loss: 0.664 train acc: 0.570\n",
      "[15,     4] train loss: 0.665 train acc: 0.602\n",
      "[15,     5] train loss: 0.658 train acc: 0.613\n",
      "[15,     6] train loss: 0.653 train acc: 0.613\n",
      "[15,     7] train loss: 0.648 train acc: 0.625\n",
      "[15,     8] train loss: 0.647 train acc: 0.605\n",
      "[15,     9] train loss: 0.668 train acc: 0.570\n",
      "[15,    10] train loss: 0.624 train acc: 0.656\n",
      "[15,    11] train loss: 0.684 train acc: 0.586\n",
      "[15,    12] train loss: 0.660 train acc: 0.570\n",
      "[15,    13] train loss: 0.641 train acc: 0.641\n",
      "[15,    14] train loss: 0.652 train acc: 0.590\n",
      "[15,    15] train loss: 0.650 train acc: 0.605\n",
      "[15,    16] train loss: 0.657 train acc: 0.566\n",
      "[15,    17] train loss: 0.655 train acc: 0.590\n",
      "[15,    18] train loss: 0.628 train acc: 0.652\n",
      "[15,    19] train loss: 0.655 train acc: 0.605\n",
      "[15,    20] train loss: 0.654 train acc: 0.613\n",
      "[15] val loss: 0.649 val acc: 0.638\n",
      "[16,     1] train loss: 0.656 train acc: 0.637\n",
      "[16,     2] train loss: 0.633 train acc: 0.602\n",
      "[16,     3] train loss: 0.634 train acc: 0.641\n",
      "[16,     4] train loss: 0.634 train acc: 0.605\n",
      "[16,     5] train loss: 0.679 train acc: 0.586\n",
      "[16,     6] train loss: 0.664 train acc: 0.613\n",
      "[16,     7] train loss: 0.658 train acc: 0.602\n",
      "[16,     8] train loss: 0.589 train acc: 0.691\n",
      "[16,     9] train loss: 0.636 train acc: 0.648\n",
      "[16,    10] train loss: 0.662 train acc: 0.559\n",
      "[16,    11] train loss: 0.649 train acc: 0.598\n",
      "[16,    12] train loss: 0.679 train acc: 0.594\n",
      "[16,    13] train loss: 0.647 train acc: 0.602\n",
      "[16,    14] train loss: 0.628 train acc: 0.672\n",
      "[16,    15] train loss: 0.680 train acc: 0.570\n",
      "[16,    16] train loss: 0.620 train acc: 0.664\n",
      "[16,    17] train loss: 0.649 train acc: 0.656\n",
      "[16,    18] train loss: 0.661 train acc: 0.578\n",
      "[16,    19] train loss: 0.630 train acc: 0.629\n",
      "[16,    20] train loss: 0.637 train acc: 0.652\n",
      "[16] val loss: 0.646 val acc: 0.647\n",
      "[17,     1] train loss: 0.633 train acc: 0.633\n",
      "[17,     2] train loss: 0.638 train acc: 0.613\n",
      "[17,     3] train loss: 0.641 train acc: 0.652\n",
      "[17,     4] train loss: 0.666 train acc: 0.598\n",
      "[17,     5] train loss: 0.638 train acc: 0.648\n",
      "[17,     6] train loss: 0.645 train acc: 0.609\n",
      "[17,     7] train loss: 0.653 train acc: 0.613\n",
      "[17,     8] train loss: 0.659 train acc: 0.625\n",
      "[17,     9] train loss: 0.672 train acc: 0.621\n",
      "[17,    10] train loss: 0.630 train acc: 0.652\n",
      "[17,    11] train loss: 0.645 train acc: 0.633\n",
      "[17,    12] train loss: 0.640 train acc: 0.629\n",
      "[17,    13] train loss: 0.635 train acc: 0.629\n",
      "[17,    14] train loss: 0.666 train acc: 0.598\n",
      "[17,    15] train loss: 0.634 train acc: 0.629\n",
      "[17,    16] train loss: 0.667 train acc: 0.625\n",
      "[17,    17] train loss: 0.629 train acc: 0.633\n",
      "[17,    18] train loss: 0.663 train acc: 0.586\n",
      "[17,    19] train loss: 0.636 train acc: 0.621\n",
      "[17,    20] train loss: 0.636 train acc: 0.639\n",
      "[17] val loss: 0.636 val acc: 0.648\n",
      "[18,     1] train loss: 0.613 train acc: 0.684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18,     2] train loss: 0.641 train acc: 0.629\n",
      "[18,     3] train loss: 0.673 train acc: 0.586\n",
      "[18,     4] train loss: 0.646 train acc: 0.605\n",
      "[18,     5] train loss: 0.650 train acc: 0.621\n",
      "[18,     6] train loss: 0.651 train acc: 0.609\n",
      "[18,     7] train loss: 0.621 train acc: 0.660\n",
      "[18,     8] train loss: 0.632 train acc: 0.613\n",
      "[18,     9] train loss: 0.631 train acc: 0.668\n",
      "[18,    10] train loss: 0.653 train acc: 0.590\n",
      "[18,    11] train loss: 0.630 train acc: 0.676\n",
      "[18,    12] train loss: 0.649 train acc: 0.617\n",
      "[18,    13] train loss: 0.630 train acc: 0.602\n",
      "[18,    14] train loss: 0.643 train acc: 0.594\n",
      "[18,    15] train loss: 0.650 train acc: 0.621\n",
      "[18,    16] train loss: 0.636 train acc: 0.629\n",
      "[18,    17] train loss: 0.635 train acc: 0.605\n",
      "[18,    18] train loss: 0.642 train acc: 0.641\n",
      "[18,    19] train loss: 0.625 train acc: 0.645\n",
      "[18,    20] train loss: 0.696 train acc: 0.510\n",
      "[18] val loss: 0.640 val acc: 0.652\n",
      "[19,     1] train loss: 0.624 train acc: 0.633\n",
      "[19,     2] train loss: 0.623 train acc: 0.648\n",
      "[19,     3] train loss: 0.684 train acc: 0.578\n",
      "[19,     4] train loss: 0.649 train acc: 0.633\n",
      "[19,     5] train loss: 0.644 train acc: 0.633\n",
      "[19,     6] train loss: 0.642 train acc: 0.641\n",
      "[19,     7] train loss: 0.640 train acc: 0.641\n",
      "[19,     8] train loss: 0.665 train acc: 0.582\n",
      "[19,     9] train loss: 0.607 train acc: 0.645\n",
      "[19,    10] train loss: 0.640 train acc: 0.637\n",
      "[19,    11] train loss: 0.622 train acc: 0.590\n",
      "[19,    12] train loss: 0.647 train acc: 0.613\n",
      "[19,    13] train loss: 0.671 train acc: 0.613\n",
      "[19,    14] train loss: 0.688 train acc: 0.574\n",
      "[19,    15] train loss: 0.620 train acc: 0.648\n",
      "[19,    16] train loss: 0.711 train acc: 0.539\n",
      "[19,    17] train loss: 0.628 train acc: 0.652\n",
      "[19,    18] train loss: 0.648 train acc: 0.605\n",
      "[19,    19] train loss: 0.615 train acc: 0.668\n",
      "[19,    20] train loss: 0.650 train acc: 0.594\n",
      "[19] val loss: 0.646 val acc: 0.661\n",
      "[20,     1] train loss: 0.616 train acc: 0.652\n",
      "[20,     2] train loss: 0.636 train acc: 0.613\n",
      "[20,     3] train loss: 0.631 train acc: 0.621\n",
      "[20,     4] train loss: 0.658 train acc: 0.633\n",
      "[20,     5] train loss: 0.639 train acc: 0.648\n",
      "[20,     6] train loss: 0.625 train acc: 0.621\n",
      "[20,     7] train loss: 0.655 train acc: 0.602\n",
      "[20,     8] train loss: 0.663 train acc: 0.594\n",
      "[20,     9] train loss: 0.649 train acc: 0.590\n",
      "[20,    10] train loss: 0.605 train acc: 0.637\n",
      "[20,    11] train loss: 0.643 train acc: 0.656\n",
      "[20,    12] train loss: 0.649 train acc: 0.641\n",
      "[20,    13] train loss: 0.615 train acc: 0.656\n",
      "[20,    14] train loss: 0.613 train acc: 0.645\n",
      "[20,    15] train loss: 0.650 train acc: 0.598\n",
      "[20,    16] train loss: 0.639 train acc: 0.668\n",
      "[20,    17] train loss: 0.615 train acc: 0.633\n",
      "[20,    18] train loss: 0.639 train acc: 0.633\n",
      "[20,    19] train loss: 0.664 train acc: 0.602\n",
      "[20,    20] train loss: 0.627 train acc: 0.645\n",
      "[20] val loss: 0.628 val acc: 0.670\n",
      "[21,     1] train loss: 0.626 train acc: 0.629\n",
      "[21,     2] train loss: 0.630 train acc: 0.621\n",
      "[21,     3] train loss: 0.659 train acc: 0.625\n",
      "[21,     4] train loss: 0.647 train acc: 0.633\n",
      "[21,     5] train loss: 0.637 train acc: 0.637\n",
      "[21,     6] train loss: 0.630 train acc: 0.598\n",
      "[21,     7] train loss: 0.639 train acc: 0.633\n",
      "[21,     8] train loss: 0.593 train acc: 0.680\n",
      "[21,     9] train loss: 0.646 train acc: 0.590\n",
      "[21,    10] train loss: 0.610 train acc: 0.688\n",
      "[21,    11] train loss: 0.629 train acc: 0.641\n",
      "[21,    12] train loss: 0.664 train acc: 0.566\n",
      "[21,    13] train loss: 0.627 train acc: 0.625\n",
      "[21,    14] train loss: 0.576 train acc: 0.668\n",
      "[21,    15] train loss: 0.642 train acc: 0.629\n",
      "[21,    16] train loss: 0.609 train acc: 0.664\n",
      "[21,    17] train loss: 0.646 train acc: 0.598\n",
      "[21,    18] train loss: 0.662 train acc: 0.598\n",
      "[21,    19] train loss: 0.689 train acc: 0.594\n",
      "[21,    20] train loss: 0.671 train acc: 0.587\n",
      "[21] val loss: 0.628 val acc: 0.683\n",
      "[22,     1] train loss: 0.602 train acc: 0.684\n",
      "[22,     2] train loss: 0.630 train acc: 0.637\n",
      "[22,     3] train loss: 0.621 train acc: 0.629\n",
      "[22,     4] train loss: 0.636 train acc: 0.605\n",
      "[22,     5] train loss: 0.652 train acc: 0.621\n",
      "[22,     6] train loss: 0.636 train acc: 0.629\n",
      "[22,     7] train loss: 0.639 train acc: 0.609\n",
      "[22,     8] train loss: 0.624 train acc: 0.629\n",
      "[22,     9] train loss: 0.615 train acc: 0.664\n",
      "[22,    10] train loss: 0.626 train acc: 0.609\n",
      "[22,    11] train loss: 0.614 train acc: 0.664\n",
      "[22,    12] train loss: 0.617 train acc: 0.656\n",
      "[22,    13] train loss: 0.634 train acc: 0.641\n",
      "[22,    14] train loss: 0.639 train acc: 0.605\n",
      "[22,    15] train loss: 0.598 train acc: 0.688\n",
      "[22,    16] train loss: 0.619 train acc: 0.641\n",
      "[22,    17] train loss: 0.607 train acc: 0.664\n",
      "[22,    18] train loss: 0.635 train acc: 0.617\n",
      "[22,    19] train loss: 0.668 train acc: 0.641\n",
      "[22,    20] train loss: 0.597 train acc: 0.671\n",
      "[22] val loss: 0.618 val acc: 0.681\n",
      "[23,     1] train loss: 0.644 train acc: 0.621\n",
      "[23,     2] train loss: 0.651 train acc: 0.609\n",
      "[23,     3] train loss: 0.600 train acc: 0.668\n",
      "[23,     4] train loss: 0.653 train acc: 0.633\n",
      "[23,     5] train loss: 0.614 train acc: 0.668\n",
      "[23,     6] train loss: 0.605 train acc: 0.652\n",
      "[23,     7] train loss: 0.596 train acc: 0.668\n",
      "[23,     8] train loss: 0.614 train acc: 0.676\n",
      "[23,     9] train loss: 0.623 train acc: 0.637\n",
      "[23,    10] train loss: 0.667 train acc: 0.645\n",
      "[23,    11] train loss: 0.609 train acc: 0.703\n",
      "[23,    12] train loss: 0.636 train acc: 0.625\n",
      "[23,    13] train loss: 0.620 train acc: 0.637\n",
      "[23,    14] train loss: 0.592 train acc: 0.660\n",
      "[23,    15] train loss: 0.630 train acc: 0.656\n",
      "[23,    16] train loss: 0.605 train acc: 0.688\n",
      "[23,    17] train loss: 0.660 train acc: 0.633\n",
      "[23,    18] train loss: 0.628 train acc: 0.621\n",
      "[23,    19] train loss: 0.596 train acc: 0.645\n",
      "[23,    20] train loss: 0.607 train acc: 0.710\n",
      "[23] val loss: 0.619 val acc: 0.685\n",
      "[24,     1] train loss: 0.600 train acc: 0.660\n",
      "[24,     2] train loss: 0.580 train acc: 0.703\n",
      "[24,     3] train loss: 0.671 train acc: 0.598\n",
      "[24,     4] train loss: 0.631 train acc: 0.664\n",
      "[24,     5] train loss: 0.628 train acc: 0.605\n",
      "[24,     6] train loss: 0.629 train acc: 0.645\n",
      "[24,     7] train loss: 0.618 train acc: 0.637\n",
      "[24,     8] train loss: 0.660 train acc: 0.594\n",
      "[24,     9] train loss: 0.607 train acc: 0.664\n",
      "[24,    10] train loss: 0.620 train acc: 0.664\n",
      "[24,    11] train loss: 0.601 train acc: 0.656\n",
      "[24,    12] train loss: 0.597 train acc: 0.672\n",
      "[24,    13] train loss: 0.624 train acc: 0.605\n",
      "[24,    14] train loss: 0.657 train acc: 0.602\n",
      "[24,    15] train loss: 0.585 train acc: 0.691\n",
      "[24,    16] train loss: 0.657 train acc: 0.645\n",
      "[24,    17] train loss: 0.657 train acc: 0.625\n",
      "[24,    18] train loss: 0.610 train acc: 0.656\n",
      "[24,    19] train loss: 0.625 train acc: 0.652\n",
      "[24,    20] train loss: 0.613 train acc: 0.684\n",
      "[24] val loss: 0.625 val acc: 0.680\n",
      "[25,     1] train loss: 0.636 train acc: 0.590\n",
      "[25,     2] train loss: 0.644 train acc: 0.648\n",
      "[25,     3] train loss: 0.623 train acc: 0.645\n",
      "[25,     4] train loss: 0.595 train acc: 0.691\n",
      "[25,     5] train loss: 0.604 train acc: 0.680\n",
      "[25,     6] train loss: 0.632 train acc: 0.633\n",
      "[25,     7] train loss: 0.639 train acc: 0.613\n",
      "[25,     8] train loss: 0.606 train acc: 0.672\n",
      "[25,     9] train loss: 0.668 train acc: 0.602\n",
      "[25,    10] train loss: 0.600 train acc: 0.676\n",
      "[25,    11] train loss: 0.618 train acc: 0.641\n",
      "[25,    12] train loss: 0.636 train acc: 0.668\n",
      "[25,    13] train loss: 0.619 train acc: 0.633\n",
      "[25,    14] train loss: 0.586 train acc: 0.656\n",
      "[25,    15] train loss: 0.623 train acc: 0.641\n",
      "[25,    16] train loss: 0.625 train acc: 0.621\n",
      "[25,    17] train loss: 0.615 train acc: 0.648\n",
      "[25,    18] train loss: 0.628 train acc: 0.633\n",
      "[25,    19] train loss: 0.610 train acc: 0.648\n",
      "[25,    20] train loss: 0.615 train acc: 0.626\n",
      "[25] val loss: 0.611 val acc: 0.694\n",
      "[26,     1] train loss: 0.628 train acc: 0.633\n",
      "[26,     2] train loss: 0.615 train acc: 0.672\n",
      "[26,     3] train loss: 0.644 train acc: 0.641\n",
      "[26,     4] train loss: 0.657 train acc: 0.621\n",
      "[26,     5] train loss: 0.613 train acc: 0.672\n",
      "[26,     6] train loss: 0.608 train acc: 0.637\n",
      "[26,     7] train loss: 0.631 train acc: 0.633\n",
      "[26,     8] train loss: 0.628 train acc: 0.605\n",
      "[26,     9] train loss: 0.606 train acc: 0.656\n",
      "[26,    10] train loss: 0.614 train acc: 0.613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26,    11] train loss: 0.613 train acc: 0.645\n",
      "[26,    12] train loss: 0.657 train acc: 0.613\n",
      "[26,    13] train loss: 0.604 train acc: 0.645\n",
      "[26,    14] train loss: 0.622 train acc: 0.656\n",
      "[26,    15] train loss: 0.588 train acc: 0.664\n",
      "[26,    16] train loss: 0.626 train acc: 0.621\n",
      "[26,    17] train loss: 0.638 train acc: 0.656\n",
      "[26,    18] train loss: 0.610 train acc: 0.656\n",
      "[26,    19] train loss: 0.640 train acc: 0.668\n",
      "[26,    20] train loss: 0.601 train acc: 0.703\n",
      "[26] val loss: 0.610 val acc: 0.691\n",
      "[27,     1] train loss: 0.621 train acc: 0.641\n",
      "[27,     2] train loss: 0.602 train acc: 0.695\n",
      "[27,     3] train loss: 0.609 train acc: 0.664\n",
      "[27,     4] train loss: 0.598 train acc: 0.645\n",
      "[27,     5] train loss: 0.599 train acc: 0.699\n",
      "[27,     6] train loss: 0.610 train acc: 0.668\n",
      "[27,     7] train loss: 0.636 train acc: 0.637\n",
      "[27,     8] train loss: 0.590 train acc: 0.641\n",
      "[27,     9] train loss: 0.612 train acc: 0.641\n",
      "[27,    10] train loss: 0.644 train acc: 0.605\n",
      "[27,    11] train loss: 0.599 train acc: 0.660\n",
      "[27,    12] train loss: 0.611 train acc: 0.668\n",
      "[27,    13] train loss: 0.602 train acc: 0.633\n",
      "[27,    14] train loss: 0.589 train acc: 0.660\n",
      "[27,    15] train loss: 0.610 train acc: 0.648\n",
      "[27,    16] train loss: 0.586 train acc: 0.723\n",
      "[27,    17] train loss: 0.617 train acc: 0.648\n",
      "[27,    18] train loss: 0.612 train acc: 0.641\n",
      "[27,    19] train loss: 0.589 train acc: 0.656\n",
      "[27,    20] train loss: 0.607 train acc: 0.658\n",
      "[27] val loss: 0.598 val acc: 0.704\n",
      "[28,     1] train loss: 0.642 train acc: 0.598\n",
      "[28,     2] train loss: 0.615 train acc: 0.656\n",
      "[28,     3] train loss: 0.633 train acc: 0.648\n",
      "[28,     4] train loss: 0.627 train acc: 0.641\n",
      "[28,     5] train loss: 0.610 train acc: 0.664\n",
      "[28,     6] train loss: 0.598 train acc: 0.656\n",
      "[28,     7] train loss: 0.608 train acc: 0.637\n",
      "[28,     8] train loss: 0.612 train acc: 0.695\n",
      "[28,     9] train loss: 0.617 train acc: 0.668\n",
      "[28,    10] train loss: 0.611 train acc: 0.645\n",
      "[28,    11] train loss: 0.611 train acc: 0.648\n",
      "[28,    12] train loss: 0.598 train acc: 0.664\n",
      "[28,    13] train loss: 0.605 train acc: 0.676\n",
      "[28,    14] train loss: 0.600 train acc: 0.664\n",
      "[28,    15] train loss: 0.608 train acc: 0.641\n",
      "[28,    16] train loss: 0.533 train acc: 0.727\n",
      "[28,    17] train loss: 0.606 train acc: 0.699\n",
      "[28,    18] train loss: 0.633 train acc: 0.660\n",
      "[28,    19] train loss: 0.624 train acc: 0.613\n",
      "[28,    20] train loss: 0.611 train acc: 0.671\n",
      "[28] val loss: 0.597 val acc: 0.706\n",
      "[29,     1] train loss: 0.555 train acc: 0.680\n",
      "[29,     2] train loss: 0.623 train acc: 0.637\n",
      "[29,     3] train loss: 0.608 train acc: 0.637\n",
      "[29,     4] train loss: 0.613 train acc: 0.656\n",
      "[29,     5] train loss: 0.599 train acc: 0.684\n",
      "[29,     6] train loss: 0.643 train acc: 0.656\n",
      "[29,     7] train loss: 0.613 train acc: 0.645\n",
      "[29,     8] train loss: 0.628 train acc: 0.645\n",
      "[29,     9] train loss: 0.595 train acc: 0.699\n",
      "[29,    10] train loss: 0.580 train acc: 0.652\n",
      "[29,    11] train loss: 0.586 train acc: 0.684\n",
      "[29,    12] train loss: 0.587 train acc: 0.680\n",
      "[29,    13] train loss: 0.597 train acc: 0.676\n",
      "[29,    14] train loss: 0.584 train acc: 0.688\n",
      "[29,    15] train loss: 0.631 train acc: 0.656\n",
      "[29,    16] train loss: 0.597 train acc: 0.652\n",
      "[29,    17] train loss: 0.583 train acc: 0.680\n",
      "[29,    18] train loss: 0.572 train acc: 0.707\n",
      "[29,    19] train loss: 0.590 train acc: 0.680\n",
      "[29,    20] train loss: 0.576 train acc: 0.703\n",
      "[29] val loss: 0.587 val acc: 0.723\n",
      "[30,     1] train loss: 0.604 train acc: 0.625\n",
      "[30,     2] train loss: 0.626 train acc: 0.656\n",
      "[30,     3] train loss: 0.577 train acc: 0.691\n",
      "[30,     4] train loss: 0.630 train acc: 0.703\n",
      "[30,     5] train loss: 0.586 train acc: 0.688\n",
      "[30,     6] train loss: 0.590 train acc: 0.664\n",
      "[30,     7] train loss: 0.563 train acc: 0.723\n",
      "[30,     8] train loss: 0.608 train acc: 0.664\n",
      "[30,     9] train loss: 0.578 train acc: 0.680\n",
      "[30,    10] train loss: 0.657 train acc: 0.617\n",
      "[30,    11] train loss: 0.626 train acc: 0.641\n",
      "[30,    12] train loss: 0.580 train acc: 0.648\n",
      "[30,    13] train loss: 0.631 train acc: 0.637\n",
      "[30,    14] train loss: 0.605 train acc: 0.699\n",
      "[30,    15] train loss: 0.594 train acc: 0.652\n",
      "[30,    16] train loss: 0.563 train acc: 0.711\n",
      "[30,    17] train loss: 0.564 train acc: 0.691\n",
      "[30,    18] train loss: 0.619 train acc: 0.660\n",
      "[30,    19] train loss: 0.624 train acc: 0.652\n",
      "[30,    20] train loss: 0.576 train acc: 0.710\n",
      "[30] val loss: 0.592 val acc: 0.712\n",
      "[31,     1] train loss: 0.556 train acc: 0.684\n",
      "[31,     2] train loss: 0.627 train acc: 0.668\n",
      "[31,     3] train loss: 0.605 train acc: 0.656\n",
      "[31,     4] train loss: 0.562 train acc: 0.691\n",
      "[31,     5] train loss: 0.610 train acc: 0.648\n",
      "[31,     6] train loss: 0.610 train acc: 0.645\n",
      "[31,     7] train loss: 0.581 train acc: 0.680\n",
      "[31,     8] train loss: 0.633 train acc: 0.652\n",
      "[31,     9] train loss: 0.559 train acc: 0.707\n",
      "[31,    10] train loss: 0.591 train acc: 0.703\n",
      "[31,    11] train loss: 0.610 train acc: 0.629\n",
      "[31,    12] train loss: 0.633 train acc: 0.617\n",
      "[31,    13] train loss: 0.626 train acc: 0.652\n",
      "[31,    14] train loss: 0.640 train acc: 0.605\n",
      "[31,    15] train loss: 0.577 train acc: 0.695\n",
      "[31,    16] train loss: 0.603 train acc: 0.680\n",
      "[31,    17] train loss: 0.615 train acc: 0.688\n",
      "[31,    18] train loss: 0.634 train acc: 0.621\n",
      "[31,    19] train loss: 0.594 train acc: 0.691\n",
      "[31,    20] train loss: 0.597 train acc: 0.639\n",
      "[31] val loss: 0.593 val acc: 0.723\n",
      "[32,     1] train loss: 0.577 train acc: 0.723\n",
      "[32,     2] train loss: 0.627 train acc: 0.652\n",
      "[32,     3] train loss: 0.598 train acc: 0.672\n",
      "[32,     4] train loss: 0.594 train acc: 0.660\n",
      "[32,     5] train loss: 0.612 train acc: 0.703\n",
      "[32,     6] train loss: 0.573 train acc: 0.688\n",
      "[32,     7] train loss: 0.658 train acc: 0.586\n",
      "[32,     8] train loss: 0.590 train acc: 0.707\n",
      "[32,     9] train loss: 0.566 train acc: 0.688\n",
      "[32,    10] train loss: 0.624 train acc: 0.645\n",
      "[32,    11] train loss: 0.604 train acc: 0.668\n",
      "[32,    12] train loss: 0.554 train acc: 0.727\n",
      "[32,    13] train loss: 0.605 train acc: 0.648\n",
      "[32,    14] train loss: 0.605 train acc: 0.660\n",
      "[32,    15] train loss: 0.581 train acc: 0.680\n",
      "[32,    16] train loss: 0.603 train acc: 0.691\n",
      "[32,    17] train loss: 0.614 train acc: 0.633\n",
      "[32,    18] train loss: 0.567 train acc: 0.734\n",
      "[32,    19] train loss: 0.598 train acc: 0.656\n",
      "[32,    20] train loss: 0.647 train acc: 0.613\n",
      "[32] val loss: 0.586 val acc: 0.721\n",
      "[33,     1] train loss: 0.633 train acc: 0.652\n",
      "[33,     2] train loss: 0.590 train acc: 0.660\n",
      "[33,     3] train loss: 0.562 train acc: 0.715\n",
      "[33,     4] train loss: 0.606 train acc: 0.660\n",
      "[33,     5] train loss: 0.621 train acc: 0.637\n",
      "[33,     6] train loss: 0.629 train acc: 0.633\n",
      "[33,     7] train loss: 0.606 train acc: 0.645\n",
      "[33,     8] train loss: 0.582 train acc: 0.684\n",
      "[33,     9] train loss: 0.571 train acc: 0.727\n",
      "[33,    10] train loss: 0.613 train acc: 0.672\n",
      "[33,    11] train loss: 0.583 train acc: 0.672\n",
      "[33,    12] train loss: 0.611 train acc: 0.664\n",
      "[33,    13] train loss: 0.558 train acc: 0.684\n",
      "[33,    14] train loss: 0.574 train acc: 0.703\n",
      "[33,    15] train loss: 0.610 train acc: 0.668\n",
      "[33,    16] train loss: 0.574 train acc: 0.668\n",
      "[33,    17] train loss: 0.632 train acc: 0.645\n",
      "[33,    18] train loss: 0.612 train acc: 0.648\n",
      "[33,    19] train loss: 0.599 train acc: 0.672\n",
      "[33,    20] train loss: 0.645 train acc: 0.581\n",
      "[33] val loss: 0.583 val acc: 0.734\n",
      "[34,     1] train loss: 0.585 train acc: 0.684\n",
      "[34,     2] train loss: 0.610 train acc: 0.652\n",
      "[34,     3] train loss: 0.580 train acc: 0.664\n",
      "[34,     4] train loss: 0.625 train acc: 0.648\n",
      "[34,     5] train loss: 0.600 train acc: 0.648\n",
      "[34,     6] train loss: 0.589 train acc: 0.719\n",
      "[34,     7] train loss: 0.551 train acc: 0.715\n",
      "[34,     8] train loss: 0.578 train acc: 0.672\n",
      "[34,     9] train loss: 0.593 train acc: 0.668\n",
      "[34,    10] train loss: 0.561 train acc: 0.703\n",
      "[34,    11] train loss: 0.607 train acc: 0.637\n",
      "[34,    12] train loss: 0.572 train acc: 0.652\n",
      "[34,    13] train loss: 0.657 train acc: 0.629\n",
      "[34,    14] train loss: 0.605 train acc: 0.637\n",
      "[34,    15] train loss: 0.555 train acc: 0.711\n",
      "[34,    16] train loss: 0.599 train acc: 0.688\n",
      "[34,    17] train loss: 0.578 train acc: 0.680\n",
      "[34,    18] train loss: 0.627 train acc: 0.645\n",
      "[34,    19] train loss: 0.608 train acc: 0.668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34,    20] train loss: 0.566 train acc: 0.723\n",
      "[34] val loss: 0.575 val acc: 0.727\n",
      "[35,     1] train loss: 0.635 train acc: 0.637\n",
      "[35,     2] train loss: 0.598 train acc: 0.641\n",
      "[35,     3] train loss: 0.633 train acc: 0.660\n",
      "[35,     4] train loss: 0.591 train acc: 0.691\n",
      "[35,     5] train loss: 0.581 train acc: 0.664\n",
      "[35,     6] train loss: 0.591 train acc: 0.703\n",
      "[35,     7] train loss: 0.562 train acc: 0.699\n",
      "[35,     8] train loss: 0.591 train acc: 0.637\n",
      "[35,     9] train loss: 0.564 train acc: 0.680\n",
      "[35,    10] train loss: 0.585 train acc: 0.699\n",
      "[35,    11] train loss: 0.587 train acc: 0.688\n",
      "[35,    12] train loss: 0.579 train acc: 0.672\n",
      "[35,    13] train loss: 0.593 train acc: 0.699\n",
      "[35,    14] train loss: 0.562 train acc: 0.680\n",
      "[35,    15] train loss: 0.555 train acc: 0.699\n",
      "[35,    16] train loss: 0.645 train acc: 0.641\n",
      "[35,    17] train loss: 0.588 train acc: 0.688\n",
      "[35,    18] train loss: 0.593 train acc: 0.648\n",
      "[35,    19] train loss: 0.572 train acc: 0.703\n",
      "[35,    20] train loss: 0.558 train acc: 0.697\n",
      "[35] val loss: 0.565 val acc: 0.743\n",
      "[36,     1] train loss: 0.569 train acc: 0.684\n",
      "[36,     2] train loss: 0.601 train acc: 0.668\n",
      "[36,     3] train loss: 0.573 train acc: 0.703\n",
      "[36,     4] train loss: 0.577 train acc: 0.723\n",
      "[36,     5] train loss: 0.562 train acc: 0.664\n",
      "[36,     6] train loss: 0.547 train acc: 0.707\n",
      "[36,     7] train loss: 0.567 train acc: 0.723\n",
      "[36,     8] train loss: 0.585 train acc: 0.688\n",
      "[36,     9] train loss: 0.570 train acc: 0.656\n",
      "[36,    10] train loss: 0.666 train acc: 0.617\n",
      "[36,    11] train loss: 0.580 train acc: 0.695\n",
      "[36,    12] train loss: 0.604 train acc: 0.707\n",
      "[36,    13] train loss: 0.591 train acc: 0.707\n",
      "[36,    14] train loss: 0.576 train acc: 0.680\n",
      "[36,    15] train loss: 0.573 train acc: 0.695\n",
      "[36,    16] train loss: 0.589 train acc: 0.660\n",
      "[36,    17] train loss: 0.553 train acc: 0.723\n",
      "[36,    18] train loss: 0.600 train acc: 0.660\n",
      "[36,    19] train loss: 0.603 train acc: 0.625\n",
      "[36,    20] train loss: 0.591 train acc: 0.632\n",
      "[36] val loss: 0.574 val acc: 0.739\n",
      "[37,     1] train loss: 0.597 train acc: 0.645\n",
      "[37,     2] train loss: 0.632 train acc: 0.633\n",
      "[37,     3] train loss: 0.583 train acc: 0.684\n",
      "[37,     4] train loss: 0.561 train acc: 0.691\n",
      "[37,     5] train loss: 0.580 train acc: 0.680\n",
      "[37,     6] train loss: 0.581 train acc: 0.691\n",
      "[37,     7] train loss: 0.593 train acc: 0.656\n",
      "[37,     8] train loss: 0.607 train acc: 0.656\n",
      "[37,     9] train loss: 0.560 train acc: 0.734\n",
      "[37,    10] train loss: 0.583 train acc: 0.723\n",
      "[37,    11] train loss: 0.605 train acc: 0.691\n",
      "[37,    12] train loss: 0.592 train acc: 0.664\n",
      "[37,    13] train loss: 0.578 train acc: 0.707\n",
      "[37,    14] train loss: 0.518 train acc: 0.727\n",
      "[37,    15] train loss: 0.567 train acc: 0.699\n",
      "[37,    16] train loss: 0.560 train acc: 0.684\n",
      "[37,    17] train loss: 0.571 train acc: 0.684\n",
      "[37,    18] train loss: 0.590 train acc: 0.691\n",
      "[37,    19] train loss: 0.570 train acc: 0.688\n",
      "[37,    20] train loss: 0.512 train acc: 0.690\n",
      "[37] val loss: 0.548 val acc: 0.747\n",
      "[38,     1] train loss: 0.544 train acc: 0.676\n",
      "[38,     2] train loss: 0.538 train acc: 0.707\n",
      "[38,     3] train loss: 0.566 train acc: 0.691\n",
      "[38,     4] train loss: 0.567 train acc: 0.688\n",
      "[38,     5] train loss: 0.565 train acc: 0.734\n",
      "[38,     6] train loss: 0.538 train acc: 0.711\n",
      "[38,     7] train loss: 0.633 train acc: 0.699\n",
      "[38,     8] train loss: 0.569 train acc: 0.730\n",
      "[38,     9] train loss: 0.594 train acc: 0.715\n",
      "[38,    10] train loss: 0.569 train acc: 0.680\n",
      "[38,    11] train loss: 0.610 train acc: 0.664\n",
      "[38,    12] train loss: 0.601 train acc: 0.637\n",
      "[38,    13] train loss: 0.637 train acc: 0.629\n",
      "[38,    14] train loss: 0.577 train acc: 0.695\n",
      "[38,    15] train loss: 0.594 train acc: 0.680\n",
      "[38,    16] train loss: 0.604 train acc: 0.648\n",
      "[38,    17] train loss: 0.592 train acc: 0.668\n",
      "[38,    18] train loss: 0.559 train acc: 0.684\n",
      "[38,    19] train loss: 0.618 train acc: 0.609\n",
      "[38,    20] train loss: 0.544 train acc: 0.710\n",
      "[38] val loss: 0.570 val acc: 0.749\n",
      "[39,     1] train loss: 0.575 train acc: 0.672\n",
      "[39,     2] train loss: 0.596 train acc: 0.680\n",
      "[39,     3] train loss: 0.518 train acc: 0.711\n",
      "[39,     4] train loss: 0.628 train acc: 0.652\n",
      "[39,     5] train loss: 0.551 train acc: 0.734\n",
      "[39,     6] train loss: 0.548 train acc: 0.691\n",
      "[39,     7] train loss: 0.623 train acc: 0.641\n",
      "[39,     8] train loss: 0.621 train acc: 0.641\n",
      "[39,     9] train loss: 0.583 train acc: 0.691\n",
      "[39,    10] train loss: 0.535 train acc: 0.719\n",
      "[39,    11] train loss: 0.605 train acc: 0.664\n",
      "[39,    12] train loss: 0.559 train acc: 0.691\n",
      "[39,    13] train loss: 0.539 train acc: 0.723\n",
      "[39,    14] train loss: 0.562 train acc: 0.691\n",
      "[39,    15] train loss: 0.596 train acc: 0.668\n",
      "[39,    16] train loss: 0.567 train acc: 0.703\n",
      "[39,    17] train loss: 0.543 train acc: 0.699\n",
      "[39,    18] train loss: 0.603 train acc: 0.680\n",
      "[39,    19] train loss: 0.565 train acc: 0.672\n",
      "[39,    20] train loss: 0.561 train acc: 0.716\n",
      "[39] val loss: 0.563 val acc: 0.761\n",
      "[40,     1] train loss: 0.639 train acc: 0.637\n",
      "[40,     2] train loss: 0.560 train acc: 0.691\n",
      "[40,     3] train loss: 0.568 train acc: 0.703\n",
      "[40,     4] train loss: 0.574 train acc: 0.676\n",
      "[40,     5] train loss: 0.562 train acc: 0.703\n",
      "[40,     6] train loss: 0.548 train acc: 0.703\n",
      "[40,     7] train loss: 0.587 train acc: 0.699\n",
      "[40,     8] train loss: 0.567 train acc: 0.699\n",
      "[40,     9] train loss: 0.545 train acc: 0.691\n",
      "[40,    10] train loss: 0.568 train acc: 0.691\n",
      "[40,    11] train loss: 0.560 train acc: 0.676\n",
      "[40,    12] train loss: 0.580 train acc: 0.684\n",
      "[40,    13] train loss: 0.585 train acc: 0.695\n",
      "[40,    14] train loss: 0.634 train acc: 0.648\n",
      "[40,    15] train loss: 0.633 train acc: 0.668\n",
      "[40,    16] train loss: 0.531 train acc: 0.738\n",
      "[40,    17] train loss: 0.553 train acc: 0.691\n",
      "[40,    18] train loss: 0.551 train acc: 0.707\n",
      "[40,    19] train loss: 0.531 train acc: 0.711\n",
      "[40,    20] train loss: 0.583 train acc: 0.690\n",
      "[40] val loss: 0.552 val acc: 0.776\n",
      "[41,     1] train loss: 0.594 train acc: 0.680\n",
      "[41,     2] train loss: 0.587 train acc: 0.676\n",
      "[41,     3] train loss: 0.597 train acc: 0.688\n",
      "[41,     4] train loss: 0.565 train acc: 0.703\n",
      "[41,     5] train loss: 0.557 train acc: 0.723\n",
      "[41,     6] train loss: 0.552 train acc: 0.707\n",
      "[41,     7] train loss: 0.538 train acc: 0.699\n",
      "[41,     8] train loss: 0.516 train acc: 0.719\n",
      "[41,     9] train loss: 0.592 train acc: 0.680\n",
      "[41,    10] train loss: 0.606 train acc: 0.672\n",
      "[41,    11] train loss: 0.543 train acc: 0.738\n",
      "[41,    12] train loss: 0.603 train acc: 0.637\n",
      "[41,    13] train loss: 0.567 train acc: 0.680\n",
      "[41,    14] train loss: 0.525 train acc: 0.742\n",
      "[41,    15] train loss: 0.549 train acc: 0.707\n",
      "[41,    16] train loss: 0.545 train acc: 0.738\n",
      "[41,    17] train loss: 0.602 train acc: 0.664\n",
      "[41,    18] train loss: 0.548 train acc: 0.719\n",
      "[41,    19] train loss: 0.546 train acc: 0.723\n",
      "[41,    20] train loss: 0.541 train acc: 0.690\n",
      "[41] val loss: 0.544 val acc: 0.783\n",
      "[42,     1] train loss: 0.575 train acc: 0.723\n",
      "[42,     2] train loss: 0.552 train acc: 0.719\n",
      "[42,     3] train loss: 0.597 train acc: 0.691\n",
      "[42,     4] train loss: 0.538 train acc: 0.699\n",
      "[42,     5] train loss: 0.532 train acc: 0.723\n",
      "[42,     6] train loss: 0.528 train acc: 0.734\n",
      "[42,     7] train loss: 0.569 train acc: 0.703\n",
      "[42,     8] train loss: 0.541 train acc: 0.715\n",
      "[42,     9] train loss: 0.541 train acc: 0.711\n",
      "[42,    10] train loss: 0.634 train acc: 0.613\n",
      "[42,    11] train loss: 0.576 train acc: 0.699\n",
      "[42,    12] train loss: 0.564 train acc: 0.715\n",
      "[42,    13] train loss: 0.549 train acc: 0.699\n",
      "[42,    14] train loss: 0.513 train acc: 0.750\n",
      "[42,    15] train loss: 0.613 train acc: 0.699\n",
      "[42,    16] train loss: 0.558 train acc: 0.711\n",
      "[42,    17] train loss: 0.541 train acc: 0.730\n",
      "[42,    18] train loss: 0.554 train acc: 0.672\n",
      "[42,    19] train loss: 0.532 train acc: 0.711\n",
      "[42,    20] train loss: 0.491 train acc: 0.755\n",
      "[42] val loss: 0.537 val acc: 0.786\n",
      "[43,     1] train loss: 0.586 train acc: 0.676\n",
      "[43,     2] train loss: 0.557 train acc: 0.684\n",
      "[43,     3] train loss: 0.622 train acc: 0.652\n",
      "[43,     4] train loss: 0.570 train acc: 0.684\n",
      "[43,     5] train loss: 0.580 train acc: 0.664\n",
      "[43,     6] train loss: 0.591 train acc: 0.680\n",
      "[43,     7] train loss: 0.574 train acc: 0.688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43,     8] train loss: 0.552 train acc: 0.734\n",
      "[43,     9] train loss: 0.573 train acc: 0.680\n",
      "[43,    10] train loss: 0.548 train acc: 0.730\n",
      "[43,    11] train loss: 0.555 train acc: 0.746\n",
      "[43,    12] train loss: 0.562 train acc: 0.707\n",
      "[43,    13] train loss: 0.571 train acc: 0.688\n",
      "[43,    14] train loss: 0.559 train acc: 0.734\n",
      "[43,    15] train loss: 0.534 train acc: 0.738\n",
      "[43,    16] train loss: 0.584 train acc: 0.723\n",
      "[43,    17] train loss: 0.535 train acc: 0.707\n",
      "[43,    18] train loss: 0.557 train acc: 0.699\n",
      "[43,    19] train loss: 0.577 train acc: 0.688\n",
      "[43,    20] train loss: 0.528 train acc: 0.748\n",
      "[43] val loss: 0.528 val acc: 0.785\n",
      "[44,     1] train loss: 0.565 train acc: 0.715\n",
      "[44,     2] train loss: 0.484 train acc: 0.758\n",
      "[44,     3] train loss: 0.569 train acc: 0.727\n",
      "[44,     4] train loss: 0.585 train acc: 0.699\n",
      "[44,     5] train loss: 0.545 train acc: 0.703\n",
      "[44,     6] train loss: 0.512 train acc: 0.746\n",
      "[44,     7] train loss: 0.531 train acc: 0.754\n",
      "[44,     8] train loss: 0.572 train acc: 0.684\n",
      "[44,     9] train loss: 0.552 train acc: 0.715\n",
      "[44,    10] train loss: 0.532 train acc: 0.734\n",
      "[44,    11] train loss: 0.551 train acc: 0.684\n",
      "[44,    12] train loss: 0.533 train acc: 0.762\n",
      "[44,    13] train loss: 0.603 train acc: 0.660\n",
      "[44,    14] train loss: 0.521 train acc: 0.711\n",
      "[44,    15] train loss: 0.565 train acc: 0.715\n",
      "[44,    16] train loss: 0.531 train acc: 0.719\n",
      "[44,    17] train loss: 0.534 train acc: 0.695\n",
      "[44,    18] train loss: 0.530 train acc: 0.707\n",
      "[44,    19] train loss: 0.547 train acc: 0.707\n",
      "[44,    20] train loss: 0.535 train acc: 0.710\n",
      "[44] val loss: 0.526 val acc: 0.798\n",
      "[45,     1] train loss: 0.533 train acc: 0.719\n",
      "[45,     2] train loss: 0.572 train acc: 0.688\n",
      "[45,     3] train loss: 0.560 train acc: 0.707\n",
      "[45,     4] train loss: 0.558 train acc: 0.707\n",
      "[45,     5] train loss: 0.527 train acc: 0.715\n",
      "[45,     6] train loss: 0.517 train acc: 0.746\n",
      "[45,     7] train loss: 0.505 train acc: 0.738\n",
      "[45,     8] train loss: 0.546 train acc: 0.727\n",
      "[45,     9] train loss: 0.499 train acc: 0.773\n",
      "[45,    10] train loss: 0.563 train acc: 0.707\n",
      "[45,    11] train loss: 0.586 train acc: 0.707\n",
      "[45,    12] train loss: 0.589 train acc: 0.652\n",
      "[45,    13] train loss: 0.599 train acc: 0.688\n",
      "[45,    14] train loss: 0.521 train acc: 0.727\n",
      "[45,    15] train loss: 0.637 train acc: 0.656\n",
      "[45,    16] train loss: 0.556 train acc: 0.711\n",
      "[45,    17] train loss: 0.521 train acc: 0.762\n",
      "[45,    18] train loss: 0.582 train acc: 0.691\n",
      "[45,    19] train loss: 0.555 train acc: 0.703\n",
      "[45,    20] train loss: 0.533 train acc: 0.761\n",
      "[45] val loss: 0.547 val acc: 0.772\n",
      "[46,     1] train loss: 0.637 train acc: 0.645\n",
      "[46,     2] train loss: 0.589 train acc: 0.660\n",
      "[46,     3] train loss: 0.535 train acc: 0.703\n",
      "[46,     4] train loss: 0.544 train acc: 0.719\n",
      "[46,     5] train loss: 0.551 train acc: 0.691\n",
      "[46,     6] train loss: 0.535 train acc: 0.703\n",
      "[46,     7] train loss: 0.551 train acc: 0.719\n",
      "[46,     8] train loss: 0.575 train acc: 0.680\n",
      "[46,     9] train loss: 0.537 train acc: 0.730\n",
      "[46,    10] train loss: 0.512 train acc: 0.707\n",
      "[46,    11] train loss: 0.548 train acc: 0.711\n",
      "[46,    12] train loss: 0.535 train acc: 0.723\n",
      "[46,    13] train loss: 0.612 train acc: 0.648\n",
      "[46,    14] train loss: 0.537 train acc: 0.711\n",
      "[46,    15] train loss: 0.572 train acc: 0.707\n",
      "[46,    16] train loss: 0.504 train acc: 0.758\n",
      "[46,    17] train loss: 0.582 train acc: 0.680\n",
      "[46,    18] train loss: 0.554 train acc: 0.734\n",
      "[46,    19] train loss: 0.571 train acc: 0.680\n",
      "[46,    20] train loss: 0.529 train acc: 0.710\n",
      "[46] val loss: 0.529 val acc: 0.781\n",
      "[47,     1] train loss: 0.582 train acc: 0.680\n",
      "[47,     2] train loss: 0.576 train acc: 0.660\n",
      "[47,     3] train loss: 0.496 train acc: 0.766\n",
      "[47,     4] train loss: 0.525 train acc: 0.730\n",
      "[47,     5] train loss: 0.558 train acc: 0.734\n",
      "[47,     6] train loss: 0.513 train acc: 0.746\n",
      "[47,     7] train loss: 0.521 train acc: 0.773\n",
      "[47,     8] train loss: 0.550 train acc: 0.734\n",
      "[47,     9] train loss: 0.594 train acc: 0.715\n",
      "[47,    10] train loss: 0.551 train acc: 0.664\n",
      "[47,    11] train loss: 0.542 train acc: 0.707\n",
      "[47,    12] train loss: 0.498 train acc: 0.723\n",
      "[47,    13] train loss: 0.519 train acc: 0.750\n",
      "[47,    14] train loss: 0.532 train acc: 0.707\n",
      "[47,    15] train loss: 0.575 train acc: 0.695\n",
      "[47,    16] train loss: 0.499 train acc: 0.754\n",
      "[47,    17] train loss: 0.535 train acc: 0.711\n",
      "[47,    18] train loss: 0.530 train acc: 0.695\n",
      "[47,    19] train loss: 0.504 train acc: 0.719\n",
      "[47,    20] train loss: 0.541 train acc: 0.755\n",
      "[47] val loss: 0.508 val acc: 0.800\n",
      "[48,     1] train loss: 0.581 train acc: 0.707\n",
      "[48,     2] train loss: 0.526 train acc: 0.730\n",
      "[48,     3] train loss: 0.555 train acc: 0.695\n",
      "[48,     4] train loss: 0.498 train acc: 0.766\n",
      "[48,     5] train loss: 0.510 train acc: 0.738\n",
      "[48,     6] train loss: 0.563 train acc: 0.699\n",
      "[48,     7] train loss: 0.526 train acc: 0.730\n",
      "[48,     8] train loss: 0.492 train acc: 0.742\n",
      "[48,     9] train loss: 0.571 train acc: 0.707\n",
      "[48,    10] train loss: 0.572 train acc: 0.695\n",
      "[48,    11] train loss: 0.529 train acc: 0.719\n",
      "[48,    12] train loss: 0.542 train acc: 0.730\n",
      "[48,    13] train loss: 0.562 train acc: 0.688\n",
      "[48,    14] train loss: 0.521 train acc: 0.742\n",
      "[48,    15] train loss: 0.425 train acc: 0.824\n",
      "[48,    16] train loss: 0.551 train acc: 0.742\n",
      "[48,    17] train loss: 0.567 train acc: 0.742\n",
      "[48,    18] train loss: 0.567 train acc: 0.711\n",
      "[48,    19] train loss: 0.542 train acc: 0.723\n",
      "[48,    20] train loss: 0.526 train acc: 0.723\n",
      "[48] val loss: 0.502 val acc: 0.815\n",
      "[49,     1] train loss: 0.538 train acc: 0.723\n",
      "[49,     2] train loss: 0.535 train acc: 0.719\n",
      "[49,     3] train loss: 0.465 train acc: 0.793\n",
      "[49,     4] train loss: 0.480 train acc: 0.762\n",
      "[49,     5] train loss: 0.574 train acc: 0.695\n",
      "[49,     6] train loss: 0.578 train acc: 0.688\n",
      "[49,     7] train loss: 0.569 train acc: 0.691\n",
      "[49,     8] train loss: 0.521 train acc: 0.754\n",
      "[49,     9] train loss: 0.527 train acc: 0.742\n",
      "[49,    10] train loss: 0.535 train acc: 0.723\n",
      "[49,    11] train loss: 0.569 train acc: 0.703\n",
      "[49,    12] train loss: 0.516 train acc: 0.734\n",
      "[49,    13] train loss: 0.596 train acc: 0.680\n",
      "[49,    14] train loss: 0.521 train acc: 0.738\n",
      "[49,    15] train loss: 0.545 train acc: 0.691\n",
      "[49,    16] train loss: 0.544 train acc: 0.707\n",
      "[49,    17] train loss: 0.541 train acc: 0.723\n",
      "[49,    18] train loss: 0.544 train acc: 0.707\n",
      "[49,    19] train loss: 0.538 train acc: 0.711\n",
      "[49,    20] train loss: 0.540 train acc: 0.710\n",
      "[49] val loss: 0.523 val acc: 0.810\n",
      "[50,     1] train loss: 0.514 train acc: 0.723\n",
      "[50,     2] train loss: 0.525 train acc: 0.707\n",
      "[50,     3] train loss: 0.482 train acc: 0.758\n",
      "[50,     4] train loss: 0.552 train acc: 0.711\n",
      "[50,     5] train loss: 0.558 train acc: 0.699\n",
      "[50,     6] train loss: 0.552 train acc: 0.734\n",
      "[50,     7] train loss: 0.567 train acc: 0.707\n",
      "[50,     8] train loss: 0.548 train acc: 0.711\n",
      "[50,     9] train loss: 0.507 train acc: 0.719\n",
      "[50,    10] train loss: 0.499 train acc: 0.762\n",
      "[50,    11] train loss: 0.473 train acc: 0.781\n",
      "[50,    12] train loss: 0.529 train acc: 0.699\n",
      "[50,    13] train loss: 0.533 train acc: 0.730\n",
      "[50,    14] train loss: 0.531 train acc: 0.703\n",
      "[50,    15] train loss: 0.499 train acc: 0.742\n",
      "[50,    16] train loss: 0.557 train acc: 0.703\n",
      "[50,    17] train loss: 0.529 train acc: 0.723\n",
      "[50,    18] train loss: 0.493 train acc: 0.723\n",
      "[50,    19] train loss: 0.558 train acc: 0.711\n",
      "[50,    20] train loss: 0.586 train acc: 0.671\n",
      "[50] val loss: 0.504 val acc: 0.802\n",
      "[51,     1] train loss: 0.530 train acc: 0.715\n",
      "[51,     2] train loss: 0.503 train acc: 0.727\n",
      "[51,     3] train loss: 0.569 train acc: 0.715\n",
      "[51,     4] train loss: 0.539 train acc: 0.750\n",
      "[51,     5] train loss: 0.538 train acc: 0.672\n",
      "[51,     6] train loss: 0.496 train acc: 0.727\n",
      "[51,     7] train loss: 0.550 train acc: 0.695\n",
      "[51,     8] train loss: 0.477 train acc: 0.738\n",
      "[51,     9] train loss: 0.553 train acc: 0.719\n",
      "[51,    10] train loss: 0.520 train acc: 0.715\n",
      "[51,    11] train loss: 0.521 train acc: 0.703\n",
      "[51,    12] train loss: 0.468 train acc: 0.762\n",
      "[51,    13] train loss: 0.517 train acc: 0.738\n",
      "[51,    14] train loss: 0.539 train acc: 0.742\n",
      "[51,    15] train loss: 0.526 train acc: 0.730\n",
      "[51,    16] train loss: 0.529 train acc: 0.695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51,    17] train loss: 0.538 train acc: 0.703\n",
      "[51,    18] train loss: 0.520 train acc: 0.730\n",
      "[51,    19] train loss: 0.541 train acc: 0.730\n",
      "[51,    20] train loss: 0.559 train acc: 0.710\n",
      "[51] val loss: 0.490 val acc: 0.822\n",
      "[52,     1] train loss: 0.509 train acc: 0.727\n",
      "[52,     2] train loss: 0.533 train acc: 0.715\n",
      "[52,     3] train loss: 0.515 train acc: 0.727\n",
      "[52,     4] train loss: 0.556 train acc: 0.695\n",
      "[52,     5] train loss: 0.541 train acc: 0.703\n",
      "[52,     6] train loss: 0.520 train acc: 0.723\n",
      "[52,     7] train loss: 0.560 train acc: 0.711\n",
      "[52,     8] train loss: 0.515 train acc: 0.773\n",
      "[52,     9] train loss: 0.575 train acc: 0.695\n",
      "[52,    10] train loss: 0.469 train acc: 0.781\n",
      "[52,    11] train loss: 0.518 train acc: 0.742\n",
      "[52,    12] train loss: 0.569 train acc: 0.695\n",
      "[52,    13] train loss: 0.528 train acc: 0.688\n",
      "[52,    14] train loss: 0.566 train acc: 0.699\n",
      "[52,    15] train loss: 0.530 train acc: 0.711\n",
      "[52,    16] train loss: 0.519 train acc: 0.727\n",
      "[52,    17] train loss: 0.532 train acc: 0.719\n",
      "[52,    18] train loss: 0.511 train acc: 0.762\n",
      "[52,    19] train loss: 0.530 train acc: 0.723\n",
      "[52,    20] train loss: 0.532 train acc: 0.710\n",
      "[52] val loss: 0.505 val acc: 0.826\n",
      "[53,     1] train loss: 0.494 train acc: 0.746\n",
      "[53,     2] train loss: 0.494 train acc: 0.715\n",
      "[53,     3] train loss: 0.526 train acc: 0.746\n",
      "[53,     4] train loss: 0.533 train acc: 0.730\n",
      "[53,     5] train loss: 0.532 train acc: 0.719\n",
      "[53,     6] train loss: 0.477 train acc: 0.770\n",
      "[53,     7] train loss: 0.520 train acc: 0.746\n",
      "[53,     8] train loss: 0.519 train acc: 0.754\n",
      "[53,     9] train loss: 0.488 train acc: 0.742\n",
      "[53,    10] train loss: 0.494 train acc: 0.754\n",
      "[53,    11] train loss: 0.491 train acc: 0.754\n",
      "[53,    12] train loss: 0.540 train acc: 0.715\n",
      "[53,    13] train loss: 0.464 train acc: 0.766\n",
      "[53,    14] train loss: 0.536 train acc: 0.707\n",
      "[53,    15] train loss: 0.592 train acc: 0.707\n",
      "[53,    16] train loss: 0.468 train acc: 0.773\n",
      "[53,    17] train loss: 0.579 train acc: 0.664\n",
      "[53,    18] train loss: 0.522 train acc: 0.727\n",
      "[53,    19] train loss: 0.519 train acc: 0.711\n",
      "[53,    20] train loss: 0.549 train acc: 0.742\n",
      "[53] val loss: 0.491 val acc: 0.824\n",
      "[54,     1] train loss: 0.463 train acc: 0.762\n",
      "[54,     2] train loss: 0.522 train acc: 0.719\n",
      "[54,     3] train loss: 0.537 train acc: 0.727\n",
      "[54,     4] train loss: 0.537 train acc: 0.715\n",
      "[54,     5] train loss: 0.529 train acc: 0.695\n",
      "[54,     6] train loss: 0.531 train acc: 0.707\n",
      "[54,     7] train loss: 0.496 train acc: 0.754\n",
      "[54,     8] train loss: 0.582 train acc: 0.699\n",
      "[54,     9] train loss: 0.494 train acc: 0.758\n",
      "[54,    10] train loss: 0.526 train acc: 0.707\n",
      "[54,    11] train loss: 0.523 train acc: 0.734\n",
      "[54,    12] train loss: 0.533 train acc: 0.746\n",
      "[54,    13] train loss: 0.535 train acc: 0.703\n",
      "[54,    14] train loss: 0.505 train acc: 0.738\n",
      "[54,    15] train loss: 0.457 train acc: 0.785\n",
      "[54,    16] train loss: 0.489 train acc: 0.762\n",
      "[54,    17] train loss: 0.566 train acc: 0.727\n",
      "[54,    18] train loss: 0.484 train acc: 0.758\n",
      "[54,    19] train loss: 0.567 train acc: 0.699\n",
      "[54,    20] train loss: 0.503 train acc: 0.716\n",
      "[54] val loss: 0.482 val acc: 0.825\n",
      "[55,     1] train loss: 0.544 train acc: 0.703\n",
      "[55,     2] train loss: 0.483 train acc: 0.746\n",
      "[55,     3] train loss: 0.478 train acc: 0.770\n",
      "[55,     4] train loss: 0.492 train acc: 0.746\n",
      "[55,     5] train loss: 0.495 train acc: 0.746\n",
      "[55,     6] train loss: 0.454 train acc: 0.766\n",
      "[55,     7] train loss: 0.480 train acc: 0.766\n",
      "[55,     8] train loss: 0.510 train acc: 0.746\n",
      "[55,     9] train loss: 0.517 train acc: 0.734\n",
      "[55,    10] train loss: 0.490 train acc: 0.754\n",
      "[55,    11] train loss: 0.537 train acc: 0.695\n",
      "[55,    12] train loss: 0.498 train acc: 0.750\n",
      "[55,    13] train loss: 0.491 train acc: 0.754\n",
      "[55,    14] train loss: 0.497 train acc: 0.738\n",
      "[55,    15] train loss: 0.540 train acc: 0.715\n",
      "[55,    16] train loss: 0.579 train acc: 0.672\n",
      "[55,    17] train loss: 0.559 train acc: 0.719\n",
      "[55,    18] train loss: 0.479 train acc: 0.793\n",
      "[55,    19] train loss: 0.506 train acc: 0.773\n",
      "[55,    20] train loss: 0.468 train acc: 0.826\n",
      "[55] val loss: 0.495 val acc: 0.840\n",
      "[56,     1] train loss: 0.526 train acc: 0.734\n",
      "[56,     2] train loss: 0.546 train acc: 0.711\n",
      "[56,     3] train loss: 0.483 train acc: 0.762\n",
      "[56,     4] train loss: 0.510 train acc: 0.734\n",
      "[56,     5] train loss: 0.505 train acc: 0.734\n",
      "[56,     6] train loss: 0.482 train acc: 0.758\n",
      "[56,     7] train loss: 0.498 train acc: 0.723\n",
      "[56,     8] train loss: 0.492 train acc: 0.781\n",
      "[56,     9] train loss: 0.514 train acc: 0.723\n",
      "[56,    10] train loss: 0.562 train acc: 0.727\n",
      "[56,    11] train loss: 0.536 train acc: 0.715\n",
      "[56,    12] train loss: 0.508 train acc: 0.754\n",
      "[56,    13] train loss: 0.495 train acc: 0.773\n",
      "[56,    14] train loss: 0.485 train acc: 0.754\n",
      "[56,    15] train loss: 0.498 train acc: 0.750\n",
      "[56,    16] train loss: 0.503 train acc: 0.770\n",
      "[56,    17] train loss: 0.487 train acc: 0.758\n",
      "[56,    18] train loss: 0.517 train acc: 0.742\n",
      "[56,    19] train loss: 0.510 train acc: 0.719\n",
      "[56,    20] train loss: 0.486 train acc: 0.768\n",
      "[56] val loss: 0.473 val acc: 0.849\n",
      "[57,     1] train loss: 0.463 train acc: 0.785\n",
      "[57,     2] train loss: 0.486 train acc: 0.762\n",
      "[57,     3] train loss: 0.543 train acc: 0.703\n",
      "[57,     4] train loss: 0.478 train acc: 0.734\n",
      "[57,     5] train loss: 0.478 train acc: 0.758\n",
      "[57,     6] train loss: 0.501 train acc: 0.754\n",
      "[57,     7] train loss: 0.531 train acc: 0.742\n",
      "[57,     8] train loss: 0.464 train acc: 0.762\n",
      "[57,     9] train loss: 0.532 train acc: 0.711\n",
      "[57,    10] train loss: 0.512 train acc: 0.766\n",
      "[57,    11] train loss: 0.497 train acc: 0.734\n",
      "[57,    12] train loss: 0.487 train acc: 0.762\n",
      "[57,    13] train loss: 0.473 train acc: 0.777\n",
      "[57,    14] train loss: 0.484 train acc: 0.758\n",
      "[57,    15] train loss: 0.510 train acc: 0.727\n",
      "[57,    16] train loss: 0.461 train acc: 0.809\n",
      "[57,    17] train loss: 0.476 train acc: 0.750\n",
      "[57,    18] train loss: 0.510 train acc: 0.730\n",
      "[57,    19] train loss: 0.473 train acc: 0.781\n",
      "[57,    20] train loss: 0.534 train acc: 0.748\n",
      "[57] val loss: 0.467 val acc: 0.836\n",
      "[58,     1] train loss: 0.433 train acc: 0.770\n",
      "[58,     2] train loss: 0.493 train acc: 0.742\n",
      "[58,     3] train loss: 0.461 train acc: 0.777\n",
      "[58,     4] train loss: 0.552 train acc: 0.699\n",
      "[58,     5] train loss: 0.503 train acc: 0.754\n",
      "[58,     6] train loss: 0.500 train acc: 0.734\n",
      "[58,     7] train loss: 0.474 train acc: 0.781\n",
      "[58,     8] train loss: 0.465 train acc: 0.781\n",
      "[58,     9] train loss: 0.528 train acc: 0.707\n",
      "[58,    10] train loss: 0.508 train acc: 0.742\n",
      "[58,    11] train loss: 0.496 train acc: 0.754\n",
      "[58,    12] train loss: 0.498 train acc: 0.738\n",
      "[58,    13] train loss: 0.589 train acc: 0.664\n",
      "[58,    14] train loss: 0.540 train acc: 0.703\n",
      "[58,    15] train loss: 0.510 train acc: 0.746\n",
      "[58,    16] train loss: 0.529 train acc: 0.703\n",
      "[58,    17] train loss: 0.517 train acc: 0.730\n",
      "[58,    18] train loss: 0.475 train acc: 0.793\n",
      "[58,    19] train loss: 0.508 train acc: 0.742\n",
      "[58,    20] train loss: 0.518 train acc: 0.748\n",
      "[58] val loss: 0.484 val acc: 0.840\n",
      "[59,     1] train loss: 0.538 train acc: 0.703\n",
      "[59,     2] train loss: 0.522 train acc: 0.715\n",
      "[59,     3] train loss: 0.494 train acc: 0.742\n",
      "[59,     4] train loss: 0.498 train acc: 0.723\n",
      "[59,     5] train loss: 0.464 train acc: 0.754\n",
      "[59,     6] train loss: 0.459 train acc: 0.785\n",
      "[59,     7] train loss: 0.507 train acc: 0.723\n",
      "[59,     8] train loss: 0.461 train acc: 0.773\n",
      "[59,     9] train loss: 0.525 train acc: 0.742\n",
      "[59,    10] train loss: 0.528 train acc: 0.711\n",
      "[59,    11] train loss: 0.455 train acc: 0.750\n",
      "[59,    12] train loss: 0.493 train acc: 0.762\n",
      "[59,    13] train loss: 0.512 train acc: 0.727\n",
      "[59,    14] train loss: 0.492 train acc: 0.781\n",
      "[59,    15] train loss: 0.518 train acc: 0.715\n",
      "[59,    16] train loss: 0.535 train acc: 0.766\n",
      "[59,    17] train loss: 0.538 train acc: 0.719\n",
      "[59,    18] train loss: 0.506 train acc: 0.754\n",
      "[59,    19] train loss: 0.488 train acc: 0.770\n",
      "[59,    20] train loss: 0.532 train acc: 0.723\n",
      "[59] val loss: 0.471 val acc: 0.855\n",
      "[60,     1] train loss: 0.468 train acc: 0.750\n",
      "[60,     2] train loss: 0.498 train acc: 0.746\n",
      "[60,     3] train loss: 0.455 train acc: 0.797\n",
      "[60,     4] train loss: 0.463 train acc: 0.758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60,     5] train loss: 0.497 train acc: 0.773\n",
      "[60,     6] train loss: 0.444 train acc: 0.766\n",
      "[60,     7] train loss: 0.472 train acc: 0.754\n",
      "[60,     8] train loss: 0.518 train acc: 0.738\n",
      "[60,     9] train loss: 0.495 train acc: 0.766\n",
      "[60,    10] train loss: 0.487 train acc: 0.734\n",
      "[60,    11] train loss: 0.479 train acc: 0.750\n",
      "[60,    12] train loss: 0.489 train acc: 0.742\n",
      "[60,    13] train loss: 0.502 train acc: 0.727\n",
      "[60,    14] train loss: 0.483 train acc: 0.777\n",
      "[60,    15] train loss: 0.508 train acc: 0.754\n",
      "[60,    16] train loss: 0.611 train acc: 0.695\n",
      "[60,    17] train loss: 0.484 train acc: 0.734\n",
      "[60,    18] train loss: 0.460 train acc: 0.809\n",
      "[60,    19] train loss: 0.504 train acc: 0.727\n",
      "[60,    20] train loss: 0.533 train acc: 0.748\n",
      "[60] val loss: 0.458 val acc: 0.857\n",
      "[61,     1] train loss: 0.484 train acc: 0.738\n",
      "[61,     2] train loss: 0.459 train acc: 0.730\n",
      "[61,     3] train loss: 0.520 train acc: 0.727\n",
      "[61,     4] train loss: 0.487 train acc: 0.742\n",
      "[61,     5] train loss: 0.465 train acc: 0.777\n",
      "[61,     6] train loss: 0.522 train acc: 0.734\n",
      "[61,     7] train loss: 0.476 train acc: 0.750\n",
      "[61,     8] train loss: 0.506 train acc: 0.762\n",
      "[61,     9] train loss: 0.492 train acc: 0.762\n",
      "[61,    10] train loss: 0.471 train acc: 0.762\n",
      "[61,    11] train loss: 0.478 train acc: 0.746\n",
      "[61,    12] train loss: 0.546 train acc: 0.758\n",
      "[61,    13] train loss: 0.493 train acc: 0.762\n",
      "[61,    14] train loss: 0.539 train acc: 0.695\n",
      "[61,    15] train loss: 0.443 train acc: 0.789\n",
      "[61,    16] train loss: 0.487 train acc: 0.762\n",
      "[61,    17] train loss: 0.474 train acc: 0.750\n",
      "[61,    18] train loss: 0.487 train acc: 0.770\n",
      "[61,    19] train loss: 0.467 train acc: 0.754\n",
      "[61,    20] train loss: 0.528 train acc: 0.729\n",
      "[61] val loss: 0.436 val acc: 0.866\n",
      "[62,     1] train loss: 0.500 train acc: 0.781\n",
      "[62,     2] train loss: 0.573 train acc: 0.730\n",
      "[62,     3] train loss: 0.445 train acc: 0.750\n",
      "[62,     4] train loss: 0.512 train acc: 0.734\n",
      "[62,     5] train loss: 0.441 train acc: 0.789\n",
      "[62,     6] train loss: 0.459 train acc: 0.770\n",
      "[62,     7] train loss: 0.469 train acc: 0.781\n",
      "[62,     8] train loss: 0.502 train acc: 0.742\n",
      "[62,     9] train loss: 0.566 train acc: 0.715\n",
      "[62,    10] train loss: 0.438 train acc: 0.801\n",
      "[62,    11] train loss: 0.443 train acc: 0.805\n",
      "[62,    12] train loss: 0.539 train acc: 0.695\n",
      "[62,    13] train loss: 0.523 train acc: 0.754\n",
      "[62,    14] train loss: 0.501 train acc: 0.750\n",
      "[62,    15] train loss: 0.477 train acc: 0.777\n",
      "[62,    16] train loss: 0.529 train acc: 0.727\n",
      "[62,    17] train loss: 0.448 train acc: 0.770\n",
      "[62,    18] train loss: 0.496 train acc: 0.766\n",
      "[62,    19] train loss: 0.503 train acc: 0.758\n",
      "[62,    20] train loss: 0.457 train acc: 0.761\n",
      "[62] val loss: 0.445 val acc: 0.863\n",
      "[63,     1] train loss: 0.457 train acc: 0.773\n",
      "[63,     2] train loss: 0.447 train acc: 0.789\n",
      "[63,     3] train loss: 0.505 train acc: 0.734\n",
      "[63,     4] train loss: 0.494 train acc: 0.727\n",
      "[63,     5] train loss: 0.464 train acc: 0.773\n",
      "[63,     6] train loss: 0.521 train acc: 0.734\n",
      "[63,     7] train loss: 0.458 train acc: 0.770\n",
      "[63,     8] train loss: 0.490 train acc: 0.754\n",
      "[63,     9] train loss: 0.495 train acc: 0.750\n",
      "[63,    10] train loss: 0.425 train acc: 0.812\n",
      "[63,    11] train loss: 0.504 train acc: 0.734\n",
      "[63,    12] train loss: 0.466 train acc: 0.777\n",
      "[63,    13] train loss: 0.518 train acc: 0.762\n",
      "[63,    14] train loss: 0.457 train acc: 0.770\n",
      "[63,    15] train loss: 0.529 train acc: 0.727\n",
      "[63,    16] train loss: 0.543 train acc: 0.699\n",
      "[63,    17] train loss: 0.461 train acc: 0.789\n",
      "[63,    18] train loss: 0.448 train acc: 0.762\n",
      "[63,    19] train loss: 0.450 train acc: 0.809\n",
      "[63,    20] train loss: 0.482 train acc: 0.742\n",
      "[63] val loss: 0.436 val acc: 0.873\n",
      "[64,     1] train loss: 0.477 train acc: 0.781\n",
      "[64,     2] train loss: 0.451 train acc: 0.770\n",
      "[64,     3] train loss: 0.429 train acc: 0.773\n",
      "[64,     4] train loss: 0.425 train acc: 0.801\n",
      "[64,     5] train loss: 0.474 train acc: 0.773\n",
      "[64,     6] train loss: 0.608 train acc: 0.703\n",
      "[64,     7] train loss: 0.454 train acc: 0.793\n",
      "[64,     8] train loss: 0.472 train acc: 0.812\n",
      "[64,     9] train loss: 0.530 train acc: 0.734\n",
      "[64,    10] train loss: 0.544 train acc: 0.742\n",
      "[64,    11] train loss: 0.425 train acc: 0.797\n",
      "[64,    12] train loss: 0.492 train acc: 0.770\n",
      "[64,    13] train loss: 0.428 train acc: 0.801\n",
      "[64,    14] train loss: 0.513 train acc: 0.727\n",
      "[64,    15] train loss: 0.503 train acc: 0.699\n",
      "[64,    16] train loss: 0.473 train acc: 0.773\n",
      "[64,    17] train loss: 0.517 train acc: 0.707\n",
      "[64,    18] train loss: 0.477 train acc: 0.770\n",
      "[64,    19] train loss: 0.436 train acc: 0.793\n",
      "[64,    20] train loss: 0.513 train acc: 0.755\n",
      "[64] val loss: 0.446 val acc: 0.872\n",
      "[65,     1] train loss: 0.508 train acc: 0.738\n",
      "[65,     2] train loss: 0.474 train acc: 0.762\n",
      "[65,     3] train loss: 0.441 train acc: 0.801\n",
      "[65,     4] train loss: 0.425 train acc: 0.805\n",
      "[65,     5] train loss: 0.539 train acc: 0.719\n",
      "[65,     6] train loss: 0.485 train acc: 0.738\n",
      "[65,     7] train loss: 0.464 train acc: 0.777\n",
      "[65,     8] train loss: 0.442 train acc: 0.797\n",
      "[65,     9] train loss: 0.484 train acc: 0.762\n",
      "[65,    10] train loss: 0.474 train acc: 0.754\n",
      "[65,    11] train loss: 0.433 train acc: 0.824\n",
      "[65,    12] train loss: 0.535 train acc: 0.727\n",
      "[65,    13] train loss: 0.455 train acc: 0.797\n",
      "[65,    14] train loss: 0.503 train acc: 0.785\n",
      "[65,    15] train loss: 0.479 train acc: 0.773\n",
      "[65,    16] train loss: 0.491 train acc: 0.781\n",
      "[65,    17] train loss: 0.486 train acc: 0.754\n",
      "[65,    18] train loss: 0.488 train acc: 0.773\n",
      "[65,    19] train loss: 0.491 train acc: 0.750\n",
      "[65,    20] train loss: 0.413 train acc: 0.813\n",
      "[65] val loss: 0.443 val acc: 0.871\n",
      "[66,     1] train loss: 0.410 train acc: 0.812\n",
      "[66,     2] train loss: 0.474 train acc: 0.793\n",
      "[66,     3] train loss: 0.453 train acc: 0.797\n",
      "[66,     4] train loss: 0.434 train acc: 0.820\n",
      "[66,     5] train loss: 0.485 train acc: 0.758\n",
      "[66,     6] train loss: 0.494 train acc: 0.742\n",
      "[66,     7] train loss: 0.428 train acc: 0.777\n",
      "[66,     8] train loss: 0.464 train acc: 0.797\n",
      "[66,     9] train loss: 0.495 train acc: 0.723\n",
      "[66,    10] train loss: 0.491 train acc: 0.750\n",
      "[66,    11] train loss: 0.472 train acc: 0.746\n",
      "[66,    12] train loss: 0.496 train acc: 0.758\n",
      "[66,    13] train loss: 0.493 train acc: 0.781\n",
      "[66,    14] train loss: 0.502 train acc: 0.785\n",
      "[66,    15] train loss: 0.509 train acc: 0.762\n",
      "[66,    16] train loss: 0.492 train acc: 0.785\n",
      "[66,    17] train loss: 0.447 train acc: 0.789\n",
      "[66,    18] train loss: 0.500 train acc: 0.754\n",
      "[66,    19] train loss: 0.503 train acc: 0.762\n",
      "[66,    20] train loss: 0.516 train acc: 0.723\n",
      "[66] val loss: 0.452 val acc: 0.883\n",
      "[67,     1] train loss: 0.495 train acc: 0.742\n",
      "[67,     2] train loss: 0.450 train acc: 0.785\n",
      "[67,     3] train loss: 0.502 train acc: 0.707\n",
      "[67,     4] train loss: 0.423 train acc: 0.820\n",
      "[67,     5] train loss: 0.426 train acc: 0.773\n",
      "[67,     6] train loss: 0.495 train acc: 0.742\n",
      "[67,     7] train loss: 0.465 train acc: 0.762\n",
      "[67,     8] train loss: 0.461 train acc: 0.746\n",
      "[67,     9] train loss: 0.497 train acc: 0.738\n",
      "[67,    10] train loss: 0.465 train acc: 0.773\n",
      "[67,    11] train loss: 0.506 train acc: 0.750\n",
      "[67,    12] train loss: 0.497 train acc: 0.738\n",
      "[67,    13] train loss: 0.506 train acc: 0.789\n",
      "[67,    14] train loss: 0.447 train acc: 0.777\n",
      "[67,    15] train loss: 0.464 train acc: 0.762\n",
      "[67,    16] train loss: 0.504 train acc: 0.746\n",
      "[67,    17] train loss: 0.408 train acc: 0.828\n",
      "[67,    18] train loss: 0.561 train acc: 0.723\n",
      "[67,    19] train loss: 0.439 train acc: 0.797\n",
      "[67,    20] train loss: 0.482 train acc: 0.748\n",
      "[67] val loss: 0.430 val acc: 0.893\n",
      "[68,     1] train loss: 0.445 train acc: 0.777\n",
      "[68,     2] train loss: 0.426 train acc: 0.793\n",
      "[68,     3] train loss: 0.513 train acc: 0.754\n",
      "[68,     4] train loss: 0.448 train acc: 0.797\n",
      "[68,     5] train loss: 0.443 train acc: 0.793\n",
      "[68,     6] train loss: 0.451 train acc: 0.781\n",
      "[68,     7] train loss: 0.424 train acc: 0.777\n",
      "[68,     8] train loss: 0.445 train acc: 0.773\n",
      "[68,     9] train loss: 0.502 train acc: 0.762\n",
      "[68,    10] train loss: 0.398 train acc: 0.793\n",
      "[68,    11] train loss: 0.393 train acc: 0.797\n",
      "[68,    12] train loss: 0.440 train acc: 0.777\n",
      "[68,    13] train loss: 0.467 train acc: 0.746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[68,    14] train loss: 0.504 train acc: 0.738\n",
      "[68,    15] train loss: 0.462 train acc: 0.777\n",
      "[68,    16] train loss: 0.508 train acc: 0.762\n",
      "[68,    17] train loss: 0.507 train acc: 0.766\n",
      "[68,    18] train loss: 0.439 train acc: 0.777\n",
      "[68,    19] train loss: 0.483 train acc: 0.762\n",
      "[68,    20] train loss: 0.492 train acc: 0.735\n",
      "[68] val loss: 0.417 val acc: 0.893\n",
      "[69,     1] train loss: 0.516 train acc: 0.762\n",
      "[69,     2] train loss: 0.484 train acc: 0.758\n",
      "[69,     3] train loss: 0.519 train acc: 0.730\n",
      "[69,     4] train loss: 0.449 train acc: 0.754\n",
      "[69,     5] train loss: 0.503 train acc: 0.750\n",
      "[69,     6] train loss: 0.481 train acc: 0.789\n",
      "[69,     7] train loss: 0.429 train acc: 0.793\n",
      "[69,     8] train loss: 0.517 train acc: 0.707\n",
      "[69,     9] train loss: 0.455 train acc: 0.770\n",
      "[69,    10] train loss: 0.509 train acc: 0.742\n",
      "[69,    11] train loss: 0.442 train acc: 0.789\n",
      "[69,    12] train loss: 0.491 train acc: 0.770\n",
      "[69,    13] train loss: 0.403 train acc: 0.820\n",
      "[69,    14] train loss: 0.464 train acc: 0.770\n",
      "[69,    15] train loss: 0.467 train acc: 0.766\n",
      "[69,    16] train loss: 0.437 train acc: 0.777\n",
      "[69,    17] train loss: 0.502 train acc: 0.754\n",
      "[69,    18] train loss: 0.472 train acc: 0.766\n",
      "[69,    19] train loss: 0.412 train acc: 0.793\n",
      "[69,    20] train loss: 0.449 train acc: 0.787\n",
      "[69] val loss: 0.401 val acc: 0.897\n",
      "[70,     1] train loss: 0.505 train acc: 0.742\n",
      "[70,     2] train loss: 0.444 train acc: 0.754\n",
      "[70,     3] train loss: 0.436 train acc: 0.766\n",
      "[70,     4] train loss: 0.410 train acc: 0.805\n",
      "[70,     5] train loss: 0.416 train acc: 0.801\n",
      "[70,     6] train loss: 0.443 train acc: 0.793\n",
      "[70,     7] train loss: 0.501 train acc: 0.754\n",
      "[70,     8] train loss: 0.428 train acc: 0.836\n",
      "[70,     9] train loss: 0.481 train acc: 0.762\n",
      "[70,    10] train loss: 0.475 train acc: 0.773\n",
      "[70,    11] train loss: 0.552 train acc: 0.750\n",
      "[70,    12] train loss: 0.448 train acc: 0.785\n",
      "[70,    13] train loss: 0.443 train acc: 0.785\n",
      "[70,    14] train loss: 0.494 train acc: 0.734\n",
      "[70,    15] train loss: 0.409 train acc: 0.805\n",
      "[70,    16] train loss: 0.418 train acc: 0.766\n",
      "[70,    17] train loss: 0.448 train acc: 0.789\n",
      "[70,    18] train loss: 0.485 train acc: 0.715\n",
      "[70,    19] train loss: 0.447 train acc: 0.762\n",
      "[70,    20] train loss: 0.441 train acc: 0.800\n",
      "[70] val loss: 0.401 val acc: 0.905\n",
      "[71,     1] train loss: 0.424 train acc: 0.785\n",
      "[71,     2] train loss: 0.410 train acc: 0.812\n",
      "[71,     3] train loss: 0.427 train acc: 0.789\n",
      "[71,     4] train loss: 0.496 train acc: 0.777\n",
      "[71,     5] train loss: 0.414 train acc: 0.824\n",
      "[71,     6] train loss: 0.444 train acc: 0.781\n",
      "[71,     7] train loss: 0.412 train acc: 0.840\n",
      "[71,     8] train loss: 0.468 train acc: 0.777\n",
      "[71,     9] train loss: 0.439 train acc: 0.820\n",
      "[71,    10] train loss: 0.473 train acc: 0.785\n",
      "[71,    11] train loss: 0.442 train acc: 0.762\n",
      "[71,    12] train loss: 0.493 train acc: 0.773\n",
      "[71,    13] train loss: 0.394 train acc: 0.809\n",
      "[71,    14] train loss: 0.470 train acc: 0.758\n",
      "[71,    15] train loss: 0.459 train acc: 0.777\n",
      "[71,    16] train loss: 0.455 train acc: 0.758\n",
      "[71,    17] train loss: 0.455 train acc: 0.785\n",
      "[71,    18] train loss: 0.418 train acc: 0.797\n",
      "[71,    19] train loss: 0.444 train acc: 0.777\n",
      "[71,    20] train loss: 0.484 train acc: 0.723\n",
      "[71] val loss: 0.399 val acc: 0.891\n",
      "[72,     1] train loss: 0.510 train acc: 0.730\n",
      "[72,     2] train loss: 0.412 train acc: 0.797\n",
      "[72,     3] train loss: 0.444 train acc: 0.773\n",
      "[72,     4] train loss: 0.393 train acc: 0.828\n",
      "[72,     5] train loss: 0.422 train acc: 0.793\n",
      "[72,     6] train loss: 0.417 train acc: 0.805\n",
      "[72,     7] train loss: 0.526 train acc: 0.762\n",
      "[72,     8] train loss: 0.455 train acc: 0.750\n",
      "[72,     9] train loss: 0.518 train acc: 0.754\n",
      "[72,    10] train loss: 0.474 train acc: 0.809\n",
      "[72,    11] train loss: 0.450 train acc: 0.766\n",
      "[72,    12] train loss: 0.454 train acc: 0.797\n",
      "[72,    13] train loss: 0.488 train acc: 0.766\n",
      "[72,    14] train loss: 0.413 train acc: 0.820\n",
      "[72,    15] train loss: 0.447 train acc: 0.785\n",
      "[72,    16] train loss: 0.488 train acc: 0.762\n",
      "[72,    17] train loss: 0.448 train acc: 0.805\n",
      "[72,    18] train loss: 0.478 train acc: 0.793\n",
      "[72,    19] train loss: 0.457 train acc: 0.785\n",
      "[72,    20] train loss: 0.480 train acc: 0.723\n",
      "[72] val loss: 0.403 val acc: 0.897\n",
      "[73,     1] train loss: 0.371 train acc: 0.871\n",
      "[73,     2] train loss: 0.440 train acc: 0.789\n",
      "[73,     3] train loss: 0.438 train acc: 0.777\n",
      "[73,     4] train loss: 0.515 train acc: 0.738\n",
      "[73,     5] train loss: 0.476 train acc: 0.785\n",
      "[73,     6] train loss: 0.433 train acc: 0.785\n",
      "[73,     7] train loss: 0.408 train acc: 0.828\n",
      "[73,     8] train loss: 0.427 train acc: 0.797\n",
      "[73,     9] train loss: 0.458 train acc: 0.762\n",
      "[73,    10] train loss: 0.383 train acc: 0.805\n",
      "[73,    11] train loss: 0.464 train acc: 0.781\n",
      "[73,    12] train loss: 0.485 train acc: 0.754\n",
      "[73,    13] train loss: 0.444 train acc: 0.777\n",
      "[73,    14] train loss: 0.405 train acc: 0.801\n",
      "[73,    15] train loss: 0.402 train acc: 0.812\n",
      "[73,    16] train loss: 0.414 train acc: 0.805\n",
      "[73,    17] train loss: 0.413 train acc: 0.809\n",
      "[73,    18] train loss: 0.430 train acc: 0.797\n",
      "[73,    19] train loss: 0.539 train acc: 0.746\n",
      "[73,    20] train loss: 0.414 train acc: 0.819\n",
      "[73] val loss: 0.376 val acc: 0.919\n",
      "[74,     1] train loss: 0.394 train acc: 0.828\n",
      "[74,     2] train loss: 0.435 train acc: 0.793\n",
      "[74,     3] train loss: 0.444 train acc: 0.809\n",
      "[74,     4] train loss: 0.399 train acc: 0.809\n",
      "[74,     5] train loss: 0.401 train acc: 0.816\n",
      "[74,     6] train loss: 0.461 train acc: 0.773\n",
      "[74,     7] train loss: 0.428 train acc: 0.824\n",
      "[74,     8] train loss: 0.457 train acc: 0.754\n",
      "[74,     9] train loss: 0.391 train acc: 0.797\n",
      "[74,    10] train loss: 0.485 train acc: 0.781\n",
      "[74,    11] train loss: 0.471 train acc: 0.785\n",
      "[74,    12] train loss: 0.470 train acc: 0.754\n",
      "[74,    13] train loss: 0.416 train acc: 0.793\n",
      "[74,    14] train loss: 0.492 train acc: 0.746\n",
      "[74,    15] train loss: 0.400 train acc: 0.812\n",
      "[74,    16] train loss: 0.442 train acc: 0.777\n",
      "[74,    17] train loss: 0.469 train acc: 0.824\n",
      "[74,    18] train loss: 0.444 train acc: 0.762\n",
      "[74,    19] train loss: 0.404 train acc: 0.805\n",
      "[74,    20] train loss: 0.422 train acc: 0.800\n",
      "[74] val loss: 0.378 val acc: 0.917\n",
      "[75,     1] train loss: 0.382 train acc: 0.820\n",
      "[75,     2] train loss: 0.402 train acc: 0.820\n",
      "[75,     3] train loss: 0.429 train acc: 0.797\n",
      "[75,     4] train loss: 0.528 train acc: 0.734\n",
      "[75,     5] train loss: 0.432 train acc: 0.773\n",
      "[75,     6] train loss: 0.396 train acc: 0.824\n",
      "[75,     7] train loss: 0.508 train acc: 0.773\n",
      "[75,     8] train loss: 0.418 train acc: 0.797\n",
      "[75,     9] train loss: 0.390 train acc: 0.820\n",
      "[75,    10] train loss: 0.412 train acc: 0.793\n",
      "[75,    11] train loss: 0.442 train acc: 0.797\n",
      "[75,    12] train loss: 0.400 train acc: 0.762\n",
      "[75,    13] train loss: 0.435 train acc: 0.801\n",
      "[75,    14] train loss: 0.435 train acc: 0.789\n",
      "[75,    15] train loss: 0.474 train acc: 0.789\n",
      "[75,    16] train loss: 0.427 train acc: 0.789\n",
      "[75,    17] train loss: 0.418 train acc: 0.789\n",
      "[75,    18] train loss: 0.379 train acc: 0.809\n",
      "[75,    19] train loss: 0.492 train acc: 0.754\n",
      "[75,    20] train loss: 0.502 train acc: 0.735\n",
      "[75] val loss: 0.376 val acc: 0.900\n",
      "[76,     1] train loss: 0.418 train acc: 0.820\n",
      "[76,     2] train loss: 0.408 train acc: 0.801\n",
      "[76,     3] train loss: 0.441 train acc: 0.785\n",
      "[76,     4] train loss: 0.398 train acc: 0.816\n",
      "[76,     5] train loss: 0.409 train acc: 0.809\n",
      "[76,     6] train loss: 0.439 train acc: 0.809\n",
      "[76,     7] train loss: 0.448 train acc: 0.773\n",
      "[76,     8] train loss: 0.409 train acc: 0.809\n",
      "[76,     9] train loss: 0.388 train acc: 0.832\n",
      "[76,    10] train loss: 0.414 train acc: 0.805\n",
      "[76,    11] train loss: 0.451 train acc: 0.781\n",
      "[76,    12] train loss: 0.414 train acc: 0.820\n",
      "[76,    13] train loss: 0.430 train acc: 0.758\n",
      "[76,    14] train loss: 0.406 train acc: 0.793\n",
      "[76,    15] train loss: 0.434 train acc: 0.766\n",
      "[76,    16] train loss: 0.396 train acc: 0.832\n",
      "[76,    17] train loss: 0.508 train acc: 0.781\n",
      "[76,    18] train loss: 0.465 train acc: 0.777\n",
      "[76,    19] train loss: 0.431 train acc: 0.785\n",
      "[76,    20] train loss: 0.439 train acc: 0.755\n",
      "[76] val loss: 0.383 val acc: 0.913\n",
      "[77,     1] train loss: 0.428 train acc: 0.797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[77,     2] train loss: 0.427 train acc: 0.809\n",
      "[77,     3] train loss: 0.451 train acc: 0.785\n",
      "[77,     4] train loss: 0.394 train acc: 0.816\n",
      "[77,     5] train loss: 0.423 train acc: 0.805\n",
      "[77,     6] train loss: 0.388 train acc: 0.809\n",
      "[77,     7] train loss: 0.389 train acc: 0.809\n",
      "[77,     8] train loss: 0.456 train acc: 0.770\n",
      "[77,     9] train loss: 0.379 train acc: 0.805\n",
      "[77,    10] train loss: 0.471 train acc: 0.758\n",
      "[77,    11] train loss: 0.391 train acc: 0.820\n",
      "[77,    12] train loss: 0.421 train acc: 0.824\n",
      "[77,    13] train loss: 0.451 train acc: 0.793\n",
      "[77,    14] train loss: 0.385 train acc: 0.812\n",
      "[77,    15] train loss: 0.432 train acc: 0.777\n",
      "[77,    16] train loss: 0.428 train acc: 0.777\n",
      "[77,    17] train loss: 0.345 train acc: 0.852\n",
      "[77,    18] train loss: 0.441 train acc: 0.781\n",
      "[77,    19] train loss: 0.444 train acc: 0.820\n",
      "[77,    20] train loss: 0.433 train acc: 0.742\n",
      "[77] val loss: 0.350 val acc: 0.916\n",
      "[78,     1] train loss: 0.467 train acc: 0.781\n",
      "[78,     2] train loss: 0.419 train acc: 0.812\n",
      "[78,     3] train loss: 0.438 train acc: 0.793\n",
      "[78,     4] train loss: 0.378 train acc: 0.824\n",
      "[78,     5] train loss: 0.413 train acc: 0.785\n",
      "[78,     6] train loss: 0.436 train acc: 0.797\n",
      "[78,     7] train loss: 0.424 train acc: 0.816\n",
      "[78,     8] train loss: 0.404 train acc: 0.809\n",
      "[78,     9] train loss: 0.427 train acc: 0.797\n",
      "[78,    10] train loss: 0.353 train acc: 0.852\n",
      "[78,    11] train loss: 0.343 train acc: 0.840\n",
      "[78,    12] train loss: 0.454 train acc: 0.773\n",
      "[78,    13] train loss: 0.428 train acc: 0.816\n",
      "[78,    14] train loss: 0.384 train acc: 0.805\n",
      "[78,    15] train loss: 0.412 train acc: 0.777\n",
      "[78,    16] train loss: 0.443 train acc: 0.793\n",
      "[78,    17] train loss: 0.494 train acc: 0.785\n",
      "[78,    18] train loss: 0.413 train acc: 0.809\n",
      "[78,    19] train loss: 0.405 train acc: 0.816\n",
      "[78,    20] train loss: 0.427 train acc: 0.813\n",
      "[78] val loss: 0.352 val acc: 0.934\n",
      "[79,     1] train loss: 0.409 train acc: 0.820\n",
      "[79,     2] train loss: 0.493 train acc: 0.762\n",
      "[79,     3] train loss: 0.449 train acc: 0.797\n",
      "[79,     4] train loss: 0.382 train acc: 0.797\n",
      "[79,     5] train loss: 0.395 train acc: 0.793\n",
      "[79,     6] train loss: 0.388 train acc: 0.840\n",
      "[79,     7] train loss: 0.472 train acc: 0.773\n",
      "[79,     8] train loss: 0.409 train acc: 0.801\n",
      "[79,     9] train loss: 0.460 train acc: 0.762\n",
      "[79,    10] train loss: 0.360 train acc: 0.863\n",
      "[79,    11] train loss: 0.451 train acc: 0.758\n",
      "[79,    12] train loss: 0.369 train acc: 0.844\n",
      "[79,    13] train loss: 0.381 train acc: 0.809\n",
      "[79,    14] train loss: 0.435 train acc: 0.812\n",
      "[79,    15] train loss: 0.411 train acc: 0.801\n",
      "[79,    16] train loss: 0.416 train acc: 0.797\n",
      "[79,    17] train loss: 0.400 train acc: 0.828\n",
      "[79,    18] train loss: 0.491 train acc: 0.758\n",
      "[79,    19] train loss: 0.386 train acc: 0.824\n",
      "[79,    20] train loss: 0.392 train acc: 0.819\n",
      "[79] val loss: 0.345 val acc: 0.932\n",
      "[80,     1] train loss: 0.395 train acc: 0.816\n",
      "[80,     2] train loss: 0.383 train acc: 0.805\n",
      "[80,     3] train loss: 0.441 train acc: 0.770\n",
      "[80,     4] train loss: 0.402 train acc: 0.789\n",
      "[80,     5] train loss: 0.419 train acc: 0.812\n",
      "[80,     6] train loss: 0.379 train acc: 0.809\n",
      "[80,     7] train loss: 0.437 train acc: 0.793\n",
      "[80,     8] train loss: 0.439 train acc: 0.809\n",
      "[80,     9] train loss: 0.385 train acc: 0.797\n",
      "[80,    10] train loss: 0.445 train acc: 0.789\n",
      "[80,    11] train loss: 0.446 train acc: 0.789\n",
      "[80,    12] train loss: 0.402 train acc: 0.809\n",
      "[80,    13] train loss: 0.475 train acc: 0.801\n",
      "[80,    14] train loss: 0.426 train acc: 0.777\n",
      "[80,    15] train loss: 0.474 train acc: 0.770\n",
      "[80,    16] train loss: 0.434 train acc: 0.797\n",
      "[80,    17] train loss: 0.423 train acc: 0.805\n",
      "[80,    18] train loss: 0.404 train acc: 0.812\n",
      "[80,    19] train loss: 0.392 train acc: 0.832\n",
      "[80,    20] train loss: 0.413 train acc: 0.787\n",
      "[80] val loss: 0.362 val acc: 0.938\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MALDataset(Dataset):\n",
    "    def __init__(self, r_test_x, r_test_y):\n",
    "        self.r_test_x = r_test_x\n",
    "        self.r_test_y = r_test_y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.r_test_x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = torch.from_numpy(np.array(r_test_x[idx]))\n",
    "        label = [[1,0],[0,1]]\n",
    "        label = torch.from_numpy(np.array(label[r_test_y[idx]], dtype='float32'))\n",
    "        return data, label\n",
    "\n",
    "ratio = 0.7\n",
    "\n",
    "trainset = MALDataset(r_test_x[:int(len(r_test_x)*ratio)], r_test_y[:int(len(r_test_y)*ratio)])\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=256,\n",
    "                                          shuffle=True, num_workers=4)\n",
    "\n",
    "valset = MALDataset(r_test_x[int(len(r_test_x)*ratio):], r_test_y[int(len(r_test_y)*ratio):])\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=128,\n",
    "                                          shuffle=True, num_workers=4)\n",
    "# Define a Loss function and optimizer\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "train_accs = []\n",
    "train_losses = []\n",
    "val_accs = []\n",
    "val_losses = []\n",
    "\n",
    "\n",
    "#Train the network\n",
    "for epoch in range(80):  # loop over the dataset multiple times\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    train_tot_acc = 0\n",
    "    train_tot_loss = 0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        outputs = F.softmax(outputs, dim=1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        outputs = outputs.detach().cpu().numpy()\n",
    "        labels = labels.detach().cpu().numpy()\n",
    "        outputs = outputs[:,1] > outputs[:,0]\n",
    "        labels = labels[:,1] > labels[:,0]\n",
    "        acc = np.sum(outputs.astype(\"int32\") == labels.astype(\"int32\"))/len(labels)\n",
    "#         print(outputs.astype('int32'), labels.astype(\"int32\"))\n",
    "        train_acc += acc\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        train_tot_loss += loss.item()\n",
    "        train_tot_acc += acc\n",
    "        if i % 1 == 0: \n",
    "            print('[%d, %5d] train loss: %.3f train acc: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 1, train_acc/ 1))\n",
    "            running_loss = 0.0\n",
    "            train_acc = 0.0\n",
    "    \n",
    "    net.eval()\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    for i, data in enumerate(valloader, 0):\n",
    "        inputs, labels = data\n",
    "        outputs = net(inputs)\n",
    "        outputs = F.softmax(outputs, dim=1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        val_loss += loss.item()\n",
    "        outputs = outputs.detach().cpu().numpy()\n",
    "        labels = labels.detach().cpu().numpy()\n",
    "        outputs = outputs[:,1] > outputs[:,0]\n",
    "        labels = labels[:,1] > labels[:,0]\n",
    "        acc = np.sum(outputs.astype(\"int32\") == labels.astype(\"int32\"))/len(labels)\n",
    "        val_acc += acc\n",
    "    print('[%d] val loss: %.3f val acc: %.3f' %\n",
    "              (epoch + 1, val_loss / len(valloader), val_acc/len(valloader)))\n",
    "    train_accs.append(train_tot_acc/len(trainloader))\n",
    "    train_losses.append(train_tot_loss/len(trainloader))\n",
    "    val_accs.append(val_acc / len(valloader))\n",
    "    val_losses.append(val_loss / len(valloader))\n",
    "\n",
    "PATH = './Path/dlmal_e_net.pth'\n",
    "torch.save(net, PATH)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4144c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(train_accs)\n",
    "plt.plot(val_accs)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train_losses)\n",
    "plt.plot(val_losses)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss', 'val_loss'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "892f8dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITACLFGGIIEKGLVTYMALGLAL\n",
      "LQSVNQLLLTATKERIDFLPHYDTL\n",
      "QPLLLSEDEEDTKRVVRSAKDKRFE\n",
      "QPLLLSEDEEDTKRVVRSAKDKRFE Q 302\n",
      "INTKFFQEENTEKLKLKYYNLMIQL\n",
      "SATVDQRLPECAKLAKEGRLQEVIE\n",
      "QVRVLELENELQKERQKLGELRKKH\n",
      "QVRVLELENELQKERQKLGELRKKH Q 305\n",
      "VYEWARDHRAHHKFSETHADPHNSR\n",
      "AEKFPSPHPSPAKLKATAGHOOOOO\n",
      "GGDGLDPAAMEGKDEPLEFKRVLDN\n",
      "KLYSILQGDSPTKWRTEDFRMFKNG\n",
      "SSSGRRVKSPSPKSERSERSERSHK\n",
      "MESLEQRAIDLYKQLKHRPSDHSYS\n",
      "LIYITLYISECLKKLQKCNSKSQGE\n",
      "ETLYVYELLGVPKPKESTTGLLKAR\n",
      "NLPHTPRYYDILKKRLQLPVWEYKD\n",
      "SVVGTDALKKTKKDDEKSKKSKEEY\n",
      "TNWNKRDFNQFIKANEKWGRDDIEN\n",
      "IRQDIEDSVSRMKPWQSEYGGVVFG\n",
      "AKKGKDEWFSRGKKPIEDPANDTVD\n",
      "SKTIRKEVGRFEKERVKDFKTVIIK\n",
      "KATVKAMQEALAKLKEEEERQKREE\n",
      "DIGKPIEKGPRAKOOOOOOOOOOOO\n",
      "KLRENKEFLEFRKARSDMLLSRKNQ\n",
      "QPVRKVQSATHFKKVRGPSRADPNH\n",
      "QPVRKVQSATHFKKVRGPSRADPNH Q 323\n",
      "FPSIGSGRNGFPKQTAAQLILKAIS\n",
      "SGTKAEVSIQNNKDGTYAVTYVPLT\n",
      "QPQHNGESNEDSKDNHEASTKKKPS\n",
      "QPQHNGESNEDSKDNHEASTKKKPS Q 326\n",
      "LVEQTLSDLEQSKCISIEDEMDVAP\n",
      "DMDYSRIIERLLKLAVPNHLIWLIF\n",
      "ARREKELEARVRKPAEAERYKLERL\n",
      "DWIENHGEAFLSKHTGVGKSLHRAR\n",
      "LLDMSVSFHTHVKELWTWLEELQKE\n",
      "NTSTAEEELCRLKLLAKHPCHIKKF\n",
      "ENLERQQKQQVEKMEQDHAVRRREE\n",
      "GFLAAFDTAWMVKSWNQGTPPLELL\n",
      "GSTSKEGEPNLDKKNTPVQSPVSLG\n",
      "SVFAEDDVKVVEKYFSGPAITLENT\n",
      "ALKNKAAKGSATKDFSVFFQKIRET\n",
      "QLKIKELDHNISKHKREAEDGAAKV\n",
      "QLKIKELDHNISKHKREAEDGAAKV Q 338\n",
      "CSWVASATQNVPKPPSLTVLEGDGR\n",
      "OOOOMEIIRSNFKSNLHKVYQAIEE\n",
      "MVLCPVIGKLLHKRVVLASASPRRQ\n",
      "ITPMLQVIRAIMKDPDDHTVCHLLF\n",
      "EISDGDVIISGNKNLCYANTINWKK\n",
      "TFNPSSDVAALHKAIMVKGVDEATI\n",
      "EITYDKLNKWTSKDKMAEDEVEVYI\n",
      "IVLIGLALLLIWKLLMIIHDRREFA\n",
      "KGPQVRDWSHYFKIIEDLRAQIFAN\n",
      "RKAPSDLYQIILKALERGSLLGCSI\n",
      "GYLTAEQFDEWVKPKDMLGPKOOOO\n",
      "EKSNKSTKSDAPKEKGKKAPRVWEL\n",
      "SGGLPTDEITFAKLLKDQGYSTALI\n",
      "FTLTISALFVTPKTTGARVELSEQQ\n",
      "LLPDNFIAACTEKKIPVVFRLQEGY\n",
      "QYEGTYKWVNPHKLOOOOOOOOOOO\n",
      "QYEGTYKWVNPHKLOOOOOOOOOOO Q 354\n",
      "SEYTVVADISVAKIDPLAPLDKVCL\n",
      "NKRINKYLDEIVKEVEAKAPILKRQ\n",
      "QDVDMVFASFIRKASDVHEVRKVLG\n",
      "QDVDMVFASFIRKASDVHEVRKVLG Q 357\n",
      "AHLYRGIFPVLCKDPVQEAWAEDVD\n",
      "EEEETAKESTAEKDELOOOOOOOOO\n",
      "SLEEIYLFSLPIKESEIIDFFLGAS\n",
      "LQTQWSWILQITKCIDVHLKENAAY\n",
      "NSQGSEMFGDDDKRKIQSQFTDAQK\n",
      "VAKSPKKAKAAAKPKKATKSPAKPK\n",
      "PKAAKAKKAAAKKKOOOOOOOOOOO\n",
      "GRGGGGDHKPQGKKTKFEOOOOOOO\n",
      "AEQQPSEKSTEPKTKPQDMISAGGE\n",
      "NSSAQIDIVISNKAAVAGLDKAERA\n",
      "KLRVLARSSPTDKHTLVKGIIDSTV\n",
      "LTTKNVSIGIVGKDLEFTIYDDDDV\n",
      "QVIMSIRTKLQNKEHVIEALRRAKF\n",
      "QVIMSIRTKLQNKEHVIEALRRAKF Q 370\n",
      "GLSMGTMICGWDKRGPGLYYVDSEG\n",
      "DDLNNYDSDDQEKQSKKKPRLFCDI\n",
      "TAEFAELKTQIEKMRLDYQHEIENL\n",
      "VQNCSLEDSQIEKERDVILREMQEN\n",
      "QLLKEQERTLALKLQEQEQLLKEGF\n",
      "QLLKEQERTLALKLQEQEQLLKEGF Q 375\n",
      "LTEEEEKSKSLAKLKNKHEAMITDL\n",
      "IDPTVTMMQVEEKPDVTYSDVGGCK\n",
      "VENLQDDFDFNYKTLKSQGDMQDLN\n",
      "AMTIPFVRQQVYKKVEEKVRKQTKG\n",
      "QLLADHANSPNKKFYQOOOOOOOOO\n",
      "QLLADHANSPNKKFYQOOOOOOOOO Q 380\n",
      "PLVLKTGVQFTVKLRLLVKLQELNY\n",
      "TGELEAAKALVLKRIQIWKRQQQLA\n",
      "KPFSLMKASSRFKAHQDALPRLPVP\n",
      "LKKEFLHAQEEVKRIQSIPLVIGQF\n",
      "QRELTNLLGLHPKIEMARASCSALM\n",
      "QRELTNLLGLHPKIEMARASCSALM Q 385\n",
      "GGLKALSKEKREKLEAYQHLFYLLQ\n",
      "GMYEQLKGEWNRKSPNLSKCGEELG\n",
      "LLELNFLPTTGTKLTKQQLILARDI\n",
      "GLAAAAGTRIMGKEIEAEAQRPLRQ\n",
      "KAAPAPKAQKGQKAPAQKAPAPKAS\n",
      "NQYVNKKFSNQYKATIGADFLTKEV\n",
      "TATSGFAGAIGQKLPPFSYAYTELE\n",
      "LRDTPPPQSLMVKITLDLLSRIPQP\n",
      "YQEGLRVMGEVGKTTGIPIHVFGTE\n",
      "ATILHLGKSSLPKKPITDDDVDRIS\n",
      "AAKALDDKNCWEKLGEVALLQGNHQ\n",
      "NILRKSLQAERNKPTKNMINIISRL\n",
      "NSDLQGVNVISVKDNDSLAARLAVE\n",
      "LESKKPKGFFGYKSEIFNENFGPDF\n",
      "QDEYALRSHSLAKKAQDEGLLSDVV\n",
      "QDEYALRSHSLAKKAQDEGLLSDVV Q 400\n",
      "HATGFNYQNEDEKVTLSFPSTLQTG\n",
      "FLSRKTLVEFPQKVLSPFRKQGSDS\n",
      "NWDAAMEDLTRLKETIDNNSVSSPL\n",
      "AVVVTNTIPQEDKMKHCSKIQVIDI\n",
      "OOOOOOMAPIGLKAVVGEKIMHDVI\n",
      "EGKELEFYLRKIKARKGKOOOOOOO\n",
      "WDLEGKIIVDELKQEVISTSSKAEP\n",
      "RRYQKSTELLIRKLPFQRLVREIAQ\n",
      "QGQSKDMPPRFSKKGQLNADEISLR\n",
      "QGQSKDMPPRFSKKGQLNADEISLR Q 409\n",
      "EIIKTLSKEEETKKOOOOOOOOOOO\n",
      "FQVWLKNGVILSKLVNSLYPDGSKP\n",
      "QEREDVLAGMSGKAIKGKVGKPKVK\n",
      "QEREDVLAGMSGKAIKGKVGKPKVK Q 412\n",
      "KPSDLRPGDVSSKRNLWEKQSVDKV\n",
      "INANIIMPEFETKCNNSKPKKSYIA\n",
      "GIWRRVALGHGLKLLTKNGHVYKYD\n",
      "SATPRSKPVCIHKNSECLKEQQKRY\n",
      "PKMKGDYDVTVPKVEGEIKAPDVDI\n",
      "QDLRRTESDSGLKKGGNANLVFMLK\n",
      "QDLRRTESDSGLKKGGNANLVFMLK Q 418\n",
      "CLLIADQHCRTRKYFLCLASGIPCV\n",
      "YQIKGSPNLTLPKESYIQEDDIYDD\n",
      "VHPFPDHELEDMKMKISALKSEIQK\n",
      "EGTVKAYVWDNNKDLAEWLEKQLTE\n",
      "KLEKLDTDLKNYKGNSIKESIRRGH\n",
      "AAVFRSMNSALGKSPWLAGNELTVA\n",
      "RKFFGDKTIVPWKVFRQCLHEVHQI\n",
      "GSVKSFSLGPLRKAVTLNPDNSYIK\n",
      "YVLRYAAKFYRRKNSWNKALELLKK\n",
      "MALGGTIGLTIAKRIQISDLPQLVA\n",
      "LKNYNQQKDIEHKELVQKLQHFQEL\n",
      "AIGPFSGLKEVRKVVLDTMKNIHPI\n",
      "GLELYKRLKEFLKNYLTNLLKDGED\n",
      "CTELNQAWSSLGKRADQRKAKLGDS\n",
      "DVGSLVYVMEDGKVEVTKEGVKLCT\n",
      "HVAVTEMAALFPKKPKSDMVRTSLR\n",
      "QKLKQDGDSFRMKLNTQEIFDDWAR\n",
      "QKLKQDGDSFRMKLNTQEIFDDWAR Q 435\n",
      "ITQAVIFLNTRRKVDWLTEKMHARD\n",
      "APVPPVNEPETLKQQNQYQASYNQS\n",
      "TANQWDYKNIIEKLQDIITALEERL\n",
      "ASNYELSDNAGCKEVNSVNCNTSWK\n",
      "AKHKGYSPPESRKSNSKAPKVQSNT\n",
      "LKEKKERLTEELKEQMKAKRKEAEL\n",
      "KDIKKEKVLLRRKSELPQDVYTIKA\n",
      "QFTVLSLSAGRPKRPHARRALCLLL\n",
      "QFTVLSLSAGRPKRPHARRALCLLL Q 443\n",
      "SALQGGTSVAQIKAQLKEIEAEKVE\n",
      "ELNFHKAQEIYEKNLDEKAKEISNL\n",
      "LQMEKAKTHYDAKKQQNQELQEQLR\n",
      "EWNALETECHSLKRENVLLSSELQR\n",
      "IIKVAISNPPQRKVPEKPETRKAPG\n",
      "EDVKGRIYQLLAKASYKKAIILTRE\n",
      "YLDLILNDFVRQKFIIRSKIITYIR\n",
      "LDSGNESKEKLLKGESALQRVQCIP\n",
      "LVTLWHQLHVDMKSLLAWQSLRRDV\n",
      "VIAGVWLEEAGQKLSIYNALKKDLL\n",
      "QLTGLSLLPLSEKAARARQEELYSE\n",
      "QLTGLSLLPLSEKAARARQEELYSE Q 454\n",
      "CFAKTLVEHVGMKNLKSWASVNRGA\n",
      "PEDDTKEKIGPSKPNEIPQQPPPPS\n",
      "SSASVIFEGVDIKNGTEDLPYAMKP\n",
      "SALDSTNVEEAFKNILTEIYRIVSQ\n",
      "FDIQNDRNSILPKSQSEYKPDTPQS\n",
      "ALLGVFCHTDLRKNLTVDEGTMKVE\n",
      "QLKDLNLLDRCIKETLRLRPPIMIM\n",
      "QLKDLNLLDRCIKETLRLRPPIMIM Q 461\n",
      "FLGGARITVLASKTSQRYRIQSEQF\n",
      "SEVFKFSSKNQLKTLQEVHFLLHPS\n",
      "INISLDHKRPLIKVLGISRDVMQAR\n",
      "RIEVENKEVLHGKKWKGLTHNLLKK\n",
      "MLTGDMGSLDDPKMKSMMPTDEQFA\n",
      "LPHPRWSAEASGKPSPSDPGSGTAT\n",
      "AMSTTAKGSKSLKVELIEDKIDYTK\n",
      "YPPNKVMIWDDLKKKTVIEIEFSTE\n",
      "PPSAASAAPSSSKQPAADTEASEQQ\n",
      "PSPSSAEKVKANKDVASPLKELGLR\n",
      "QLSALLKQADSSKRKLTLTRLASAP\n",
      "QLSALLKQADSSKRKLTLTRLASAP Q 472\n",
      "NNGTVLRASHGTKMMTPEVLAEAYG\n",
      "QAVHAAKVILQVKESLGLNGDFSVL\n",
      "QAVHAAKVILQVKESLGLNGDFSVL Q 474\n",
      "LAIGVCYHASLEKKDSYRKAIARFF\n",
      "PFEAVMRTLCECKETASKTLSRFGI\n",
      "HTIALWQFLSAHKSEQLLRLHKEPF\n",
      "DIVYMKPHGRLQKVMNHITDGPRKD\n",
      "VSRTSTAPLDRLKIMMQVHGSKSDK\n",
      "LSGRVLQEMASLKRQFTELLSDIGF\n",
      "KARLGRMVVASDKSGQPVTADDLGV\n",
      "MEVLHLYGSEEQKKQWLEPLLQGNI\n",
      "IFSLSNLQELDLKSNNIRTIEEIIS\n",
      "PGQKEKRVRPEEKQQAKPVKVERTR\n",
      "PPALRPKPAVLPKTNPTIGPAPPPQ\n",
      "KVRKEALLLLSWKQMLDHFQATPHH\n",
      "FKHTVDDGLDIRKAAFECMYTLLDS\n",
      "KPYVENIWALLLKHCECAEEGTRNV\n",
      "LIAAAKYPSYIHKMVIWGANAYVTD\n",
      "DQSERNKVISDFKKKDIPVLVATDV\n",
      "NNSREGTGGSNGKRERYTENRGSSR\n",
      "EKVSLLQGDLSEKEASLLDLKEHAS\n",
      "DIKGPKLDLKDPKVEMRVPDVEVSL\n",
      "QAFTCNTADAPSKDIFVKLTTMAMY\n",
      "QAFTCNTADAPSKDIFVKLTTMAMY Q 494\n",
      "FLCDLLLRLEQAKEAESKDALKDLV\n",
      "GYRWERQLVFRSKLTMHTAFDRKDN\n",
      "AVRFLGCFSDLRKISAMNVFPSNTQ\n",
      "YHSVSTPPVYPPKNVADLKLHVTTS\n",
      "FSSMVESELHAAKTKQAWNFLSHLP\n",
      "FPTQGHDYVLAEKQVQRSRNKQVRE\n",
      "AVKKLKNSLPLRKELDRLKDELSHQ\n",
      "TFEELEHVSAPYKTGSKGTKAQRAR\n",
      "GEGEVKLNMAIGKGEQALRSSNKEG\n",
      "DAESTAVHLEALKKLALALQERKYA\n",
      "RTFTKWINSHLAKRKPPMVVDDLFE\n",
      "IGRLLSEDFVSVKVDREERPDVDKV\n",
      "QVKLYKLNLESSKQELIDYKQKATR\n",
      "QVKLYKLNLESSKQELIDYKQKATR Q 507\n",
      "GLSAFLSQEEINKSLDLARRAIADS\n",
      "SKVALQAQIENHKVFFQKLVADMLL\n",
      "IAKLEEQWLSLNKKIDHELHRLQAL\n",
      "SPSVISDLFTDIKKGHVLLDLLEVL\n",
      "VQALTQQQQSPTKAVPALGKSPPHH\n",
      "LGRLRRATEYAPKKRIEPLSPELVA\n",
      "QKIKEKLEIALEKHQDSSMRKFQEQ\n",
      "QKIKEKLEIALEKHQDSSMRKFQEQ Q 514\n",
      "RTILPMSRAFRGKHLSFVVRFPNQG\n",
      "OMQELTLSPGPAKLTPTLDPTHRME\n",
      "SGSIYSSPGLYSKTMTPTYDAHDGS\n",
      "LNPIEVAIDEMSKKVSELNQLCTME\n",
      "DARRFDGVDAEFKELMFKTAKVENV\n",
      "FEKLERLEFGGTKGAILNGQVHEMS\n",
      "LDVCKQLYNEHMKQIECGHVVLNKN\n",
      "LAEAYEVLSDEVKRKQYDAYGSAGF\n",
      "HFPIGPDVEDLVKEAVSQVRAEATT\n",
      "VYQLLVNEQEPCKFLLDAVFAKGMT\n",
      "AVYLTPESKSSFKQALEALPQLSSG\n",
      "VLNRRWSRLCLPKQYLFTMKLQSPE\n",
      "SKVDDKWEKKCQKIFSFAHQTISAL\n",
      "NTDKNGEELHGGKRVMECLKKALKI\n",
      "HKAAIEVYNEAAKLNQKDWEISHNL\n",
      "RPQSPSPRRETGKESRKSQSPSPKN\n",
      "LDDAIEDCTNAVKLDDTYIKAYLRR\n",
      "AEPSTVPGTPPPKKFRSLFFGSILA\n",
      "AWVQTLCRNAFPKGSWTLAPTDNPP\n",
      "LNKRRGFVFITFKEEEPVKKVLEKK\n",
      "AIVDAEWNILYDKLEKIHHSGAKVV\n",
      "GPVEQQLLQETEKLMKEKLEVQCQA\n",
      "LVKDQEALMKSVKLLQALAQYQNHL\n",
      "SIRRIKDYDANFKIKDFPEKAKDIF\n",
      "GSSGGAPPEEPPKEGNPAEINVERD\n",
      "SFEQMTDAHVWNKSVTLYTVKDKAT\n",
      "PWVRAKKPENCEKLVTLLENYKEMY\n",
      "TIGKLEPSYVIRKFLDAQRIHNLTA\n",
      "SNKPIRELIAEAKAEVTEEVEDGKE\n",
      "ECAIQTCPELLRKDFESLFPEVANG\n",
      "GQGRDNALTLLIKAVPRKSLKDPNN\n",
      "ADSETVKAAKVWKLAEVLVGEQQQC\n",
      "QYLKQIEPSLYPKLFQKNLDPDVFN\n",
      "QYLKQIEPSLYPKLFQKNLDPDVFN Q 547\n",
      "RGPSCRQGRGIQKPQRQALYRGLEN\n",
      "KGKMWEKAIKLSKELAETYESKVFD\n",
      "NLVTFTPSKDSTKDSFQIATLICST\n",
      "VEKFFTEEVDSRKIDQEGKIPDETL\n",
      "GQDVGSFAYLTIKDRIPQILTKVID\n",
      "ASEELQKDLEEVKVLLEKATRKRVR\n",
      "EEVKVLLEKATRKRVRDALTAEKSK\n",
      "ENTVAALKSEFQKTLNDKTENQKSL\n",
      "GSGDTNNFPYLEKTAKKGRPMVISS\n",
      "NIFIECTGTDFTKAKIVLDIIVTMF\n",
      "KNYRHLCAVYYNKNPGFEIIHGLLD\n",
      "IDRVSTEVTLAVKKDVPPSAVTRPI\n",
      "KKRKLPSDVNEGKTVFIRNLSFDSE\n",
      "LRIQRSLQKMRSKPATGEPQKGQPE\n",
      "RKRRHSEVETDSKKKKMKLPEHPEG\n",
      "KSHVYSLEGQDCKYTPMFGPEARTL\n",
      "SSSNKKLPSDEPKSSCILQITVEEF\n",
      "LPLELGTFHQLFKHLGTEDIISTKQ\n",
      "TYSQRFFVPPTFKSVGNPVEARRWL\n",
      "AQEEIMKLKDTLKSQMTQEASDEAE\n",
      "EVVQIRSEVSQVKREKENIQTLLKS\n",
      "NANSCPVDRTLFKCICIRAQFGGKI\n",
      "FLVPELQATEEEKSKLESGLTNGDE\n",
      "EWPFLIITDLFLKSPELVQAMFPKL\n",
      "RTGLGRLGVSLSKGLHHKAVLAVRR\n",
      "EYRGQAQAIEFLKEQISLAEKKMLD\n",
      "VSALESKCKSGEKKVDALLKEKRRL\n",
      "FKRDGSNIIYTAKISLREALCGCSI\n",
      "SVVRDLGFFGIYKGAKACFLRDIPF\n",
      "TVELLSGVVDQTKDGLISFQEFVAF\n",
      "FCRVKDPNSGLPKFVLINWTGEGVN\n",
      "OOOOOOOOOMSLKLQASNVTNKNDP\n",
      "RVKPEEMMDERPKTRSQEQEVLERG\n",
      "GGLSPLSSPSDTKAESPAEKVPEES\n",
      "AGLQLVVVILPGKTPVYAEVKRVGD\n",
      "KRLKLRFYRTSVKEDLNVNEVFKYL\n",
      "LKGDLKGVKGDLKKPFDKAWKDYET\n",
      "EKPTVQQLQILWKAINCPEDIVFPA\n",
      "ATLALNYSVCFHKDHNIEGKAQCLS\n",
      "MTMYNQATQEIAKPSELLTSVRAYM\n",
      "VDTEIEEKDEETKAFEALLSNIVKP\n",
      "IRVAAKWYNEHLKKMSADNQLQVIF\n",
      "RPAGPELQTPPGKDGAVEDEEGEGE\n",
      "EQQQHRSGGRGNKTRNSNNNNTAAA\n",
      "SALLSAAFLLVRKLPPLCHGLPTQR\n",
      "FLEKINKNCWRIKKGFVPNMQVEGV\n",
      "PPPNTDPWLLRSKSPVGNPQLIQFS\n",
      "DKNIVVDDITEQKPEPQDDGKSTES\n",
      "KKYATLSLFNTYKGKSLETQKTTVA\n",
      "LKNTPSFLIACNKQDIAMAKSAKLI\n",
      "RKNTKEMFGGFFKSVVKSADEVLFT\n",
      "IFTVQMDDYLGGKPVQNRELQGYES\n",
      "(600, 1, 25)\n",
      "[[[ 5  2 15 ...  9 11 11]]\n",
      "\n",
      " [[ 1 13 12 ... 20 12  3]]\n",
      "\n",
      " [[ 3 14  1 ...  6  2 12]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[11 12  3 ... 12 11 10]]\n",
      "\n",
      " [[ 2 12  3 ... 11 14 17]]\n",
      "\n",
      " [[10 14 17 ... 19  7 16]]]\n"
     ]
    }
   ],
   "source": [
    "r_test_x = []\n",
    "r_test_y = []\n",
    "posit_1 = 1;\n",
    "negat_0 = 0;\n",
    "\n",
    "# define universe of possible input values\n",
    "alphabet = 'OARNDCQEGHILKMFPSTWYV'\n",
    "# define a mapping of chars to integers\n",
    "char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
    "\n",
    "i = 0\n",
    "#-------------------------TEST DATASET----------------------------------------\n",
    "#for positive sequence\n",
    "def innertest1():\n",
    "    #Input\n",
    "    data = seq_record.seq\n",
    "    #rint(data) \n",
    "    # integer encode input data\n",
    "    for char in data:\n",
    "        if char not in alphabet:\n",
    "            return\n",
    "    integer_encoded = [char_to_int[char] for char in data]\n",
    "    r_test_x.append(integer_encoded)\n",
    "    r_test_y.append(posit_1)\n",
    "for seq_record in SeqIO.parse(\"./Datasets/independent_data/H_test.fasta\", \"fasta\"):\n",
    "    innertest1()\n",
    "    i += 1\n",
    "\n",
    "\n",
    "#for negative sequence\n",
    "def innertest2():\n",
    "    #Input\n",
    "    data = seq_record.seq\n",
    "    print(data) \n",
    "    # integer encode input data\n",
    "    for char in data:\n",
    "        if char not in alphabet:\n",
    "#             print(data, i)\n",
    "            return\n",
    "    integer_encoded = [char_to_int[char] for char in data]\n",
    "    if integer_encoded[0] == 6: print(data, int_to_char[6], len(r_test_x))\n",
    "    r_test_x.append(integer_encoded) \n",
    "    r_test_y.append(negat_0)\n",
    "for seq_record in SeqIO.parse(\"./Datasets/independent_data/H_test_neg.fasta\", \"fasta\"):\n",
    "    innertest2()\n",
    "# Changing to array (matrix)    \n",
    "r_test_x = np.array(r_test_x)\n",
    "r_test_y = np.array(r_test_y)\n",
    "\n",
    "# Balancing test dataset\n",
    "# Testing Data Balancing by undersampling####################################\n",
    "# rus = RandomUnderSampler(random_state=7)\n",
    "# x_res3, y_res3 = rus.fit_resample(r_test_x, r_test_y)\n",
    "# #Shuffling\n",
    "# r_test_x, r_test_y = shuffle(x_res3, y_res3, random_state=7)\n",
    "# r_test_x = np.array(r_test_x)\n",
    "# r_test_y = np.array(r_test_y)\n",
    "\n",
    "r_test_x = np.expand_dims(r_test_x, 1)\n",
    "print(r_test_x.shape)\n",
    "print(r_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c82050f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5  2 15 18  1 16  2  1  1  1  2 15 12 15 16  1 16  7 20 11 17  2  9 11\n",
      "  11]]\n",
      "['C', 'R', 'P', 'W', 'A', 'S', 'R', 'A', 'A', 'A', 'R', 'P', 'K', 'P', 'S', 'A', 'S', 'E', 'V', 'L', 'T', 'R', 'H', 'L', 'L']\n",
      "tensor([[0.6445, 0.3555]], grad_fn=<SoftmaxBackward>)\n",
      "[[10 14 17 20  6 13  4  4 19 11  8  8 12 15 20  6  3  2  7 11  6  8 19  7\n",
      "  16]]\n",
      "['I', 'F', 'T', 'V', 'Q', 'M', 'D', 'D', 'Y', 'L', 'G', 'G', 'K', 'P', 'V', 'Q', 'N', 'R', 'E', 'L', 'Q', 'G', 'Y', 'E', 'S']\n",
      "tensor([[0.7703, 0.2297]], grad_fn=<SoftmaxBackward>)\n",
      "['C', 'R', 'P', 'W', 'A', 'S', 'R', 'A', 'A', 'A', 'R', 'P', 'K', 'P', 'S', 'A', 'S', 'E', 'V', 'L', 'T', 'R', 'H', 'L', 'L'] [[0.6445085  0.35549146]]\n",
      "['L', 'G', 'S', 'I', 'L', 'K', 'T', 'N', 'V', 'R', 'A', 'C', 'K', 'A', 'V', 'G', 'H', 'P', 'F', 'V', 'I', 'Q', 'L', 'G', 'R'] [[0.504349   0.49565095]]\n",
      "['S', 'S', 'Y', 'N', 'L', 'V', 'P', 'R', 'Y', 'I', 'P', 'Q', 'K', 'Q', 'S', 'E', 'D', 'M', 'H', 'A', 'F', 'V', 'T', 'E', 'V'] [[0.6211862  0.37881377]]\n",
      "['A', 'Q', 'L', 'A', 'Q', 'R', 'I', 'S', 'S', 'N', 'I', 'Q', 'K', 'I', 'T', 'Q', 'C', 'S', 'V', 'E', 'I', 'Q', 'R', 'T', 'L'] [[0.7420042  0.25799578]]\n",
      "['V', 'A', 'A', 'T', 'L', 'K', 'K', 'Q', 'K', 'K', 'N', 'T', 'K', 'D', 'E', 'F', 'E', 'E', 'R', 'A', 'K', 'A', 'I', 'I', 'V'] [[0.60786784 0.39213213]]\n",
      "['P', 'D', 'S', 'T', 'H', 'L', 'L', 'S', 'A', 'S', 'G', 'D', 'K', 'T', 'S', 'K', 'I', 'W', 'D', 'V', 'S', 'V', 'N', 'S', 'V'] [[0.5750065  0.42499352]]\n",
      "['N', 'S', 'L', 'C', 'F', 'P', 'E', 'D', 'A', 'E', 'I', 'S', 'K', 'H', 'A', 'K', 'N', 'L', 'I', 'C', 'A', 'F', 'L', 'T', 'D'] [[0.7156842  0.28431582]]\n",
      "['G', 'C', 'G', 'R', 'T', 'D', 'F', 'Q', 'Q', 'G', 'C', 'A', 'K', 'T', 'L', 'Y', 'H', 'S', 'V', 'H', 'E', 'K', 'I', 'F', 'T'] [[0.7886904  0.21130958]]\n",
      "['K', 'Q', 'S', 'A', 'A', 'L', 'C', 'L', 'L', 'R', 'L', 'Y', 'K', 'A', 'S', 'P', 'D', 'L', 'V', 'P', 'M', 'G', 'E', 'W', 'T'] [[0.6021792  0.39782086]]\n",
      "['N', 'L', 'N', 'H', 'V', 'S', 'Y', 'G', 'R', 'L', 'T', 'F', 'K', 'Y', 'E', 'R', 'D', 'S', 'N', 'Y', 'H', 'L', 'L', 'M', 'S'] [[0.5219822  0.47801775]]\n",
      "['H', 'L', 'G', 'R', 'P', 'D', 'G', 'V', 'P', 'M', 'P', 'D', 'K', 'Y', 'S', 'L', 'E', 'P', 'V', 'A', 'V', 'E', 'L', 'K', 'S'] [[0.84640896 0.15359104]]\n",
      "['R', 'C', 'L', 'V', 'E', 'K', 'G', 'D', 'V', 'A', 'F', 'V', 'K', 'H', 'Q', 'T', 'V', 'P', 'Q', 'N', 'T', 'G', 'G', 'K', 'N'] [[0.5312554  0.46874458]]\n",
      "['Y', 'S', 'R', 'L', 'N', 'L', 'N', 'N', 'T', 'V', 'L', 'S', 'K', 'R', 'K', 'L', 'T', 'W', 'F', 'V', 'N', 'E', 'G', 'L', 'V'] [[0.54601747 0.4539825 ]]\n",
      "['G', 'Q', 'T', 'Y', 'C', 'D', 'L', 'R', 'S', 'L', 'N', 'A', 'K', 'A', 'V', 'V', 'A', 'A', 'L', 'M', 'K', 'A', 'O', 'O', 'O'] [[0.63446355 0.36553645]]\n",
      "['I', 'N', 'T', 'E', 'F', 'K', 'N', 'T', 'R', 'T', 'N', 'E', 'K', 'V', 'E', 'L', 'Q', 'E', 'L', 'N', 'D', 'R', 'F', 'A', 'N'] [[0.5611686  0.43883142]]\n",
      "['L', 'N', 'N', 'S', 'H', 'Y', 'Y', 'H', 'M', 'A', 'H', 'G', 'K', 'D', 'F', 'A', 'S', 'R', 'G', 'I', 'E', 'M', 'S', 'E', 'V'] [[0.70757467 0.29242536]]\n",
      "['D', 'L', 'I', 'K', 'M', 'I', 'F', 'D', 'V', 'E', 'S', 'M', 'K', 'K', 'A', 'M', 'V', 'E', 'Y', 'E', 'I', 'D', 'L', 'Q', 'K'] [[0.78654104 0.21345894]]\n",
      "['L', 'G', 'S', 'I', 'K', 'A', 'I', 'P', 'R', 'F', 'N', 'Q', 'K', 'G', 'E', 'V', 'Y', 'K', 'A', 'Q', 'I', 'M', 'N', 'V', 'S'] [[0.51939 0.48061]]\n",
      "['K', 'T', 'L', 'L', 'A', 'R', 'A', 'C', 'A', 'A', 'Q', 'T', 'K', 'A', 'T', 'F', 'L', 'K', 'L', 'A', 'G', 'P', 'Q', 'L', 'V'] [[0.63725775 0.36274225]]\n",
      "['M', 'V', 'R', 'Y', 'S', 'L', 'D', 'P', 'E', 'N', 'P', 'T', 'K', 'S', 'C', 'K', 'S', 'R', 'G', 'S', 'N', 'L', 'R', 'V', 'H'] [[0.5418822 0.4581178]]\n",
      "['S', 'R', 'N', 'Y', 'L', 'S', 'Q', 'P', 'R', 'L', 'T', 'Y', 'K', 'T', 'V', 'S', 'G', 'V', 'N', 'G', 'P', 'L', 'V', 'I', 'L'] [[0.53651077 0.46348926]]\n",
      "['R', 'S', 'I', 'V', 'D', 'N', 'W', 'P', 'E', 'N', 'H', 'V', 'K', 'A', 'V', 'V', 'V', 'T', 'D', 'G', 'E', 'R', 'I', 'L', 'G'] [[0.58619 0.41381]]\n",
      "['O', 'O', 'O', 'M', 'A', 'D', 'L', 'A', 'E', 'C', 'N', 'I', 'K', 'V', 'M', 'C', 'R', 'F', 'R', 'P', 'L', 'N', 'E', 'S', 'E'] [[0.8247281  0.17527193]]\n",
      "['G', 'L', 'V', 'A', 'A', 'K', 'V', 'I', 'P', 'S', 'P', 'F', 'K', 'H', 'A', 'D', 'I', 'V', 'T', 'T', 'T', 'T', 'H', 'K', 'T'] [[0.55883443 0.44116554]]\n",
      "['K', 'L', 'R', 'N', 'W', 'Q', 'W', 'W', 'R', 'L', 'F', 'T', 'K', 'V', 'K', 'P', 'L', 'L', 'Q', 'V', 'S', 'R', 'Q', 'E', 'E'] [[0.59483707 0.40516293]]\n",
      "['L', 'E', 'A', 'L', 'M', 'F', 'D', 'R', 'S', 'F', 'V', 'G', 'K', 'Q', 'F', 'S', 'A', 'N', 'D', 'K', 'V', 'Y', 'T', 'V', 'E'] [[0.5137309  0.48626906]]\n",
      "['R', 'T', 'D', 'F', 'K', 'E', 'E', 'P', 'E', 'P', 'G', 'F', 'K', 'R', 'L', 'A', 'W', 'G', 'Q', 'P', 'V', 'G', 'L', 'R', 'H'] [[0.7421337 0.2578663]]\n",
      "['A', 'D', 'E', 'A', 'S', 'E', 'L', 'A', 'C', 'P', 'T', 'P', 'K', 'E', 'D', 'G', 'L', 'A', 'Q', 'Q', 'Q', 'T', 'Q', 'L', 'N'] [[0.78634423 0.21365574]]\n",
      "['Y', 'M', 'R', 'R', 'S', 'T', 'C', 'T', 'I', 'N', 'Y', 'S', 'K', 'D', 'L', 'P', 'L', 'A', 'Q', 'G', 'I', 'K', 'F', 'Q', 'O'] [[0.60014504 0.39985493]]\n",
      "['A', 'E', 'V', 'K', 'L', 'E', 'E', 'E', 'N', 'R', 'S', 'L', 'K', 'A', 'D', 'L', 'Q', 'K', 'L', 'K', 'D', 'E', 'L', 'A', 'S'] [[0.5219106  0.47808936]]\n",
      "['F', 'K', 'S', 'H', 'R', 'T', 'E', 'M', 'D', 'W', 'V', 'L', 'K', 'H', 'S', 'G', 'P', 'N', 'S', 'A', 'D', 'S', 'A', 'N', 'D'] [[0.558048   0.44195196]]\n",
      "['D', 'Y', 'S', 'W', 'A', 'R', 'E', 'L', 'G', 'L', 'I', 'R', 'K', 'P', 'A', 'S', 'F', 'M', 'T', 'S', 'I', 'C', 'D', 'E', 'R'] [[0.58637035 0.41362965]]\n",
      "['V', 'S', 'N', 'D', 'S', 'G', 'I', 'Y', 'V', 'S', 'R', 'I', 'K', 'E', 'N', 'G', 'A', 'A', 'A', 'L', 'D', 'G', 'R', 'L', 'Q'] [[0.6333985 0.3666015]]\n",
      "['K', 'E', 'R', 'A', 'C', 'Y', 'L', 'S', 'I', 'N', 'P', 'Q', 'K', 'D', 'E', 'T', 'L', 'E', 'T', 'E', 'K', 'A', 'Q', 'Y', 'Y'] [[0.8760233  0.12397669]]\n",
      "['D', 'K', 'P', 'L', 'R', 'L', 'P', 'L', 'Q', 'D', 'V', 'Y', 'K', 'I', 'G', 'G', 'I', 'G', 'T', 'V', 'P', 'V', 'G', 'R', 'V'] [[0.67797726 0.3220227 ]]\n",
      "['F', 'R', 'E', 'R', 'A', 'N', 'Q', 'K', 'H', 'Q', 'G', 'L', 'K', 'L', 'A', 'T', 'T', 'I', 'L', 'Q', 'H', 'W', 'K', 'K', 'C'] [[0.51607746 0.4839225 ]]\n",
      "['K', 'I', 'K', 'K', 'D', 'K', 'E', 'P', 'K', 'E', 'E', 'V', 'K', 'S', 'F', 'M', 'D', 'R', 'K', 'K', 'G', 'F', 'T', 'E', 'V'] [[0.51670784 0.48329213]]\n",
      "['V', 'T', 'G', 'S', 'P', 'E', 'A', 'S', 'I', 'S', 'G', 'S', 'K', 'G', 'D', 'L', 'K', 'S', 'S', 'K', 'A', 'S', 'L', 'G', 'S'] [[0.50538105 0.49461892]]\n",
      "['S', 'L', 'S', 'A', 'M', 'H', 'S', 'S', 'G', 'S', 'S', 'G', 'K', 'G', 'A', 'G', 'P', 'L', 'R', 'G', 'K', 'T', 'S', 'G', 'T'] [[0.5976476  0.40235236]]\n",
      "['P', 'K', 'Q', 'A', 'A', 'A', 'D', 'R', 'R', 'T', 'V', 'E', 'K', 'T', 'W', 'K', 'L', 'M', 'D', 'K', 'V', 'V', 'R', 'L', 'C'] [[0.5966429 0.4033571]]\n",
      "['V', 'E', 'D', 'S', 'K', 'D', 'V', 'N', 'V', 'N', 'F', 'E', 'K', 'S', 'K', 'L', 'T', 'F', 'S', 'C', 'L', 'G', 'G', 'S', 'D'] [[0.50668025 0.49331972]]\n",
      "['V', 'Q', 'V', 'H', 'E', 'L', 'G', 'C', 'E', 'G', 'I', 'S', 'K', 'S', 'Y', 'V', 'F', 'R', 'G', 'T', 'K', 'D', 'L', 'S', 'A'] [[0.54454124 0.45545873]]\n",
      "['L', 'A', 'A', 'V', 'T', 'Y', 'N', 'G', 'V', 'D', 'N', 'N', 'K', 'N', 'K', 'G', 'Q', 'L', 'T', 'K', 'S', 'P', 'L', 'A', 'Q'] [[0.5516508 0.4483492]]\n",
      "['V', 'Y', 'E', 'P', 'Q', 'L', 'Q', 'H', 'H', 'V', 'A', 'Q', 'K', 'K', 'I', 'P', 'Y', 'V', 'D', 'T', 'Q', 'G', 'Q', 'L', 'I'] [[0.53547925 0.46452072]]\n",
      "['F', 'A', 'L', 'V', 'G', 'V', 'G', 'S', 'E', 'A', 'S', 'S', 'K', 'K', 'L', 'M', 'D', 'L', 'L', 'P', 'K', 'R', 'E', 'L', 'H'] [[0.562204   0.43779603]]\n",
      "['D', 'G', 'K', 'A', 'D', 'P', 'L', 'A', 'L', 'A', 'A', 'E', 'K', 'D', 'G', 'T', 'P', 'V', 'F', 'K', 'L', 'P', 'K', 'W', 'R'] [[0.500412 0.499588]]\n",
      "['L', 'E', 'A', 'G', 'T', 'V', 'F', 'I', 'N', 'T', 'Y', 'N', 'K', 'T', 'D', 'V', 'A', 'A', 'P', 'F', 'G', 'G', 'V', 'K', 'Q'] [[0.79852504 0.20147498]]\n",
      "['V', 'H', 'R', 'Y', 'P', 'I', 'D', 'T', 'L', 'P', 'T', 'S', 'K', 'E', 'D', 'L', 'Q', 'L', 'W', 'C', 'H', 'K', 'R', 'W', 'E'] [[0.5364875  0.46351248]]\n",
      "['E', 'A', 'T', 'P', 'I', 'V', 'R', 'V', 'A', 'V', 'E', 'P', 'K', 'H', 'P', 'S', 'E', 'M', 'P', 'Q', 'L', 'V', 'K', 'G', 'M'] [[0.6220545  0.37794548]]\n",
      "['Q', 'T', 'I', 'K', 'L', 'C', 'I', 'G', 'N', 'I', 'T', 'N', 'K', 'K', 'G', 'G', 'A', 'S', 'K', 'P', 'R', 'T', 'A', 'R', 'G'] [[0.5388637  0.46113634]]\n",
      "['S', 'R', 'E', 'L', 'A', 'E', 'Q', 'T', 'L', 'N', 'N', 'I', 'K', 'Q', 'F', 'K', 'K', 'Y', 'I', 'D', 'N', 'P', 'K', 'L', 'R'] [[0.54913384 0.45086616]]\n",
      "['I', 'K', 'S', 'N', 'F', 'K', 'P', 'S', 'L', 'L', 'A', 'Q', 'K', 'I', 'E', 'V', 'R', 'I', 'P', 'T', 'P', 'L', 'N', 'T', 'S'] [[0.5239482  0.47605172]]\n",
      "['K', 'P', 'A', 'N', 'F', 'L', 'D', 'L', 'G', 'G', 'G', 'V', 'K', 'E', 'A', 'Q', 'V', 'Y', 'Q', 'A', 'F', 'K', 'L', 'L', 'T'] [[0.6507219 0.3492781]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'R', 'L', 'N', 'L', 'G', 'K', 'K', 'R', 'K', 'M', 'V', 'K', 'V', 'Y', 'T', 'K', 'T', 'D', 'G', 'L', 'V', 'A', 'V', 'H'] [[0.54336005 0.4566399 ]]\n",
      "['P', 'V', 'E', 'P', 'V', 'L', 'T', 'V', 'H', 'P', 'E', 'S', 'K', 'S', 'K', 'T', 'K', 'T', 'R', 'S', 'R', 'S', 'R', 'G', 'R'] [[0.7803018 0.2196982]]\n",
      "['S', 'D', 'V', 'R', 'N', 'T', 'V', 'T', 'Y', 'T', 'S', 'L', 'K', 'T', 'K', 'L', 'S', 'N', 'V', 'I', 'N', 'S', 'A', 'T', 'D'] [[0.54414135 0.45585868]]\n",
      "['T', 'R', 'E', 'L', 'S', 'N', 'F', 'Y', 'F', 'S', 'I', 'I', 'K', 'D', 'R', 'L', 'Y', 'C', 'E', 'K', 'E', 'N', 'D', 'P', 'K'] [[0.6471319  0.35286805]]\n",
      "['O', 'M', 'K', 'H', 'Y', 'E', 'V', 'E', 'I', 'L', 'D', 'A', 'K', 'T', 'R', 'E', 'K', 'L', 'C', 'F', 'L', 'D', 'K', 'V', 'E'] [[0.56747764 0.4325223 ]]\n",
      "['Y', 'V', 'K', 'G', 'W', 'I', 'P', 'G', 'N', 'E', 'E', 'N', 'K', 'Q', 'K', 'T', 'D', 'V', 'H', 'Y', 'R', 'S', 'L', 'D', 'G'] [[0.67633647 0.3236635 ]]\n",
      "['W', 'K', 'E', 'A', 'K', 'P', 'D', 'E', 'L', 'M', 'D', 'S', 'K', 'L', 'R', 'C', 'V', 'F', 'E', 'M', 'P', 'N', 'E', 'N', 'D'] [[0.5634668  0.43653318]]\n",
      "['V', 'I', 'A', 'S', 'E', 'L', 'G', 'S', 'M', 'P', 'E', 'L', 'K', 'K', 'Y', 'M', 'K', 'K', 'V', 'M', 'P', 'F', 'V', 'A', 'M'] [[0.62559485 0.37440518]]\n",
      "['F', 'M', 'S', 'E', 'K', 'E', 'V', 'P', 'L', 'V', 'F', 'P', 'K', 'T', 'Y', 'G', 'E', 'S', 'M', 'L', 'Y', 'L', 'D', 'G', 'Q'] [[0.76035404 0.23964599]]\n",
      "['K', 'E', 'A', 'D', 'L', 'A', 'A', 'Q', 'E', 'E', 'A', 'A', 'K', 'K', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] [[0.51389647 0.48610353]]\n",
      "['L', 'Q', 'S', 'V', 'N', 'Q', 'L', 'L', 'L', 'T', 'A', 'T', 'K', 'E', 'R', 'I', 'D', 'F', 'L', 'P', 'H', 'Y', 'D', 'T', 'L'] [[0.4786998 0.5213002]]\n",
      "['Q', 'P', 'L', 'L', 'L', 'S', 'E', 'D', 'E', 'E', 'D', 'T', 'K', 'R', 'V', 'V', 'R', 'S', 'A', 'K', 'D', 'K', 'R', 'F', 'E'] [[0.440398   0.55960196]]\n",
      "['S', 'A', 'T', 'V', 'D', 'Q', 'R', 'L', 'P', 'E', 'C', 'A', 'K', 'L', 'A', 'K', 'E', 'G', 'R', 'L', 'Q', 'E', 'V', 'I', 'E'] [[0.31913424 0.68086576]]\n",
      "['Q', 'V', 'R', 'V', 'L', 'E', 'L', 'E', 'N', 'E', 'L', 'Q', 'K', 'E', 'R', 'Q', 'K', 'L', 'G', 'E', 'L', 'R', 'K', 'K', 'H'] [[0.46125793 0.53874207]]\n",
      "['V', 'Y', 'E', 'W', 'A', 'R', 'D', 'H', 'R', 'A', 'H', 'H', 'K', 'F', 'S', 'E', 'T', 'H', 'A', 'D', 'P', 'H', 'N', 'S', 'R'] [[0.4651179  0.53488207]]\n",
      "['A', 'E', 'K', 'F', 'P', 'S', 'P', 'H', 'P', 'S', 'P', 'A', 'K', 'L', 'K', 'A', 'T', 'A', 'G', 'H', 'O', 'O', 'O', 'O', 'O'] [[0.3708497 0.6291503]]\n",
      "['K', 'L', 'Y', 'S', 'I', 'L', 'Q', 'G', 'D', 'S', 'P', 'T', 'K', 'W', 'R', 'T', 'E', 'D', 'F', 'R', 'M', 'F', 'K', 'N', 'G'] [[0.44748694 0.5525131 ]]\n",
      "['T', 'N', 'W', 'N', 'K', 'R', 'D', 'F', 'N', 'Q', 'F', 'I', 'K', 'A', 'N', 'E', 'K', 'W', 'G', 'R', 'D', 'D', 'I', 'E', 'N'] [[0.36260706 0.63739294]]\n",
      "['I', 'R', 'Q', 'D', 'I', 'E', 'D', 'S', 'V', 'S', 'R', 'M', 'K', 'P', 'W', 'Q', 'S', 'E', 'Y', 'G', 'G', 'V', 'V', 'F', 'G'] [[0.44168004 0.5583199 ]]\n",
      "['K', 'A', 'T', 'V', 'K', 'A', 'M', 'Q', 'E', 'A', 'L', 'A', 'K', 'L', 'K', 'E', 'E', 'E', 'E', 'R', 'Q', 'K', 'R', 'E', 'E'] [[0.4459632 0.5540368]]\n",
      "['K', 'L', 'R', 'E', 'N', 'K', 'E', 'F', 'L', 'E', 'F', 'R', 'K', 'A', 'R', 'S', 'D', 'M', 'L', 'L', 'S', 'R', 'K', 'N', 'Q'] [[0.43724385 0.5627562 ]]\n",
      "['Q', 'P', 'V', 'R', 'K', 'V', 'Q', 'S', 'A', 'T', 'H', 'F', 'K', 'K', 'V', 'R', 'G', 'P', 'S', 'R', 'A', 'D', 'P', 'N', 'H'] [[0.49578372 0.5042164 ]]\n",
      "['F', 'P', 'S', 'I', 'G', 'S', 'G', 'R', 'N', 'G', 'F', 'P', 'K', 'Q', 'T', 'A', 'A', 'Q', 'L', 'I', 'L', 'K', 'A', 'I', 'S'] [[0.35495263 0.6450474 ]]\n",
      "['S', 'G', 'T', 'K', 'A', 'E', 'V', 'S', 'I', 'Q', 'N', 'N', 'K', 'D', 'G', 'T', 'Y', 'A', 'V', 'T', 'Y', 'V', 'P', 'L', 'T'] [[0.4244962 0.5755038]]\n",
      "['D', 'W', 'I', 'E', 'N', 'H', 'G', 'E', 'A', 'F', 'L', 'S', 'K', 'H', 'T', 'G', 'V', 'G', 'K', 'S', 'L', 'H', 'R', 'A', 'R'] [[0.3832436 0.6167564]]\n",
      "['N', 'T', 'S', 'T', 'A', 'E', 'E', 'E', 'L', 'C', 'R', 'L', 'K', 'L', 'L', 'A', 'K', 'H', 'P', 'C', 'H', 'I', 'K', 'K', 'F'] [[0.37078795 0.629212  ]]\n",
      "['A', 'L', 'K', 'N', 'K', 'A', 'A', 'K', 'G', 'S', 'A', 'T', 'K', 'D', 'F', 'S', 'V', 'F', 'F', 'Q', 'K', 'I', 'R', 'E', 'T'] [[0.33252466 0.6674753 ]]\n",
      "['Q', 'L', 'K', 'I', 'K', 'E', 'L', 'D', 'H', 'N', 'I', 'S', 'K', 'H', 'K', 'R', 'E', 'A', 'E', 'D', 'G', 'A', 'A', 'K', 'V'] [[0.41056627 0.5894337 ]]\n",
      "['O', 'O', 'O', 'O', 'M', 'E', 'I', 'I', 'R', 'S', 'N', 'F', 'K', 'S', 'N', 'L', 'H', 'K', 'V', 'Y', 'Q', 'A', 'I', 'E', 'E'] [[0.48301482 0.5169852 ]]\n",
      "['L', 'L', 'P', 'D', 'N', 'F', 'I', 'A', 'A', 'C', 'T', 'E', 'K', 'K', 'I', 'P', 'V', 'V', 'F', 'R', 'L', 'Q', 'E', 'G', 'Y'] [[0.4045393 0.5954608]]\n",
      "['N', 'K', 'R', 'I', 'N', 'K', 'Y', 'L', 'D', 'E', 'I', 'V', 'K', 'E', 'V', 'E', 'A', 'K', 'A', 'P', 'I', 'L', 'K', 'R', 'Q'] [[0.26386675 0.7361333 ]]\n",
      "['Q', 'D', 'V', 'D', 'M', 'V', 'F', 'A', 'S', 'F', 'I', 'R', 'K', 'A', 'S', 'D', 'V', 'H', 'E', 'V', 'R', 'K', 'V', 'L', 'G'] [[0.29424402 0.705756  ]]\n",
      "['N', 'S', 'Q', 'G', 'S', 'E', 'M', 'F', 'G', 'D', 'D', 'D', 'K', 'R', 'K', 'I', 'Q', 'S', 'Q', 'F', 'T', 'D', 'A', 'Q', 'K'] [[0.34961554 0.6503845 ]]\n",
      "['Q', 'V', 'I', 'M', 'S', 'I', 'R', 'T', 'K', 'L', 'Q', 'N', 'K', 'E', 'H', 'V', 'I', 'E', 'A', 'L', 'R', 'R', 'A', 'K', 'F'] [[0.20429897 0.795701  ]]\n",
      "['Q', 'L', 'L', 'K', 'E', 'Q', 'E', 'R', 'T', 'L', 'A', 'L', 'K', 'L', 'Q', 'E', 'Q', 'E', 'Q', 'L', 'L', 'K', 'E', 'G', 'F'] [[0.1472733  0.85272676]]\n",
      "['A', 'M', 'T', 'I', 'P', 'F', 'V', 'R', 'Q', 'Q', 'V', 'Y', 'K', 'K', 'V', 'E', 'E', 'K', 'V', 'R', 'K', 'Q', 'T', 'K', 'G'] [[0.35449448 0.64550555]]\n",
      "['P', 'L', 'V', 'L', 'K', 'T', 'G', 'V', 'Q', 'F', 'T', 'V', 'K', 'L', 'R', 'L', 'L', 'V', 'K', 'L', 'Q', 'E', 'L', 'N', 'Y'] [[0.33325303 0.666747  ]]\n",
      "['T', 'G', 'E', 'L', 'E', 'A', 'A', 'K', 'A', 'L', 'V', 'L', 'K', 'R', 'I', 'Q', 'I', 'W', 'K', 'R', 'Q', 'Q', 'Q', 'L', 'A'] [[0.3749568 0.6250432]]\n",
      "['K', 'P', 'F', 'S', 'L', 'M', 'K', 'A', 'S', 'S', 'R', 'F', 'K', 'A', 'H', 'Q', 'D', 'A', 'L', 'P', 'R', 'L', 'P', 'V', 'P'] [[0.45423728 0.5457627 ]]\n",
      "['L', 'K', 'K', 'E', 'F', 'L', 'H', 'A', 'Q', 'E', 'E', 'V', 'K', 'R', 'I', 'Q', 'S', 'I', 'P', 'L', 'V', 'I', 'G', 'Q', 'F'] [[0.41069034 0.58930963]]\n",
      "['Q', 'R', 'E', 'L', 'T', 'N', 'L', 'L', 'G', 'L', 'H', 'P', 'K', 'I', 'E', 'M', 'A', 'R', 'A', 'S', 'C', 'S', 'A', 'L', 'M'] [[0.43414164 0.5658584 ]]\n",
      "['G', 'G', 'L', 'K', 'A', 'L', 'S', 'K', 'E', 'K', 'R', 'E', 'K', 'L', 'E', 'A', 'Y', 'Q', 'H', 'L', 'F', 'Y', 'L', 'L', 'Q'] [[0.40712637 0.5928737 ]]\n",
      "['G', 'M', 'Y', 'E', 'Q', 'L', 'K', 'G', 'E', 'W', 'N', 'R', 'K', 'S', 'P', 'N', 'L', 'S', 'K', 'C', 'G', 'E', 'E', 'L', 'G'] [[0.40785754 0.5921424 ]]\n",
      "['L', 'L', 'E', 'L', 'N', 'F', 'L', 'P', 'T', 'T', 'G', 'T', 'K', 'L', 'T', 'K', 'Q', 'Q', 'L', 'I', 'L', 'A', 'R', 'D', 'I'] [[0.4755947  0.52440536]]\n",
      "['G', 'L', 'A', 'A', 'A', 'A', 'G', 'T', 'R', 'I', 'M', 'G', 'K', 'E', 'I', 'E', 'A', 'E', 'A', 'Q', 'R', 'P', 'L', 'R', 'Q'] [[0.33519873 0.66480124]]\n",
      "['N', 'Q', 'Y', 'V', 'N', 'K', 'K', 'F', 'S', 'N', 'Q', 'Y', 'K', 'A', 'T', 'I', 'G', 'A', 'D', 'F', 'L', 'T', 'K', 'E', 'V'] [[0.47575223 0.52424777]]\n",
      "['Y', 'Q', 'E', 'G', 'L', 'R', 'V', 'M', 'G', 'E', 'V', 'G', 'K', 'T', 'T', 'G', 'I', 'P', 'I', 'H', 'V', 'F', 'G', 'T', 'E'] [[0.1597369 0.8402631]]\n",
      "['A', 'A', 'K', 'A', 'L', 'D', 'D', 'K', 'N', 'C', 'W', 'E', 'K', 'L', 'G', 'E', 'V', 'A', 'L', 'L', 'Q', 'G', 'N', 'H', 'Q'] [[0.39822656 0.6017735 ]]\n",
      "['L', 'E', 'S', 'K', 'K', 'P', 'K', 'G', 'F', 'F', 'G', 'Y', 'K', 'S', 'E', 'I', 'F', 'N', 'E', 'N', 'F', 'G', 'P', 'D', 'F'] [[0.36483267 0.63516736]]\n",
      "['F', 'L', 'S', 'R', 'K', 'T', 'L', 'V', 'E', 'F', 'P', 'Q', 'K', 'V', 'L', 'S', 'P', 'F', 'R', 'K', 'Q', 'G', 'S', 'D', 'S'] [[0.47610208 0.5238979 ]]\n",
      "['N', 'W', 'D', 'A', 'A', 'M', 'E', 'D', 'L', 'T', 'R', 'L', 'K', 'E', 'T', 'I', 'D', 'N', 'N', 'S', 'V', 'S', 'S', 'P', 'L'] [[0.4455759  0.55442417]]\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'M', 'A', 'P', 'I', 'G', 'L', 'K', 'A', 'V', 'V', 'G', 'E', 'K', 'I', 'M', 'H', 'D', 'V', 'I'] [[0.11894645 0.88105357]]\n",
      "['W', 'D', 'L', 'E', 'G', 'K', 'I', 'I', 'V', 'D', 'E', 'L', 'K', 'Q', 'E', 'V', 'I', 'S', 'T', 'S', 'S', 'K', 'A', 'E', 'P'] [[0.49039185 0.5096081 ]]\n",
      "['R', 'R', 'Y', 'Q', 'K', 'S', 'T', 'E', 'L', 'L', 'I', 'R', 'K', 'L', 'P', 'F', 'Q', 'R', 'L', 'V', 'R', 'E', 'I', 'A', 'Q'] [[0.37997776 0.62002224]]\n",
      "['Q', 'G', 'Q', 'S', 'K', 'D', 'M', 'P', 'P', 'R', 'F', 'S', 'K', 'K', 'G', 'Q', 'L', 'N', 'A', 'D', 'E', 'I', 'S', 'L', 'R'] [[0.4994169  0.50058305]]\n",
      "['Q', 'E', 'R', 'E', 'D', 'V', 'L', 'A', 'G', 'M', 'S', 'G', 'K', 'A', 'I', 'K', 'G', 'K', 'V', 'G', 'K', 'P', 'K', 'V', 'K'] [[0.40702954 0.5929705 ]]\n",
      "['G', 'I', 'W', 'R', 'R', 'V', 'A', 'L', 'G', 'H', 'G', 'L', 'K', 'L', 'L', 'T', 'K', 'N', 'G', 'H', 'V', 'Y', 'K', 'Y', 'D'] [[0.4775936  0.52240634]]\n",
      "['S', 'A', 'T', 'P', 'R', 'S', 'K', 'P', 'V', 'C', 'I', 'H', 'K', 'N', 'S', 'E', 'C', 'L', 'K', 'E', 'Q', 'Q', 'K', 'R', 'Y'] [[0.41724074 0.58275926]]\n",
      "['Q', 'D', 'L', 'R', 'R', 'T', 'E', 'S', 'D', 'S', 'G', 'L', 'K', 'K', 'G', 'G', 'N', 'A', 'N', 'L', 'V', 'F', 'M', 'L', 'K'] [[0.45340294 0.54659706]]\n",
      "['C', 'L', 'L', 'I', 'A', 'D', 'Q', 'H', 'C', 'R', 'T', 'R', 'K', 'Y', 'F', 'L', 'C', 'L', 'A', 'S', 'G', 'I', 'P', 'C', 'V'] [[0.3338789  0.66612107]]\n",
      "['E', 'G', 'T', 'V', 'K', 'A', 'Y', 'V', 'W', 'D', 'N', 'N', 'K', 'D', 'L', 'A', 'E', 'W', 'L', 'E', 'K', 'Q', 'L', 'T', 'E'] [[0.39408723 0.6059128 ]]\n",
      "['K', 'L', 'E', 'K', 'L', 'D', 'T', 'D', 'L', 'K', 'N', 'Y', 'K', 'G', 'N', 'S', 'I', 'K', 'E', 'S', 'I', 'R', 'R', 'G', 'H'] [[0.48107937 0.51892066]]\n",
      "['A', 'A', 'V', 'F', 'R', 'S', 'M', 'N', 'S', 'A', 'L', 'G', 'K', 'S', 'P', 'W', 'L', 'A', 'G', 'N', 'E', 'L', 'T', 'V', 'A'] [[0.4862997 0.5137003]]\n",
      "['R', 'K', 'F', 'F', 'G', 'D', 'K', 'T', 'I', 'V', 'P', 'W', 'K', 'V', 'F', 'R', 'Q', 'C', 'L', 'H', 'E', 'V', 'H', 'Q', 'I'] [[0.2619514 0.7380487]]\n",
      "['G', 'S', 'V', 'K', 'S', 'F', 'S', 'L', 'G', 'P', 'L', 'R', 'K', 'A', 'V', 'T', 'L', 'N', 'P', 'D', 'N', 'S', 'Y', 'I', 'K'] [[0.46246025 0.5375398 ]]\n",
      "['L', 'K', 'N', 'Y', 'N', 'Q', 'Q', 'K', 'D', 'I', 'E', 'H', 'K', 'E', 'L', 'V', 'Q', 'K', 'L', 'Q', 'H', 'F', 'Q', 'E', 'L'] [[0.39150417 0.60849583]]\n",
      "['A', 'I', 'G', 'P', 'F', 'S', 'G', 'L', 'K', 'E', 'V', 'R', 'K', 'V', 'V', 'L', 'D', 'T', 'M', 'K', 'N', 'I', 'H', 'P', 'I'] [[0.30474526 0.6952547 ]]\n",
      "['G', 'L', 'E', 'L', 'Y', 'K', 'R', 'L', 'K', 'E', 'F', 'L', 'K', 'N', 'Y', 'L', 'T', 'N', 'L', 'L', 'K', 'D', 'G', 'E', 'D'] [[0.49312305 0.5068769 ]]\n",
      "['H', 'V', 'A', 'V', 'T', 'E', 'M', 'A', 'A', 'L', 'F', 'P', 'K', 'K', 'P', 'K', 'S', 'D', 'M', 'V', 'R', 'T', 'S', 'L', 'R'] [[0.45419803 0.545802  ]]\n",
      "['Q', 'K', 'L', 'K', 'Q', 'D', 'G', 'D', 'S', 'F', 'R', 'M', 'K', 'L', 'N', 'T', 'Q', 'E', 'I', 'F', 'D', 'D', 'W', 'A', 'R'] [[0.44017348 0.55982655]]\n",
      "['I', 'T', 'Q', 'A', 'V', 'I', 'F', 'L', 'N', 'T', 'R', 'R', 'K', 'V', 'D', 'W', 'L', 'T', 'E', 'K', 'M', 'H', 'A', 'R', 'D'] [[0.10472324 0.8952767 ]]\n",
      "['T', 'A', 'N', 'Q', 'W', 'D', 'Y', 'K', 'N', 'I', 'I', 'E', 'K', 'L', 'Q', 'D', 'I', 'I', 'T', 'A', 'L', 'E', 'E', 'R', 'L'] [[0.39268658 0.60731345]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L', 'K', 'E', 'K', 'K', 'E', 'R', 'L', 'T', 'E', 'E', 'L', 'K', 'E', 'Q', 'M', 'K', 'A', 'K', 'R', 'K', 'E', 'A', 'E', 'L'] [[0.33925474 0.66074526]]\n",
      "['K', 'D', 'I', 'K', 'K', 'E', 'K', 'V', 'L', 'L', 'R', 'R', 'K', 'S', 'E', 'L', 'P', 'Q', 'D', 'V', 'Y', 'T', 'I', 'K', 'A'] [[0.48522854 0.5147714 ]]\n",
      "['E', 'L', 'N', 'F', 'H', 'K', 'A', 'Q', 'E', 'I', 'Y', 'E', 'K', 'N', 'L', 'D', 'E', 'K', 'A', 'K', 'E', 'I', 'S', 'N', 'L'] [[0.4802872  0.51971275]]\n",
      "['E', 'D', 'V', 'K', 'G', 'R', 'I', 'Y', 'Q', 'L', 'L', 'A', 'K', 'A', 'S', 'Y', 'K', 'K', 'A', 'I', 'I', 'L', 'T', 'R', 'E'] [[0.42129302 0.578707  ]]\n",
      "['L', 'D', 'S', 'G', 'N', 'E', 'S', 'K', 'E', 'K', 'L', 'L', 'K', 'G', 'E', 'S', 'A', 'L', 'Q', 'R', 'V', 'Q', 'C', 'I', 'P'] [[0.24410005 0.75589997]]\n",
      "['Q', 'L', 'T', 'G', 'L', 'S', 'L', 'L', 'P', 'L', 'S', 'E', 'K', 'A', 'A', 'R', 'A', 'R', 'Q', 'E', 'E', 'L', 'Y', 'S', 'E'] [[0.3324505  0.66754943]]\n",
      "['C', 'F', 'A', 'K', 'T', 'L', 'V', 'E', 'H', 'V', 'G', 'M', 'K', 'N', 'L', 'K', 'S', 'W', 'A', 'S', 'V', 'N', 'R', 'G', 'A'] [[0.3535612 0.6464388]]\n",
      "['A', 'L', 'L', 'G', 'V', 'F', 'C', 'H', 'T', 'D', 'L', 'R', 'K', 'N', 'L', 'T', 'V', 'D', 'E', 'G', 'T', 'M', 'K', 'V', 'E'] [[0.44896543 0.55103457]]\n",
      "['Q', 'L', 'K', 'D', 'L', 'N', 'L', 'L', 'D', 'R', 'C', 'I', 'K', 'E', 'T', 'L', 'R', 'L', 'R', 'P', 'P', 'I', 'M', 'I', 'M'] [[0.3456902 0.6543098]]\n",
      "['F', 'L', 'G', 'G', 'A', 'R', 'I', 'T', 'V', 'L', 'A', 'S', 'K', 'T', 'S', 'Q', 'R', 'Y', 'R', 'I', 'Q', 'S', 'E', 'Q', 'F'] [[0.29877836 0.70122164]]\n",
      "['I', 'N', 'I', 'S', 'L', 'D', 'H', 'K', 'R', 'P', 'L', 'I', 'K', 'V', 'L', 'G', 'I', 'S', 'R', 'D', 'V', 'M', 'Q', 'A', 'R'] [[0.3882252 0.6117748]]\n",
      "['R', 'I', 'E', 'V', 'E', 'N', 'K', 'E', 'V', 'L', 'H', 'G', 'K', 'K', 'W', 'K', 'G', 'L', 'T', 'H', 'N', 'L', 'L', 'K', 'K'] [[0.42733273 0.57266724]]\n",
      "['L', 'P', 'H', 'P', 'R', 'W', 'S', 'A', 'E', 'A', 'S', 'G', 'K', 'P', 'S', 'P', 'S', 'D', 'P', 'G', 'S', 'G', 'T', 'A', 'T'] [[0.46419087 0.53580916]]\n",
      "['A', 'M', 'S', 'T', 'T', 'A', 'K', 'G', 'S', 'K', 'S', 'L', 'K', 'V', 'E', 'L', 'I', 'E', 'D', 'K', 'I', 'D', 'Y', 'T', 'K'] [[0.45919278 0.5408071 ]]\n",
      "['P', 'S', 'P', 'S', 'S', 'A', 'E', 'K', 'V', 'K', 'A', 'N', 'K', 'D', 'V', 'A', 'S', 'P', 'L', 'K', 'E', 'L', 'G', 'L', 'R'] [[0.35884127 0.64115876]]\n",
      "['N', 'N', 'G', 'T', 'V', 'L', 'R', 'A', 'S', 'H', 'G', 'T', 'K', 'M', 'M', 'T', 'P', 'E', 'V', 'L', 'A', 'E', 'A', 'Y', 'G'] [[0.435092   0.56490797]]\n",
      "['P', 'F', 'E', 'A', 'V', 'M', 'R', 'T', 'L', 'C', 'E', 'C', 'K', 'E', 'T', 'A', 'S', 'K', 'T', 'L', 'S', 'R', 'F', 'G', 'I'] [[0.47539893 0.52460104]]\n",
      "['D', 'I', 'V', 'Y', 'M', 'K', 'P', 'H', 'G', 'R', 'L', 'Q', 'K', 'V', 'M', 'N', 'H', 'I', 'T', 'D', 'G', 'P', 'R', 'K', 'D'] [[0.43899438 0.5610056 ]]\n",
      "['V', 'S', 'R', 'T', 'S', 'T', 'A', 'P', 'L', 'D', 'R', 'L', 'K', 'I', 'M', 'M', 'Q', 'V', 'H', 'G', 'S', 'K', 'S', 'D', 'K'] [[0.21638389 0.7836161 ]]\n",
      "['K', 'A', 'R', 'L', 'G', 'R', 'M', 'V', 'V', 'A', 'S', 'D', 'K', 'S', 'G', 'Q', 'P', 'V', 'T', 'A', 'D', 'D', 'L', 'G', 'V'] [[0.41608787 0.5839121 ]]\n",
      "['P', 'P', 'A', 'L', 'R', 'P', 'K', 'P', 'A', 'V', 'L', 'P', 'K', 'T', 'N', 'P', 'T', 'I', 'G', 'P', 'A', 'P', 'P', 'P', 'Q'] [[0.3188672 0.6811328]]\n",
      "['F', 'K', 'H', 'T', 'V', 'D', 'D', 'G', 'L', 'D', 'I', 'R', 'K', 'A', 'A', 'F', 'E', 'C', 'M', 'Y', 'T', 'L', 'L', 'D', 'S'] [[0.38580397 0.61419606]]\n",
      "['D', 'I', 'K', 'G', 'P', 'K', 'L', 'D', 'L', 'K', 'D', 'P', 'K', 'V', 'E', 'M', 'R', 'V', 'P', 'D', 'V', 'E', 'V', 'S', 'L'] [[0.41239774 0.58760226]]\n",
      "['G', 'Y', 'R', 'W', 'E', 'R', 'Q', 'L', 'V', 'F', 'R', 'S', 'K', 'L', 'T', 'M', 'H', 'T', 'A', 'F', 'D', 'R', 'K', 'D', 'N'] [[0.16897193 0.8310281 ]]\n",
      "['F', 'S', 'S', 'M', 'V', 'E', 'S', 'E', 'L', 'H', 'A', 'A', 'K', 'T', 'K', 'Q', 'A', 'W', 'N', 'F', 'L', 'S', 'H', 'L', 'P'] [[0.49472252 0.50527745]]\n",
      "['F', 'P', 'T', 'Q', 'G', 'H', 'D', 'Y', 'V', 'L', 'A', 'E', 'K', 'Q', 'V', 'Q', 'R', 'S', 'R', 'N', 'K', 'Q', 'V', 'R', 'E'] [[0.4724279  0.52757215]]\n",
      "['A', 'V', 'K', 'K', 'L', 'K', 'N', 'S', 'L', 'P', 'L', 'R', 'K', 'E', 'L', 'D', 'R', 'L', 'K', 'D', 'E', 'L', 'S', 'H', 'Q'] [[0.380222 0.619778]]\n",
      "['G', 'E', 'G', 'E', 'V', 'K', 'L', 'N', 'M', 'A', 'I', 'G', 'K', 'G', 'E', 'Q', 'A', 'L', 'R', 'S', 'S', 'N', 'K', 'E', 'G'] [[0.33290687 0.6670931 ]]\n",
      "['D', 'A', 'E', 'S', 'T', 'A', 'V', 'H', 'L', 'E', 'A', 'L', 'K', 'K', 'L', 'A', 'L', 'A', 'L', 'Q', 'E', 'R', 'K', 'Y', 'A'] [[0.3305789 0.6694211]]\n",
      "['I', 'G', 'R', 'L', 'L', 'S', 'E', 'D', 'F', 'V', 'S', 'V', 'K', 'V', 'D', 'R', 'E', 'E', 'R', 'P', 'D', 'V', 'D', 'K', 'V'] [[0.32905975 0.6709402 ]]\n",
      "['G', 'L', 'S', 'A', 'F', 'L', 'S', 'Q', 'E', 'E', 'I', 'N', 'K', 'S', 'L', 'D', 'L', 'A', 'R', 'R', 'A', 'I', 'A', 'D', 'S'] [[0.38978395 0.61021614]]\n",
      "['S', 'P', 'S', 'V', 'I', 'S', 'D', 'L', 'F', 'T', 'D', 'I', 'K', 'K', 'G', 'H', 'V', 'L', 'L', 'D', 'L', 'L', 'E', 'V', 'L'] [[0.4685817 0.5314183]]\n",
      "['L', 'G', 'R', 'L', 'R', 'R', 'A', 'T', 'E', 'Y', 'A', 'P', 'K', 'K', 'R', 'I', 'E', 'P', 'L', 'S', 'P', 'E', 'L', 'V', 'A'] [[0.46383524 0.53616476]]\n",
      "['R', 'T', 'I', 'L', 'P', 'M', 'S', 'R', 'A', 'F', 'R', 'G', 'K', 'H', 'L', 'S', 'F', 'V', 'V', 'R', 'F', 'P', 'N', 'Q', 'G'] [[0.1997282  0.80027187]]\n",
      "['S', 'K', 'V', 'D', 'D', 'K', 'W', 'E', 'K', 'K', 'C', 'Q', 'K', 'I', 'F', 'S', 'F', 'A', 'H', 'Q', 'T', 'I', 'S', 'A', 'L'] [[0.28775802 0.712242  ]]\n",
      "['N', 'T', 'D', 'K', 'N', 'G', 'E', 'E', 'L', 'H', 'G', 'G', 'K', 'R', 'V', 'M', 'E', 'C', 'L', 'K', 'K', 'A', 'L', 'K', 'I'] [[0.4870892 0.5129108]]\n",
      "['H', 'K', 'A', 'A', 'I', 'E', 'V', 'Y', 'N', 'E', 'A', 'A', 'K', 'L', 'N', 'Q', 'K', 'D', 'W', 'E', 'I', 'S', 'H', 'N', 'L'] [[0.2846322  0.71536785]]\n",
      "['A', 'I', 'V', 'D', 'A', 'E', 'W', 'N', 'I', 'L', 'Y', 'D', 'K', 'L', 'E', 'K', 'I', 'H', 'H', 'S', 'G', 'A', 'K', 'V', 'V'] [[0.44556484 0.5544352 ]]\n",
      "['L', 'V', 'K', 'D', 'Q', 'E', 'A', 'L', 'M', 'K', 'S', 'V', 'K', 'L', 'L', 'Q', 'A', 'L', 'A', 'Q', 'Y', 'Q', 'N', 'H', 'L'] [[0.19735527 0.8026447 ]]\n",
      "['S', 'I', 'R', 'R', 'I', 'K', 'D', 'Y', 'D', 'A', 'N', 'F', 'K', 'I', 'K', 'D', 'F', 'P', 'E', 'K', 'A', 'K', 'D', 'I', 'F'] [[0.36709073 0.6329093 ]]\n",
      "['P', 'W', 'V', 'R', 'A', 'K', 'K', 'P', 'E', 'N', 'C', 'E', 'K', 'L', 'V', 'T', 'L', 'L', 'E', 'N', 'Y', 'K', 'E', 'M', 'Y'] [[0.2796541 0.720346 ]]\n",
      "['T', 'I', 'G', 'K', 'L', 'E', 'P', 'S', 'Y', 'V', 'I', 'R', 'K', 'F', 'L', 'D', 'A', 'Q', 'R', 'I', 'H', 'N', 'L', 'T', 'A'] [[0.38068897 0.61931103]]\n",
      "['E', 'C', 'A', 'I', 'Q', 'T', 'C', 'P', 'E', 'L', 'L', 'R', 'K', 'D', 'F', 'E', 'S', 'L', 'F', 'P', 'E', 'V', 'A', 'N', 'G'] [[0.47491896 0.5250811 ]]\n",
      "['G', 'Q', 'G', 'R', 'D', 'N', 'A', 'L', 'T', 'L', 'L', 'I', 'K', 'A', 'V', 'P', 'R', 'K', 'S', 'L', 'K', 'D', 'P', 'N', 'N'] [[0.3152474  0.68475264]]\n",
      "['K', 'G', 'K', 'M', 'W', 'E', 'K', 'A', 'I', 'K', 'L', 'S', 'K', 'E', 'L', 'A', 'E', 'T', 'Y', 'E', 'S', 'K', 'V', 'F', 'D'] [[0.28346053 0.7165395 ]]\n",
      "['V', 'E', 'K', 'F', 'F', 'T', 'E', 'E', 'V', 'D', 'S', 'R', 'K', 'I', 'D', 'Q', 'E', 'G', 'K', 'I', 'P', 'D', 'E', 'T', 'L'] [[0.3985732 0.6014268]]\n",
      "['G', 'S', 'G', 'D', 'T', 'N', 'N', 'F', 'P', 'Y', 'L', 'E', 'K', 'T', 'A', 'K', 'K', 'G', 'R', 'P', 'M', 'V', 'I', 'S', 'S'] [[0.4388657  0.56113434]]\n",
      "['K', 'K', 'R', 'K', 'L', 'P', 'S', 'D', 'V', 'N', 'E', 'G', 'K', 'T', 'V', 'F', 'I', 'R', 'N', 'L', 'S', 'F', 'D', 'S', 'E'] [[0.4242846 0.5757154]]\n",
      "['R', 'T', 'G', 'L', 'G', 'R', 'L', 'G', 'V', 'S', 'L', 'S', 'K', 'G', 'L', 'H', 'H', 'K', 'A', 'V', 'L', 'A', 'V', 'R', 'R'] [[0.47055385 0.5294461 ]]\n",
      "['E', 'Y', 'R', 'G', 'Q', 'A', 'Q', 'A', 'I', 'E', 'F', 'L', 'K', 'E', 'Q', 'I', 'S', 'L', 'A', 'E', 'K', 'K', 'M', 'L', 'D'] [[0.3817962  0.61820376]]\n",
      "['F', 'K', 'R', 'D', 'G', 'S', 'N', 'I', 'I', 'Y', 'T', 'A', 'K', 'I', 'S', 'L', 'R', 'E', 'A', 'L', 'C', 'G', 'C', 'S', 'I'] [[0.49371776 0.50628227]]\n",
      "['S', 'V', 'V', 'R', 'D', 'L', 'G', 'F', 'F', 'G', 'I', 'Y', 'K', 'G', 'A', 'K', 'A', 'C', 'F', 'L', 'R', 'D', 'I', 'P', 'F'] [[0.44260418 0.5573958 ]]\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'M', 'S', 'L', 'K', 'L', 'Q', 'A', 'S', 'N', 'V', 'T', 'N', 'K', 'N', 'D', 'P'] [[0.20612545 0.79387456]]\n",
      "['A', 'G', 'L', 'Q', 'L', 'V', 'V', 'V', 'I', 'L', 'P', 'G', 'K', 'T', 'P', 'V', 'Y', 'A', 'E', 'V', 'K', 'R', 'V', 'G', 'D'] [[0.20248117 0.79751885]]\n",
      "['L', 'K', 'G', 'D', 'L', 'K', 'G', 'V', 'K', 'G', 'D', 'L', 'K', 'K', 'P', 'F', 'D', 'K', 'A', 'W', 'K', 'D', 'Y', 'E', 'T'] [[0.49016318 0.5098368 ]]\n",
      "['I', 'R', 'V', 'A', 'A', 'K', 'W', 'Y', 'N', 'E', 'H', 'L', 'K', 'K', 'M', 'S', 'A', 'D', 'N', 'Q', 'L', 'Q', 'V', 'I', 'F'] [[0.4050391 0.5949609]]\n",
      "['K', 'K', 'Y', 'A', 'T', 'L', 'S', 'L', 'F', 'N', 'T', 'Y', 'K', 'G', 'K', 'S', 'L', 'E', 'T', 'Q', 'K', 'T', 'T', 'V', 'A'] [[0.46583107 0.534169  ]]\n",
      "acc: 69.66666666666667\n",
      "sn: 66.57303370786516\n",
      "sp: 74.18032786885246\n",
      "mcc: 0.40037052280992086\n"
     ]
    }
   ],
   "source": [
    "PATH = './Path/dlmal_h_net.pth'\n",
    "net = torch.load(PATH, map_location=\"cpu\")\n",
    "net.eval()\n",
    "\n",
    "print(r_test_x[0])\n",
    "print([int_to_char[i] for i in r_test_x[0][0]])\n",
    "y = net(torch.from_numpy(np.array([r_test_x[0]])))\n",
    "print(F.softmax(y, dim=1))\n",
    "\n",
    "print(r_test_x[-1])\n",
    "print([int_to_char[i] for i in r_test_x[-1][0]])\n",
    "y = net(torch.from_numpy(np.array([r_test_x[-1]])))\n",
    "print(F.softmax(y, dim=1))\n",
    "\n",
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "for i in range(len(r_test_x)):\n",
    "    y = net(torch.from_numpy(np.array([r_test_x[i]])))\n",
    "    y = F.softmax(y, dim=1)\n",
    "    y = y.detach().cpu().numpy()\n",
    "    if (y[0][0] > y[0][1] and r_test_y[i] == 0):\n",
    "        TN += 1\n",
    "    elif (y[0][0] < y[0][1] and r_test_y[i] == 1):\n",
    "        TP += 1\n",
    "    elif r_test_y[i] == 0:\n",
    "        FN += 1\n",
    "        print([int_to_char[i] for i in r_test_x[i][0]], y)\n",
    "    else:\n",
    "        FP +=1\n",
    "        print([int_to_char[i] for i in r_test_x[i][0]], y)\n",
    "       \n",
    "print(\"acc:\", (TP+TN)/(TP+TN+FP+FN)*100)\n",
    "print(\"sn:\", (TP)/(TP+FN)*100)\n",
    "print(\"sp:\", TN/(TN+FP)*100)\n",
    "print(\"mcc:\", (TP*TN-FP*FN)/((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))**(1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ce7630",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
