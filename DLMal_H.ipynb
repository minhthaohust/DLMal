{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "269b429f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7170, 1, 25)\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "\n",
    "r_test_x = []\n",
    "r_test_y = []\n",
    "posit_1 = 1;\n",
    "negat_0 = 0;\n",
    "\n",
    "# define universe of possible input values\n",
    "alphabet = 'OARNDCQEGHILKMFPSTWYV'\n",
    "# define a mapping of chars to integers\n",
    "char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
    "\n",
    "i = 0\n",
    "#-------------------------TEST DATASET----------------------------------------\n",
    "#for positive sequence\n",
    "def innertest1():\n",
    "    #Input\n",
    "    data = seq_record.seq\n",
    "    #rint(data) \n",
    "    # integer encode input data\n",
    "    for char in data:\n",
    "        if char not in alphabet:\n",
    "            print(data, i)\n",
    "            return\n",
    "    integer_encoded = [char_to_int[char] for char in data]\n",
    "    r_test_x.append(integer_encoded)\n",
    "    r_test_y.append(posit_1)\n",
    "for seq_record in SeqIO.parse(\"./Datasets/training_data/H_train.fasta\", \"fasta\"):\n",
    "\n",
    "    innertest1()\n",
    "    i += 1\n",
    "    \n",
    "#print(len(r_test_x))\n",
    "\n",
    "#for negative sequence\n",
    "def innertest2():\n",
    "    #Input\n",
    "    data = seq_record.seq\n",
    "    #print(data) \n",
    "    # integer encode input data\n",
    "    for char in data:\n",
    "        if char not in alphabet:\n",
    "            return\n",
    "    integer_encoded = [char_to_int[char] for char in data]\n",
    "    r_test_x.append(integer_encoded) \n",
    "    r_test_y.append(negat_0)\n",
    "\n",
    "for seq_record in SeqIO.parse(\"./Datasets/training_data/H_train_neg.fasta\", \"fasta\"):\n",
    "    innertest2()\n",
    "# Changing to array (matrix)    \n",
    "r_test_x = np.array(r_test_x)\n",
    "r_test_y = np.array(r_test_y)\n",
    "\n",
    "# Balancing test dataset\n",
    "# Testing Data Balancing by undersampling####################################\n",
    "rus = RandomUnderSampler(random_state=7)\n",
    "x_res3, y_res3 = rus.fit_resample(r_test_x, r_test_y)\n",
    "#Shuffling\n",
    "r_test_x, r_test_y = shuffle(x_res3, y_res3, random_state=7)\n",
    "r_test_x = np.array(r_test_x)\n",
    "r_test_y = np.array(r_test_y)\n",
    "\n",
    "#print(r_test_y.shape)\n",
    "r_test_x = np.expand_dims(r_test_x, 1)\n",
    "print(r_test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa03832c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0770, -0.0506]], grad_fn=<AddmmBackward>)\n",
      "[1 0 0 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DLMal(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DLMal, self).__init__()\n",
    "        self.embedding = nn.Embedding(25,21)\n",
    "        self.conv1 = nn.Conv2d(1, 64, (15, 3))\n",
    "        self.dropout1 = nn.Dropout(0.6)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3)\n",
    "        self.dropout2 = nn.Dropout(0.6)\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(4096, 768)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(768, 256)\n",
    "        self.dropout4 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(256, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        #print(x.shape)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        #print(x.shape)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.maxpool(x)\n",
    "        #print(x.shape)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout4(x)\n",
    "        return self.fc3(x)\n",
    "net = DLMal()\n",
    "y = net(torch.from_numpy(np.array([r_test_x[0]])))#convert array numpy to tensor\n",
    "print(y)\n",
    "print(r_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0712fc9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] train loss: 0.391 train acc: 0.832\n",
      "[1,     2] train loss: 0.412 train acc: 0.840\n",
      "[1,     3] train loss: 0.356 train acc: 0.852\n",
      "[1,     4] train loss: 0.419 train acc: 0.805\n",
      "[1,     5] train loss: 0.362 train acc: 0.836\n",
      "[1,     6] train loss: 0.441 train acc: 0.777\n",
      "[1,     7] train loss: 0.447 train acc: 0.797\n",
      "[1,     8] train loss: 0.477 train acc: 0.785\n",
      "[1,     9] train loss: 0.371 train acc: 0.824\n",
      "[1,    10] train loss: 0.380 train acc: 0.832\n",
      "[1,    11] train loss: 0.388 train acc: 0.801\n",
      "[1,    12] train loss: 0.407 train acc: 0.820\n",
      "[1,    13] train loss: 0.449 train acc: 0.762\n",
      "[1,    14] train loss: 0.396 train acc: 0.812\n",
      "[1,    15] train loss: 0.383 train acc: 0.836\n",
      "[1,    16] train loss: 0.422 train acc: 0.797\n",
      "[1,    17] train loss: 0.413 train acc: 0.793\n",
      "[1,    18] train loss: 0.422 train acc: 0.777\n",
      "[1,    19] train loss: 0.416 train acc: 0.793\n",
      "[1,    20] train loss: 0.408 train acc: 0.813\n",
      "[1] val loss: 0.351 val acc: 0.950\n",
      "[2,     1] train loss: 0.399 train acc: 0.809\n",
      "[2,     2] train loss: 0.391 train acc: 0.805\n",
      "[2,     3] train loss: 0.390 train acc: 0.828\n",
      "[2,     4] train loss: 0.467 train acc: 0.766\n",
      "[2,     5] train loss: 0.400 train acc: 0.809\n",
      "[2,     6] train loss: 0.446 train acc: 0.781\n",
      "[2,     7] train loss: 0.361 train acc: 0.820\n",
      "[2,     8] train loss: 0.367 train acc: 0.805\n",
      "[2,     9] train loss: 0.391 train acc: 0.809\n",
      "[2,    10] train loss: 0.374 train acc: 0.828\n",
      "[2,    11] train loss: 0.464 train acc: 0.766\n",
      "[2,    12] train loss: 0.414 train acc: 0.824\n",
      "[2,    13] train loss: 0.346 train acc: 0.824\n",
      "[2,    14] train loss: 0.383 train acc: 0.824\n",
      "[2,    15] train loss: 0.393 train acc: 0.809\n",
      "[2,    16] train loss: 0.431 train acc: 0.793\n",
      "[2,    17] train loss: 0.359 train acc: 0.828\n",
      "[2,    18] train loss: 0.444 train acc: 0.781\n",
      "[2,    19] train loss: 0.398 train acc: 0.828\n",
      "[2,    20] train loss: 0.392 train acc: 0.806\n",
      "[2] val loss: 0.321 val acc: 0.946\n",
      "[3,     1] train loss: 0.426 train acc: 0.820\n",
      "[3,     2] train loss: 0.329 train acc: 0.855\n",
      "[3,     3] train loss: 0.385 train acc: 0.805\n",
      "[3,     4] train loss: 0.436 train acc: 0.836\n",
      "[3,     5] train loss: 0.375 train acc: 0.824\n",
      "[3,     6] train loss: 0.388 train acc: 0.824\n",
      "[3,     7] train loss: 0.380 train acc: 0.816\n",
      "[3,     8] train loss: 0.394 train acc: 0.797\n",
      "[3,     9] train loss: 0.386 train acc: 0.824\n",
      "[3,    10] train loss: 0.374 train acc: 0.844\n",
      "[3,    11] train loss: 0.334 train acc: 0.844\n",
      "[3,    12] train loss: 0.384 train acc: 0.805\n",
      "[3,    13] train loss: 0.432 train acc: 0.836\n",
      "[3,    14] train loss: 0.360 train acc: 0.797\n",
      "[3,    15] train loss: 0.429 train acc: 0.793\n",
      "[3,    16] train loss: 0.441 train acc: 0.793\n",
      "[3,    17] train loss: 0.427 train acc: 0.797\n",
      "[3,    18] train loss: 0.385 train acc: 0.832\n",
      "[3,    19] train loss: 0.386 train acc: 0.809\n",
      "[3,    20] train loss: 0.314 train acc: 0.865\n",
      "[3] val loss: 0.339 val acc: 0.955\n",
      "[4,     1] train loss: 0.340 train acc: 0.844\n",
      "[4,     2] train loss: 0.377 train acc: 0.816\n",
      "[4,     3] train loss: 0.357 train acc: 0.816\n",
      "[4,     4] train loss: 0.436 train acc: 0.797\n",
      "[4,     5] train loss: 0.424 train acc: 0.797\n",
      "[4,     6] train loss: 0.392 train acc: 0.797\n",
      "[4,     7] train loss: 0.465 train acc: 0.781\n",
      "[4,     8] train loss: 0.357 train acc: 0.855\n",
      "[4,     9] train loss: 0.334 train acc: 0.852\n",
      "[4,    10] train loss: 0.422 train acc: 0.793\n",
      "[4,    11] train loss: 0.414 train acc: 0.816\n",
      "[4,    12] train loss: 0.418 train acc: 0.832\n",
      "[4,    13] train loss: 0.453 train acc: 0.770\n",
      "[4,    14] train loss: 0.367 train acc: 0.828\n",
      "[4,    15] train loss: 0.334 train acc: 0.863\n",
      "[4,    16] train loss: 0.365 train acc: 0.820\n",
      "[4,    17] train loss: 0.421 train acc: 0.797\n",
      "[4,    18] train loss: 0.433 train acc: 0.758\n",
      "[4,    19] train loss: 0.401 train acc: 0.836\n",
      "[4,    20] train loss: 0.444 train acc: 0.774\n",
      "[4] val loss: 0.342 val acc: 0.951\n",
      "[5,     1] train loss: 0.384 train acc: 0.836\n",
      "[5,     2] train loss: 0.417 train acc: 0.785\n",
      "[5,     3] train loss: 0.373 train acc: 0.855\n",
      "[5,     4] train loss: 0.409 train acc: 0.820\n",
      "[5,     5] train loss: 0.325 train acc: 0.879\n",
      "[5,     6] train loss: 0.393 train acc: 0.820\n",
      "[5,     7] train loss: 0.395 train acc: 0.781\n",
      "[5,     8] train loss: 0.350 train acc: 0.844\n",
      "[5,     9] train loss: 0.388 train acc: 0.812\n",
      "[5,    10] train loss: 0.409 train acc: 0.809\n",
      "[5,    11] train loss: 0.377 train acc: 0.816\n",
      "[5,    12] train loss: 0.345 train acc: 0.844\n",
      "[5,    13] train loss: 0.368 train acc: 0.816\n",
      "[5,    14] train loss: 0.407 train acc: 0.824\n",
      "[5,    15] train loss: 0.367 train acc: 0.828\n",
      "[5,    16] train loss: 0.378 train acc: 0.820\n",
      "[5,    17] train loss: 0.374 train acc: 0.812\n",
      "[5,    18] train loss: 0.392 train acc: 0.809\n",
      "[5,    19] train loss: 0.341 train acc: 0.848\n",
      "[5,    20] train loss: 0.334 train acc: 0.839\n",
      "[5] val loss: 0.310 val acc: 0.958\n",
      "[6,     1] train loss: 0.381 train acc: 0.840\n",
      "[6,     2] train loss: 0.404 train acc: 0.812\n",
      "[6,     3] train loss: 0.383 train acc: 0.824\n",
      "[6,     4] train loss: 0.398 train acc: 0.805\n",
      "[6,     5] train loss: 0.344 train acc: 0.844\n",
      "[6,     6] train loss: 0.381 train acc: 0.820\n",
      "[6,     7] train loss: 0.301 train acc: 0.883\n",
      "[6,     8] train loss: 0.436 train acc: 0.797\n",
      "[6,     9] train loss: 0.389 train acc: 0.824\n",
      "[6,    10] train loss: 0.375 train acc: 0.824\n",
      "[6,    11] train loss: 0.357 train acc: 0.816\n",
      "[6,    12] train loss: 0.378 train acc: 0.816\n",
      "[6,    13] train loss: 0.392 train acc: 0.816\n",
      "[6,    14] train loss: 0.347 train acc: 0.844\n",
      "[6,    15] train loss: 0.418 train acc: 0.812\n",
      "[6,    16] train loss: 0.397 train acc: 0.832\n",
      "[6,    17] train loss: 0.374 train acc: 0.809\n",
      "[6,    18] train loss: 0.325 train acc: 0.859\n",
      "[6,    19] train loss: 0.409 train acc: 0.824\n",
      "[6,    20] train loss: 0.391 train acc: 0.819\n",
      "[6] val loss: 0.312 val acc: 0.951\n",
      "[7,     1] train loss: 0.362 train acc: 0.824\n",
      "[7,     2] train loss: 0.307 train acc: 0.867\n",
      "[7,     3] train loss: 0.415 train acc: 0.781\n",
      "[7,     4] train loss: 0.353 train acc: 0.855\n",
      "[7,     5] train loss: 0.384 train acc: 0.789\n",
      "[7,     6] train loss: 0.363 train acc: 0.844\n",
      "[7,     7] train loss: 0.393 train acc: 0.820\n",
      "[7,     8] train loss: 0.344 train acc: 0.840\n",
      "[7,     9] train loss: 0.420 train acc: 0.828\n",
      "[7,    10] train loss: 0.396 train acc: 0.824\n",
      "[7,    11] train loss: 0.374 train acc: 0.816\n",
      "[7,    12] train loss: 0.366 train acc: 0.828\n",
      "[7,    13] train loss: 0.382 train acc: 0.824\n",
      "[7,    14] train loss: 0.346 train acc: 0.832\n",
      "[7,    15] train loss: 0.366 train acc: 0.832\n",
      "[7,    16] train loss: 0.373 train acc: 0.820\n",
      "[7,    17] train loss: 0.392 train acc: 0.809\n",
      "[7,    18] train loss: 0.345 train acc: 0.867\n",
      "[7,    19] train loss: 0.377 train acc: 0.840\n",
      "[7,    20] train loss: 0.366 train acc: 0.819\n",
      "[7] val loss: 0.316 val acc: 0.963\n",
      "[8,     1] train loss: 0.391 train acc: 0.836\n",
      "[8,     2] train loss: 0.355 train acc: 0.836\n",
      "[8,     3] train loss: 0.381 train acc: 0.852\n",
      "[8,     4] train loss: 0.298 train acc: 0.875\n",
      "[8,     5] train loss: 0.376 train acc: 0.809\n",
      "[8,     6] train loss: 0.376 train acc: 0.852\n",
      "[8,     7] train loss: 0.398 train acc: 0.801\n",
      "[8,     8] train loss: 0.342 train acc: 0.844\n",
      "[8,     9] train loss: 0.327 train acc: 0.863\n",
      "[8,    10] train loss: 0.412 train acc: 0.809\n",
      "[8,    11] train loss: 0.411 train acc: 0.809\n",
      "[8,    12] train loss: 0.325 train acc: 0.848\n",
      "[8,    13] train loss: 0.346 train acc: 0.859\n",
      "[8,    14] train loss: 0.359 train acc: 0.836\n",
      "[8,    15] train loss: 0.339 train acc: 0.828\n",
      "[8,    16] train loss: 0.333 train acc: 0.855\n",
      "[8,    17] train loss: 0.328 train acc: 0.855\n",
      "[8,    18] train loss: 0.376 train acc: 0.840\n",
      "[8,    19] train loss: 0.373 train acc: 0.836\n",
      "[8,    20] train loss: 0.339 train acc: 0.877\n",
      "[8] val loss: 0.291 val acc: 0.963\n",
      "[9,     1] train loss: 0.387 train acc: 0.809\n",
      "[9,     2] train loss: 0.264 train acc: 0.883\n",
      "[9,     3] train loss: 0.337 train acc: 0.848\n",
      "[9,     4] train loss: 0.324 train acc: 0.848\n",
      "[9,     5] train loss: 0.367 train acc: 0.844\n",
      "[9,     6] train loss: 0.423 train acc: 0.789\n",
      "[9,     7] train loss: 0.407 train acc: 0.844\n",
      "[9,     8] train loss: 0.350 train acc: 0.828\n",
      "[9,     9] train loss: 0.430 train acc: 0.770\n",
      "[9,    10] train loss: 0.464 train acc: 0.773\n",
      "[9,    11] train loss: 0.398 train acc: 0.828\n",
      "[9,    12] train loss: 0.360 train acc: 0.848\n",
      "[9,    13] train loss: 0.373 train acc: 0.844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9,    14] train loss: 0.389 train acc: 0.809\n",
      "[9,    15] train loss: 0.319 train acc: 0.871\n",
      "[9,    16] train loss: 0.363 train acc: 0.836\n",
      "[9,    17] train loss: 0.368 train acc: 0.820\n",
      "[9,    18] train loss: 0.358 train acc: 0.801\n",
      "[9,    19] train loss: 0.334 train acc: 0.883\n",
      "[9,    20] train loss: 0.327 train acc: 0.890\n",
      "[9] val loss: 0.313 val acc: 0.959\n",
      "[10,     1] train loss: 0.360 train acc: 0.816\n",
      "[10,     2] train loss: 0.325 train acc: 0.855\n",
      "[10,     3] train loss: 0.364 train acc: 0.824\n",
      "[10,     4] train loss: 0.389 train acc: 0.832\n",
      "[10,     5] train loss: 0.355 train acc: 0.844\n",
      "[10,     6] train loss: 0.355 train acc: 0.840\n",
      "[10,     7] train loss: 0.325 train acc: 0.859\n",
      "[10,     8] train loss: 0.315 train acc: 0.859\n",
      "[10,     9] train loss: 0.373 train acc: 0.816\n",
      "[10,    10] train loss: 0.323 train acc: 0.867\n",
      "[10,    11] train loss: 0.384 train acc: 0.828\n",
      "[10,    12] train loss: 0.342 train acc: 0.828\n",
      "[10,    13] train loss: 0.295 train acc: 0.879\n",
      "[10,    14] train loss: 0.372 train acc: 0.816\n",
      "[10,    15] train loss: 0.330 train acc: 0.816\n",
      "[10,    16] train loss: 0.447 train acc: 0.793\n",
      "[10,    17] train loss: 0.346 train acc: 0.840\n",
      "[10,    18] train loss: 0.355 train acc: 0.840\n",
      "[10,    19] train loss: 0.392 train acc: 0.816\n",
      "[10,    20] train loss: 0.350 train acc: 0.858\n",
      "[10] val loss: 0.290 val acc: 0.965\n",
      "[11,     1] train loss: 0.358 train acc: 0.879\n",
      "[11,     2] train loss: 0.355 train acc: 0.836\n",
      "[11,     3] train loss: 0.379 train acc: 0.805\n",
      "[11,     4] train loss: 0.361 train acc: 0.848\n",
      "[11,     5] train loss: 0.403 train acc: 0.805\n",
      "[11,     6] train loss: 0.354 train acc: 0.828\n",
      "[11,     7] train loss: 0.322 train acc: 0.844\n",
      "[11,     8] train loss: 0.324 train acc: 0.855\n",
      "[11,     9] train loss: 0.356 train acc: 0.840\n",
      "[11,    10] train loss: 0.392 train acc: 0.797\n",
      "[11,    11] train loss: 0.337 train acc: 0.852\n",
      "[11,    12] train loss: 0.343 train acc: 0.824\n",
      "[11,    13] train loss: 0.398 train acc: 0.801\n",
      "[11,    14] train loss: 0.317 train acc: 0.879\n",
      "[11,    15] train loss: 0.405 train acc: 0.816\n",
      "[11,    16] train loss: 0.432 train acc: 0.805\n",
      "[11,    17] train loss: 0.405 train acc: 0.828\n",
      "[11,    18] train loss: 0.369 train acc: 0.855\n",
      "[11,    19] train loss: 0.356 train acc: 0.816\n",
      "[11,    20] train loss: 0.349 train acc: 0.839\n",
      "[11] val loss: 0.298 val acc: 0.971\n",
      "[12,     1] train loss: 0.333 train acc: 0.848\n",
      "[12,     2] train loss: 0.338 train acc: 0.820\n",
      "[12,     3] train loss: 0.361 train acc: 0.855\n",
      "[12,     4] train loss: 0.360 train acc: 0.852\n",
      "[12,     5] train loss: 0.328 train acc: 0.871\n",
      "[12,     6] train loss: 0.366 train acc: 0.824\n",
      "[12,     7] train loss: 0.293 train acc: 0.883\n",
      "[12,     8] train loss: 0.380 train acc: 0.855\n",
      "[12,     9] train loss: 0.305 train acc: 0.895\n",
      "[12,    10] train loss: 0.373 train acc: 0.820\n",
      "[12,    11] train loss: 0.343 train acc: 0.848\n",
      "[12,    12] train loss: 0.363 train acc: 0.820\n",
      "[12,    13] train loss: 0.395 train acc: 0.824\n",
      "[12,    14] train loss: 0.335 train acc: 0.832\n",
      "[12,    15] train loss: 0.365 train acc: 0.832\n",
      "[12,    16] train loss: 0.344 train acc: 0.820\n",
      "[12,    17] train loss: 0.414 train acc: 0.816\n",
      "[12,    18] train loss: 0.328 train acc: 0.855\n",
      "[12,    19] train loss: 0.359 train acc: 0.820\n",
      "[12,    20] train loss: 0.266 train acc: 0.890\n",
      "[12] val loss: 0.283 val acc: 0.976\n",
      "[13,     1] train loss: 0.358 train acc: 0.844\n",
      "[13,     2] train loss: 0.321 train acc: 0.863\n",
      "[13,     3] train loss: 0.351 train acc: 0.832\n",
      "[13,     4] train loss: 0.418 train acc: 0.812\n",
      "[13,     5] train loss: 0.343 train acc: 0.828\n",
      "[13,     6] train loss: 0.311 train acc: 0.859\n",
      "[13,     7] train loss: 0.410 train acc: 0.820\n",
      "[13,     8] train loss: 0.380 train acc: 0.816\n",
      "[13,     9] train loss: 0.378 train acc: 0.820\n",
      "[13,    10] train loss: 0.376 train acc: 0.840\n",
      "[13,    11] train loss: 0.407 train acc: 0.824\n",
      "[13,    12] train loss: 0.339 train acc: 0.844\n",
      "[13,    13] train loss: 0.354 train acc: 0.820\n",
      "[13,    14] train loss: 0.286 train acc: 0.871\n",
      "[13,    15] train loss: 0.350 train acc: 0.828\n",
      "[13,    16] train loss: 0.281 train acc: 0.895\n",
      "[13,    17] train loss: 0.287 train acc: 0.883\n",
      "[13,    18] train loss: 0.331 train acc: 0.855\n",
      "[13,    19] train loss: 0.316 train acc: 0.891\n",
      "[13,    20] train loss: 0.402 train acc: 0.839\n",
      "[13] val loss: 0.277 val acc: 0.983\n",
      "[14,     1] train loss: 0.333 train acc: 0.852\n",
      "[14,     2] train loss: 0.346 train acc: 0.859\n",
      "[14,     3] train loss: 0.360 train acc: 0.840\n",
      "[14,     4] train loss: 0.394 train acc: 0.832\n",
      "[14,     5] train loss: 0.296 train acc: 0.895\n",
      "[14,     6] train loss: 0.352 train acc: 0.840\n",
      "[14,     7] train loss: 0.349 train acc: 0.820\n",
      "[14,     8] train loss: 0.323 train acc: 0.848\n",
      "[14,     9] train loss: 0.325 train acc: 0.859\n",
      "[14,    10] train loss: 0.317 train acc: 0.848\n",
      "[14,    11] train loss: 0.384 train acc: 0.840\n",
      "[14,    12] train loss: 0.353 train acc: 0.871\n",
      "[14,    13] train loss: 0.314 train acc: 0.871\n",
      "[14,    14] train loss: 0.350 train acc: 0.828\n",
      "[14,    15] train loss: 0.354 train acc: 0.840\n",
      "[14,    16] train loss: 0.294 train acc: 0.867\n",
      "[14,    17] train loss: 0.332 train acc: 0.852\n",
      "[14,    18] train loss: 0.396 train acc: 0.832\n",
      "[14,    19] train loss: 0.388 train acc: 0.812\n",
      "[14,    20] train loss: 0.343 train acc: 0.852\n",
      "[14] val loss: 0.275 val acc: 0.977\n",
      "[15,     1] train loss: 0.331 train acc: 0.859\n",
      "[15,     2] train loss: 0.330 train acc: 0.852\n",
      "[15,     3] train loss: 0.360 train acc: 0.836\n",
      "[15,     4] train loss: 0.324 train acc: 0.855\n",
      "[15,     5] train loss: 0.359 train acc: 0.812\n",
      "[15,     6] train loss: 0.376 train acc: 0.832\n",
      "[15,     7] train loss: 0.303 train acc: 0.852\n",
      "[15,     8] train loss: 0.330 train acc: 0.848\n",
      "[15,     9] train loss: 0.395 train acc: 0.828\n",
      "[15,    10] train loss: 0.323 train acc: 0.879\n",
      "[15,    11] train loss: 0.340 train acc: 0.836\n",
      "[15,    12] train loss: 0.336 train acc: 0.852\n",
      "[15,    13] train loss: 0.370 train acc: 0.844\n",
      "[15,    14] train loss: 0.416 train acc: 0.797\n",
      "[15,    15] train loss: 0.313 train acc: 0.863\n",
      "[15,    16] train loss: 0.372 train acc: 0.820\n",
      "[15,    17] train loss: 0.315 train acc: 0.867\n",
      "[15,    18] train loss: 0.332 train acc: 0.867\n",
      "[15,    19] train loss: 0.363 train acc: 0.828\n",
      "[15,    20] train loss: 0.399 train acc: 0.832\n",
      "[15] val loss: 0.279 val acc: 0.976\n",
      "[16,     1] train loss: 0.314 train acc: 0.871\n",
      "[16,     2] train loss: 0.322 train acc: 0.863\n",
      "[16,     3] train loss: 0.349 train acc: 0.859\n",
      "[16,     4] train loss: 0.351 train acc: 0.820\n",
      "[16,     5] train loss: 0.359 train acc: 0.836\n",
      "[16,     6] train loss: 0.328 train acc: 0.859\n",
      "[16,     7] train loss: 0.327 train acc: 0.879\n",
      "[16,     8] train loss: 0.360 train acc: 0.844\n",
      "[16,     9] train loss: 0.383 train acc: 0.820\n",
      "[16,    10] train loss: 0.347 train acc: 0.859\n",
      "[16,    11] train loss: 0.355 train acc: 0.871\n",
      "[16,    12] train loss: 0.402 train acc: 0.844\n",
      "[16,    13] train loss: 0.383 train acc: 0.836\n",
      "[16,    14] train loss: 0.373 train acc: 0.824\n",
      "[16,    15] train loss: 0.364 train acc: 0.828\n",
      "[16,    16] train loss: 0.363 train acc: 0.855\n",
      "[16,    17] train loss: 0.357 train acc: 0.836\n",
      "[16,    18] train loss: 0.321 train acc: 0.855\n",
      "[16,    19] train loss: 0.460 train acc: 0.785\n",
      "[16,    20] train loss: 0.322 train acc: 0.832\n",
      "[16] val loss: 0.280 val acc: 0.980\n",
      "[17,     1] train loss: 0.345 train acc: 0.863\n",
      "[17,     2] train loss: 0.370 train acc: 0.852\n",
      "[17,     3] train loss: 0.321 train acc: 0.863\n",
      "[17,     4] train loss: 0.335 train acc: 0.848\n",
      "[17,     5] train loss: 0.339 train acc: 0.895\n",
      "[17,     6] train loss: 0.337 train acc: 0.844\n",
      "[17,     7] train loss: 0.368 train acc: 0.844\n",
      "[17,     8] train loss: 0.315 train acc: 0.855\n",
      "[17,     9] train loss: 0.349 train acc: 0.832\n",
      "[17,    10] train loss: 0.355 train acc: 0.828\n",
      "[17,    11] train loss: 0.307 train acc: 0.879\n",
      "[17,    12] train loss: 0.366 train acc: 0.848\n",
      "[17,    13] train loss: 0.320 train acc: 0.836\n",
      "[17,    14] train loss: 0.378 train acc: 0.812\n",
      "[17,    15] train loss: 0.259 train acc: 0.902\n",
      "[17,    16] train loss: 0.366 train acc: 0.809\n",
      "[17,    17] train loss: 0.353 train acc: 0.848\n",
      "[17,    18] train loss: 0.369 train acc: 0.816\n",
      "[17,    19] train loss: 0.354 train acc: 0.812\n",
      "[17,    20] train loss: 0.320 train acc: 0.871\n",
      "[17] val loss: 0.260 val acc: 0.983\n",
      "[18,     1] train loss: 0.352 train acc: 0.871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18,     2] train loss: 0.315 train acc: 0.875\n",
      "[18,     3] train loss: 0.298 train acc: 0.875\n",
      "[18,     4] train loss: 0.396 train acc: 0.809\n",
      "[18,     5] train loss: 0.324 train acc: 0.879\n",
      "[18,     6] train loss: 0.359 train acc: 0.828\n",
      "[18,     7] train loss: 0.348 train acc: 0.844\n",
      "[18,     8] train loss: 0.334 train acc: 0.855\n",
      "[18,     9] train loss: 0.305 train acc: 0.859\n",
      "[18,    10] train loss: 0.314 train acc: 0.859\n",
      "[18,    11] train loss: 0.380 train acc: 0.816\n",
      "[18,    12] train loss: 0.396 train acc: 0.828\n",
      "[18,    13] train loss: 0.365 train acc: 0.832\n",
      "[18,    14] train loss: 0.329 train acc: 0.855\n",
      "[18,    15] train loss: 0.262 train acc: 0.883\n",
      "[18,    16] train loss: 0.314 train acc: 0.836\n",
      "[18,    17] train loss: 0.358 train acc: 0.824\n",
      "[18,    18] train loss: 0.337 train acc: 0.859\n",
      "[18,    19] train loss: 0.310 train acc: 0.883\n",
      "[18,    20] train loss: 0.288 train acc: 0.890\n",
      "[18] val loss: 0.247 val acc: 0.987\n",
      "[19,     1] train loss: 0.346 train acc: 0.852\n",
      "[19,     2] train loss: 0.351 train acc: 0.824\n",
      "[19,     3] train loss: 0.318 train acc: 0.863\n",
      "[19,     4] train loss: 0.320 train acc: 0.844\n",
      "[19,     5] train loss: 0.354 train acc: 0.840\n",
      "[19,     6] train loss: 0.321 train acc: 0.859\n",
      "[19,     7] train loss: 0.405 train acc: 0.805\n",
      "[19,     8] train loss: 0.382 train acc: 0.840\n",
      "[19,     9] train loss: 0.382 train acc: 0.836\n",
      "[19,    10] train loss: 0.326 train acc: 0.855\n",
      "[19,    11] train loss: 0.322 train acc: 0.836\n",
      "[19,    12] train loss: 0.386 train acc: 0.820\n",
      "[19,    13] train loss: 0.296 train acc: 0.871\n",
      "[19,    14] train loss: 0.398 train acc: 0.805\n",
      "[19,    15] train loss: 0.377 train acc: 0.805\n",
      "[19,    16] train loss: 0.297 train acc: 0.879\n",
      "[19,    17] train loss: 0.286 train acc: 0.867\n",
      "[19,    18] train loss: 0.306 train acc: 0.859\n",
      "[19,    19] train loss: 0.293 train acc: 0.855\n",
      "[19,    20] train loss: 0.382 train acc: 0.806\n",
      "[19] val loss: 0.268 val acc: 0.990\n",
      "[20,     1] train loss: 0.344 train acc: 0.852\n",
      "[20,     2] train loss: 0.381 train acc: 0.801\n",
      "[20,     3] train loss: 0.342 train acc: 0.879\n",
      "[20,     4] train loss: 0.271 train acc: 0.898\n",
      "[20,     5] train loss: 0.305 train acc: 0.855\n",
      "[20,     6] train loss: 0.354 train acc: 0.828\n",
      "[20,     7] train loss: 0.317 train acc: 0.871\n",
      "[20,     8] train loss: 0.405 train acc: 0.816\n",
      "[20,     9] train loss: 0.335 train acc: 0.848\n",
      "[20,    10] train loss: 0.372 train acc: 0.852\n",
      "[20,    11] train loss: 0.337 train acc: 0.852\n",
      "[20,    12] train loss: 0.353 train acc: 0.844\n",
      "[20,    13] train loss: 0.359 train acc: 0.836\n",
      "[20,    14] train loss: 0.342 train acc: 0.844\n",
      "[20,    15] train loss: 0.372 train acc: 0.852\n",
      "[20,    16] train loss: 0.314 train acc: 0.859\n",
      "[20,    17] train loss: 0.306 train acc: 0.863\n",
      "[20,    18] train loss: 0.335 train acc: 0.832\n",
      "[20,    19] train loss: 0.303 train acc: 0.852\n",
      "[20,    20] train loss: 0.340 train acc: 0.839\n",
      "[20] val loss: 0.250 val acc: 0.984\n",
      "[21,     1] train loss: 0.319 train acc: 0.871\n",
      "[21,     2] train loss: 0.326 train acc: 0.863\n",
      "[21,     3] train loss: 0.318 train acc: 0.871\n",
      "[21,     4] train loss: 0.273 train acc: 0.875\n",
      "[21,     5] train loss: 0.266 train acc: 0.895\n",
      "[21,     6] train loss: 0.264 train acc: 0.883\n",
      "[21,     7] train loss: 0.332 train acc: 0.863\n",
      "[21,     8] train loss: 0.292 train acc: 0.871\n",
      "[21,     9] train loss: 0.311 train acc: 0.867\n",
      "[21,    10] train loss: 0.318 train acc: 0.871\n",
      "[21,    11] train loss: 0.317 train acc: 0.875\n",
      "[21,    12] train loss: 0.324 train acc: 0.836\n",
      "[21,    13] train loss: 0.332 train acc: 0.859\n",
      "[21,    14] train loss: 0.286 train acc: 0.871\n",
      "[21,    15] train loss: 0.314 train acc: 0.855\n",
      "[21,    16] train loss: 0.344 train acc: 0.852\n",
      "[21,    17] train loss: 0.309 train acc: 0.852\n",
      "[21,    18] train loss: 0.306 train acc: 0.871\n",
      "[21,    19] train loss: 0.323 train acc: 0.855\n",
      "[21,    20] train loss: 0.341 train acc: 0.832\n",
      "[21] val loss: 0.244 val acc: 0.982\n",
      "[22,     1] train loss: 0.331 train acc: 0.863\n",
      "[22,     2] train loss: 0.342 train acc: 0.832\n",
      "[22,     3] train loss: 0.335 train acc: 0.832\n",
      "[22,     4] train loss: 0.347 train acc: 0.863\n",
      "[22,     5] train loss: 0.330 train acc: 0.840\n",
      "[22,     6] train loss: 0.329 train acc: 0.871\n",
      "[22,     7] train loss: 0.350 train acc: 0.855\n",
      "[22,     8] train loss: 0.340 train acc: 0.859\n",
      "[22,     9] train loss: 0.364 train acc: 0.844\n",
      "[22,    10] train loss: 0.297 train acc: 0.883\n",
      "[22,    11] train loss: 0.309 train acc: 0.859\n",
      "[22,    12] train loss: 0.347 train acc: 0.840\n",
      "[22,    13] train loss: 0.310 train acc: 0.879\n",
      "[22,    14] train loss: 0.317 train acc: 0.844\n",
      "[22,    15] train loss: 0.335 train acc: 0.848\n",
      "[22,    16] train loss: 0.308 train acc: 0.875\n",
      "[22,    17] train loss: 0.314 train acc: 0.852\n",
      "[22,    18] train loss: 0.373 train acc: 0.848\n",
      "[22,    19] train loss: 0.342 train acc: 0.832\n",
      "[22,    20] train loss: 0.312 train acc: 0.865\n",
      "[22] val loss: 0.240 val acc: 0.986\n",
      "[23,     1] train loss: 0.357 train acc: 0.840\n",
      "[23,     2] train loss: 0.276 train acc: 0.867\n",
      "[23,     3] train loss: 0.283 train acc: 0.871\n",
      "[23,     4] train loss: 0.331 train acc: 0.848\n",
      "[23,     5] train loss: 0.290 train acc: 0.875\n",
      "[23,     6] train loss: 0.317 train acc: 0.875\n",
      "[23,     7] train loss: 0.306 train acc: 0.848\n",
      "[23,     8] train loss: 0.263 train acc: 0.902\n",
      "[23,     9] train loss: 0.323 train acc: 0.859\n",
      "[23,    10] train loss: 0.297 train acc: 0.871\n",
      "[23,    11] train loss: 0.336 train acc: 0.840\n",
      "[23,    12] train loss: 0.312 train acc: 0.875\n",
      "[23,    13] train loss: 0.307 train acc: 0.871\n",
      "[23,    14] train loss: 0.316 train acc: 0.863\n",
      "[23,    15] train loss: 0.283 train acc: 0.855\n",
      "[23,    16] train loss: 0.264 train acc: 0.891\n",
      "[23,    17] train loss: 0.334 train acc: 0.836\n",
      "[23,    18] train loss: 0.308 train acc: 0.855\n",
      "[23,    19] train loss: 0.346 train acc: 0.855\n",
      "[23,    20] train loss: 0.422 train acc: 0.819\n",
      "[23] val loss: 0.235 val acc: 0.990\n",
      "[24,     1] train loss: 0.307 train acc: 0.844\n",
      "[24,     2] train loss: 0.276 train acc: 0.895\n",
      "[24,     3] train loss: 0.294 train acc: 0.855\n",
      "[24,     4] train loss: 0.336 train acc: 0.844\n",
      "[24,     5] train loss: 0.311 train acc: 0.852\n",
      "[24,     6] train loss: 0.339 train acc: 0.848\n",
      "[24,     7] train loss: 0.307 train acc: 0.867\n",
      "[24,     8] train loss: 0.354 train acc: 0.855\n",
      "[24,     9] train loss: 0.314 train acc: 0.859\n",
      "[24,    10] train loss: 0.286 train acc: 0.863\n",
      "[24,    11] train loss: 0.282 train acc: 0.875\n",
      "[24,    12] train loss: 0.366 train acc: 0.816\n",
      "[24,    13] train loss: 0.351 train acc: 0.840\n",
      "[24,    14] train loss: 0.402 train acc: 0.820\n",
      "[24,    15] train loss: 0.348 train acc: 0.832\n",
      "[24,    16] train loss: 0.356 train acc: 0.816\n",
      "[24,    17] train loss: 0.321 train acc: 0.871\n",
      "[24,    18] train loss: 0.339 train acc: 0.852\n",
      "[24,    19] train loss: 0.297 train acc: 0.867\n",
      "[24,    20] train loss: 0.389 train acc: 0.813\n",
      "[24] val loss: 0.248 val acc: 0.992\n",
      "[25,     1] train loss: 0.408 train acc: 0.828\n",
      "[25,     2] train loss: 0.345 train acc: 0.832\n",
      "[25,     3] train loss: 0.324 train acc: 0.863\n",
      "[25,     4] train loss: 0.300 train acc: 0.855\n",
      "[25,     5] train loss: 0.260 train acc: 0.867\n",
      "[25,     6] train loss: 0.340 train acc: 0.848\n",
      "[25,     7] train loss: 0.275 train acc: 0.887\n",
      "[25,     8] train loss: 0.317 train acc: 0.836\n",
      "[25,     9] train loss: 0.316 train acc: 0.844\n",
      "[25,    10] train loss: 0.287 train acc: 0.844\n",
      "[25,    11] train loss: 0.299 train acc: 0.859\n",
      "[25,    12] train loss: 0.315 train acc: 0.871\n",
      "[25,    13] train loss: 0.346 train acc: 0.828\n",
      "[25,    14] train loss: 0.324 train acc: 0.863\n",
      "[25,    15] train loss: 0.356 train acc: 0.848\n",
      "[25,    16] train loss: 0.285 train acc: 0.875\n",
      "[25,    17] train loss: 0.310 train acc: 0.863\n",
      "[25,    18] train loss: 0.310 train acc: 0.879\n",
      "[25,    19] train loss: 0.327 train acc: 0.867\n",
      "[25,    20] train loss: 0.358 train acc: 0.800\n",
      "[25] val loss: 0.217 val acc: 0.993\n",
      "[26,     1] train loss: 0.322 train acc: 0.852\n",
      "[26,     2] train loss: 0.329 train acc: 0.844\n",
      "[26,     3] train loss: 0.253 train acc: 0.906\n",
      "[26,     4] train loss: 0.302 train acc: 0.875\n",
      "[26,     5] train loss: 0.259 train acc: 0.906\n",
      "[26,     6] train loss: 0.354 train acc: 0.828\n",
      "[26,     7] train loss: 0.268 train acc: 0.867\n",
      "[26,     8] train loss: 0.321 train acc: 0.891\n",
      "[26,     9] train loss: 0.283 train acc: 0.879\n",
      "[26,    10] train loss: 0.346 train acc: 0.855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26,    11] train loss: 0.395 train acc: 0.832\n",
      "[26,    12] train loss: 0.278 train acc: 0.891\n",
      "[26,    13] train loss: 0.360 train acc: 0.820\n",
      "[26,    14] train loss: 0.345 train acc: 0.840\n",
      "[26,    15] train loss: 0.294 train acc: 0.867\n",
      "[26,    16] train loss: 0.323 train acc: 0.828\n",
      "[26,    17] train loss: 0.253 train acc: 0.898\n",
      "[26,    18] train loss: 0.304 train acc: 0.859\n",
      "[26,    19] train loss: 0.353 train acc: 0.832\n",
      "[26,    20] train loss: 0.277 train acc: 0.858\n",
      "[26] val loss: 0.213 val acc: 0.994\n",
      "[27,     1] train loss: 0.328 train acc: 0.871\n",
      "[27,     2] train loss: 0.296 train acc: 0.871\n",
      "[27,     3] train loss: 0.289 train acc: 0.871\n",
      "[27,     4] train loss: 0.279 train acc: 0.859\n",
      "[27,     5] train loss: 0.262 train acc: 0.898\n",
      "[27,     6] train loss: 0.214 train acc: 0.914\n",
      "[27,     7] train loss: 0.254 train acc: 0.898\n",
      "[27,     8] train loss: 0.246 train acc: 0.895\n",
      "[27,     9] train loss: 0.330 train acc: 0.863\n",
      "[27,    10] train loss: 0.304 train acc: 0.883\n",
      "[27,    11] train loss: 0.261 train acc: 0.879\n",
      "[27,    12] train loss: 0.293 train acc: 0.883\n",
      "[27,    13] train loss: 0.394 train acc: 0.820\n",
      "[27,    14] train loss: 0.341 train acc: 0.844\n",
      "[27,    15] train loss: 0.279 train acc: 0.887\n",
      "[27,    16] train loss: 0.354 train acc: 0.840\n",
      "[27,    17] train loss: 0.338 train acc: 0.824\n",
      "[27,    18] train loss: 0.358 train acc: 0.832\n",
      "[27,    19] train loss: 0.303 train acc: 0.875\n",
      "[27,    20] train loss: 0.221 train acc: 0.897\n",
      "[27] val loss: 0.210 val acc: 0.993\n",
      "[28,     1] train loss: 0.279 train acc: 0.875\n",
      "[28,     2] train loss: 0.336 train acc: 0.855\n",
      "[28,     3] train loss: 0.294 train acc: 0.879\n",
      "[28,     4] train loss: 0.309 train acc: 0.879\n",
      "[28,     5] train loss: 0.303 train acc: 0.867\n",
      "[28,     6] train loss: 0.269 train acc: 0.879\n",
      "[28,     7] train loss: 0.358 train acc: 0.855\n",
      "[28,     8] train loss: 0.294 train acc: 0.867\n",
      "[28,     9] train loss: 0.266 train acc: 0.883\n",
      "[28,    10] train loss: 0.331 train acc: 0.859\n",
      "[28,    11] train loss: 0.322 train acc: 0.875\n",
      "[28,    12] train loss: 0.363 train acc: 0.844\n",
      "[28,    13] train loss: 0.274 train acc: 0.883\n",
      "[28,    14] train loss: 0.313 train acc: 0.879\n",
      "[28,    15] train loss: 0.357 train acc: 0.844\n",
      "[28,    16] train loss: 0.247 train acc: 0.906\n",
      "[28,    17] train loss: 0.288 train acc: 0.887\n",
      "[28,    18] train loss: 0.322 train acc: 0.871\n",
      "[28,    19] train loss: 0.366 train acc: 0.824\n",
      "[28,    20] train loss: 0.323 train acc: 0.871\n",
      "[28] val loss: 0.223 val acc: 0.994\n",
      "[29,     1] train loss: 0.327 train acc: 0.844\n",
      "[29,     2] train loss: 0.281 train acc: 0.887\n",
      "[29,     3] train loss: 0.295 train acc: 0.891\n",
      "[29,     4] train loss: 0.324 train acc: 0.844\n",
      "[29,     5] train loss: 0.317 train acc: 0.879\n",
      "[29,     6] train loss: 0.303 train acc: 0.848\n",
      "[29,     7] train loss: 0.290 train acc: 0.875\n",
      "[29,     8] train loss: 0.321 train acc: 0.855\n",
      "[29,     9] train loss: 0.345 train acc: 0.848\n",
      "[29,    10] train loss: 0.330 train acc: 0.879\n",
      "[29,    11] train loss: 0.255 train acc: 0.898\n",
      "[29,    12] train loss: 0.294 train acc: 0.883\n",
      "[29,    13] train loss: 0.248 train acc: 0.910\n",
      "[29,    14] train loss: 0.336 train acc: 0.863\n",
      "[29,    15] train loss: 0.336 train acc: 0.871\n",
      "[29,    16] train loss: 0.315 train acc: 0.855\n",
      "[29,    17] train loss: 0.232 train acc: 0.898\n",
      "[29,    18] train loss: 0.335 train acc: 0.848\n",
      "[29,    19] train loss: 0.286 train acc: 0.883\n",
      "[29,    20] train loss: 0.294 train acc: 0.877\n",
      "[29] val loss: 0.205 val acc: 0.995\n",
      "[30,     1] train loss: 0.310 train acc: 0.863\n",
      "[30,     2] train loss: 0.311 train acc: 0.863\n",
      "[30,     3] train loss: 0.288 train acc: 0.867\n",
      "[30,     4] train loss: 0.322 train acc: 0.855\n",
      "[30,     5] train loss: 0.334 train acc: 0.844\n",
      "[30,     6] train loss: 0.307 train acc: 0.859\n",
      "[30,     7] train loss: 0.282 train acc: 0.891\n",
      "[30,     8] train loss: 0.275 train acc: 0.852\n",
      "[30,     9] train loss: 0.281 train acc: 0.906\n",
      "[30,    10] train loss: 0.348 train acc: 0.863\n",
      "[30,    11] train loss: 0.245 train acc: 0.914\n",
      "[30,    12] train loss: 0.284 train acc: 0.891\n",
      "[30,    13] train loss: 0.315 train acc: 0.875\n",
      "[30,    14] train loss: 0.328 train acc: 0.867\n",
      "[30,    15] train loss: 0.296 train acc: 0.871\n",
      "[30,    16] train loss: 0.293 train acc: 0.852\n",
      "[30,    17] train loss: 0.243 train acc: 0.898\n",
      "[30,    18] train loss: 0.298 train acc: 0.855\n",
      "[30,    19] train loss: 0.355 train acc: 0.879\n",
      "[30,    20] train loss: 0.301 train acc: 0.884\n",
      "[30] val loss: 0.199 val acc: 0.994\n",
      "[31,     1] train loss: 0.284 train acc: 0.855\n",
      "[31,     2] train loss: 0.265 train acc: 0.875\n",
      "[31,     3] train loss: 0.275 train acc: 0.898\n",
      "[31,     4] train loss: 0.351 train acc: 0.852\n",
      "[31,     5] train loss: 0.258 train acc: 0.891\n",
      "[31,     6] train loss: 0.258 train acc: 0.895\n",
      "[31,     7] train loss: 0.233 train acc: 0.883\n",
      "[31,     8] train loss: 0.308 train acc: 0.875\n",
      "[31,     9] train loss: 0.345 train acc: 0.840\n",
      "[31,    10] train loss: 0.336 train acc: 0.852\n",
      "[31,    11] train loss: 0.311 train acc: 0.855\n",
      "[31,    12] train loss: 0.257 train acc: 0.875\n",
      "[31,    13] train loss: 0.303 train acc: 0.871\n",
      "[31,    14] train loss: 0.292 train acc: 0.883\n",
      "[31,    15] train loss: 0.311 train acc: 0.871\n",
      "[31,    16] train loss: 0.323 train acc: 0.840\n",
      "[31,    17] train loss: 0.275 train acc: 0.883\n",
      "[31,    18] train loss: 0.244 train acc: 0.895\n",
      "[31,    19] train loss: 0.283 train acc: 0.891\n",
      "[31,    20] train loss: 0.262 train acc: 0.897\n",
      "[31] val loss: 0.203 val acc: 0.994\n",
      "[32,     1] train loss: 0.258 train acc: 0.891\n",
      "[32,     2] train loss: 0.266 train acc: 0.879\n",
      "[32,     3] train loss: 0.240 train acc: 0.891\n",
      "[32,     4] train loss: 0.283 train acc: 0.891\n",
      "[32,     5] train loss: 0.256 train acc: 0.875\n",
      "[32,     6] train loss: 0.329 train acc: 0.875\n",
      "[32,     7] train loss: 0.273 train acc: 0.898\n",
      "[32,     8] train loss: 0.229 train acc: 0.910\n",
      "[32,     9] train loss: 0.216 train acc: 0.883\n",
      "[32,    10] train loss: 0.311 train acc: 0.891\n",
      "[32,    11] train loss: 0.268 train acc: 0.902\n",
      "[32,    12] train loss: 0.342 train acc: 0.852\n",
      "[32,    13] train loss: 0.223 train acc: 0.902\n",
      "[32,    14] train loss: 0.364 train acc: 0.859\n",
      "[32,    15] train loss: 0.310 train acc: 0.844\n",
      "[32,    16] train loss: 0.313 train acc: 0.859\n",
      "[32,    17] train loss: 0.296 train acc: 0.863\n",
      "[32,    18] train loss: 0.238 train acc: 0.898\n",
      "[32,    19] train loss: 0.229 train acc: 0.902\n",
      "[32,    20] train loss: 0.431 train acc: 0.852\n",
      "[32] val loss: 0.185 val acc: 0.996\n",
      "[33,     1] train loss: 0.356 train acc: 0.848\n",
      "[33,     2] train loss: 0.283 train acc: 0.875\n",
      "[33,     3] train loss: 0.326 train acc: 0.852\n",
      "[33,     4] train loss: 0.273 train acc: 0.867\n",
      "[33,     5] train loss: 0.297 train acc: 0.867\n",
      "[33,     6] train loss: 0.227 train acc: 0.918\n",
      "[33,     7] train loss: 0.278 train acc: 0.859\n",
      "[33,     8] train loss: 0.274 train acc: 0.887\n",
      "[33,     9] train loss: 0.333 train acc: 0.863\n",
      "[33,    10] train loss: 0.254 train acc: 0.902\n",
      "[33,    11] train loss: 0.286 train acc: 0.875\n",
      "[33,    12] train loss: 0.282 train acc: 0.891\n",
      "[33,    13] train loss: 0.282 train acc: 0.871\n",
      "[33,    14] train loss: 0.242 train acc: 0.883\n",
      "[33,    15] train loss: 0.315 train acc: 0.844\n",
      "[33,    16] train loss: 0.283 train acc: 0.859\n",
      "[33,    17] train loss: 0.323 train acc: 0.852\n",
      "[33,    18] train loss: 0.273 train acc: 0.883\n",
      "[33,    19] train loss: 0.255 train acc: 0.906\n",
      "[33,    20] train loss: 0.172 train acc: 0.935\n",
      "[33] val loss: 0.179 val acc: 0.994\n",
      "[34,     1] train loss: 0.267 train acc: 0.910\n",
      "[34,     2] train loss: 0.254 train acc: 0.895\n",
      "[34,     3] train loss: 0.360 train acc: 0.844\n",
      "[34,     4] train loss: 0.252 train acc: 0.898\n",
      "[34,     5] train loss: 0.239 train acc: 0.910\n",
      "[34,     6] train loss: 0.325 train acc: 0.852\n",
      "[34,     7] train loss: 0.303 train acc: 0.891\n",
      "[34,     8] train loss: 0.243 train acc: 0.895\n",
      "[34,     9] train loss: 0.236 train acc: 0.922\n",
      "[34,    10] train loss: 0.314 train acc: 0.867\n",
      "[34,    11] train loss: 0.294 train acc: 0.875\n",
      "[34,    12] train loss: 0.181 train acc: 0.945\n",
      "[34,    13] train loss: 0.303 train acc: 0.855\n",
      "[34,    14] train loss: 0.285 train acc: 0.867\n",
      "[34,    15] train loss: 0.298 train acc: 0.855\n",
      "[34,    16] train loss: 0.255 train acc: 0.875\n",
      "[34,    17] train loss: 0.274 train acc: 0.891\n",
      "[34,    18] train loss: 0.244 train acc: 0.879\n",
      "[34,    19] train loss: 0.281 train acc: 0.883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34,    20] train loss: 0.285 train acc: 0.871\n",
      "[34] val loss: 0.183 val acc: 0.997\n",
      "[35,     1] train loss: 0.270 train acc: 0.871\n",
      "[35,     2] train loss: 0.255 train acc: 0.902\n",
      "[35,     3] train loss: 0.256 train acc: 0.887\n",
      "[35,     4] train loss: 0.260 train acc: 0.887\n",
      "[35,     5] train loss: 0.265 train acc: 0.891\n",
      "[35,     6] train loss: 0.198 train acc: 0.934\n",
      "[35,     7] train loss: 0.300 train acc: 0.891\n",
      "[35,     8] train loss: 0.239 train acc: 0.891\n",
      "[35,     9] train loss: 0.244 train acc: 0.914\n",
      "[35,    10] train loss: 0.231 train acc: 0.891\n",
      "[35,    11] train loss: 0.305 train acc: 0.875\n",
      "[35,    12] train loss: 0.268 train acc: 0.891\n",
      "[35,    13] train loss: 0.250 train acc: 0.891\n",
      "[35,    14] train loss: 0.290 train acc: 0.859\n",
      "[35,    15] train loss: 0.327 train acc: 0.855\n",
      "[35,    16] train loss: 0.333 train acc: 0.879\n",
      "[35,    17] train loss: 0.288 train acc: 0.859\n",
      "[35,    18] train loss: 0.262 train acc: 0.887\n",
      "[35,    19] train loss: 0.250 train acc: 0.867\n",
      "[35,    20] train loss: 0.200 train acc: 0.916\n",
      "[35] val loss: 0.173 val acc: 0.995\n",
      "[36,     1] train loss: 0.253 train acc: 0.879\n",
      "[36,     2] train loss: 0.274 train acc: 0.883\n",
      "[36,     3] train loss: 0.354 train acc: 0.859\n",
      "[36,     4] train loss: 0.276 train acc: 0.855\n",
      "[36,     5] train loss: 0.214 train acc: 0.914\n",
      "[36,     6] train loss: 0.239 train acc: 0.918\n",
      "[36,     7] train loss: 0.201 train acc: 0.918\n",
      "[36,     8] train loss: 0.270 train acc: 0.891\n",
      "[36,     9] train loss: 0.222 train acc: 0.898\n",
      "[36,    10] train loss: 0.263 train acc: 0.887\n",
      "[36,    11] train loss: 0.243 train acc: 0.898\n",
      "[36,    12] train loss: 0.273 train acc: 0.871\n",
      "[36,    13] train loss: 0.286 train acc: 0.867\n",
      "[36,    14] train loss: 0.273 train acc: 0.871\n",
      "[36,    15] train loss: 0.233 train acc: 0.910\n",
      "[36,    16] train loss: 0.229 train acc: 0.902\n",
      "[36,    17] train loss: 0.270 train acc: 0.871\n",
      "[36,    18] train loss: 0.219 train acc: 0.910\n",
      "[36,    19] train loss: 0.214 train acc: 0.910\n",
      "[36,    20] train loss: 0.300 train acc: 0.865\n",
      "[36] val loss: 0.158 val acc: 0.994\n",
      "[37,     1] train loss: 0.290 train acc: 0.867\n",
      "[37,     2] train loss: 0.241 train acc: 0.887\n",
      "[37,     3] train loss: 0.243 train acc: 0.898\n",
      "[37,     4] train loss: 0.241 train acc: 0.891\n",
      "[37,     5] train loss: 0.305 train acc: 0.867\n",
      "[37,     6] train loss: 0.297 train acc: 0.867\n",
      "[37,     7] train loss: 0.299 train acc: 0.863\n",
      "[37,     8] train loss: 0.346 train acc: 0.832\n",
      "[37,     9] train loss: 0.236 train acc: 0.906\n",
      "[37,    10] train loss: 0.229 train acc: 0.918\n",
      "[37,    11] train loss: 0.278 train acc: 0.879\n",
      "[37,    12] train loss: 0.260 train acc: 0.891\n",
      "[37,    13] train loss: 0.298 train acc: 0.879\n",
      "[37,    14] train loss: 0.325 train acc: 0.836\n",
      "[37,    15] train loss: 0.255 train acc: 0.895\n",
      "[37,    16] train loss: 0.295 train acc: 0.867\n",
      "[37,    17] train loss: 0.285 train acc: 0.875\n",
      "[37,    18] train loss: 0.262 train acc: 0.902\n",
      "[37,    19] train loss: 0.226 train acc: 0.918\n",
      "[37,    20] train loss: 0.311 train acc: 0.871\n",
      "[37] val loss: 0.173 val acc: 0.996\n",
      "[38,     1] train loss: 0.222 train acc: 0.902\n",
      "[38,     2] train loss: 0.344 train acc: 0.848\n",
      "[38,     3] train loss: 0.316 train acc: 0.867\n",
      "[38,     4] train loss: 0.280 train acc: 0.867\n",
      "[38,     5] train loss: 0.361 train acc: 0.832\n",
      "[38,     6] train loss: 0.211 train acc: 0.906\n",
      "[38,     7] train loss: 0.278 train acc: 0.883\n",
      "[38,     8] train loss: 0.222 train acc: 0.895\n",
      "[38,     9] train loss: 0.213 train acc: 0.906\n",
      "[38,    10] train loss: 0.284 train acc: 0.867\n",
      "[38,    11] train loss: 0.276 train acc: 0.871\n",
      "[38,    12] train loss: 0.254 train acc: 0.910\n",
      "[38,    13] train loss: 0.259 train acc: 0.887\n",
      "[38,    14] train loss: 0.299 train acc: 0.855\n",
      "[38,    15] train loss: 0.208 train acc: 0.906\n",
      "[38,    16] train loss: 0.260 train acc: 0.910\n",
      "[38,    17] train loss: 0.270 train acc: 0.883\n",
      "[38,    18] train loss: 0.248 train acc: 0.895\n",
      "[38,    19] train loss: 0.226 train acc: 0.887\n",
      "[38,    20] train loss: 0.204 train acc: 0.897\n",
      "[38] val loss: 0.170 val acc: 0.996\n",
      "[39,     1] train loss: 0.260 train acc: 0.902\n",
      "[39,     2] train loss: 0.255 train acc: 0.879\n",
      "[39,     3] train loss: 0.289 train acc: 0.895\n",
      "[39,     4] train loss: 0.257 train acc: 0.895\n",
      "[39,     5] train loss: 0.277 train acc: 0.887\n",
      "[39,     6] train loss: 0.261 train acc: 0.875\n",
      "[39,     7] train loss: 0.264 train acc: 0.895\n",
      "[39,     8] train loss: 0.217 train acc: 0.910\n",
      "[39,     9] train loss: 0.201 train acc: 0.922\n",
      "[39,    10] train loss: 0.285 train acc: 0.863\n",
      "[39,    11] train loss: 0.298 train acc: 0.867\n",
      "[39,    12] train loss: 0.278 train acc: 0.859\n",
      "[39,    13] train loss: 0.288 train acc: 0.879\n",
      "[39,    14] train loss: 0.268 train acc: 0.891\n",
      "[39,    15] train loss: 0.286 train acc: 0.883\n",
      "[39,    16] train loss: 0.274 train acc: 0.895\n",
      "[39,    17] train loss: 0.298 train acc: 0.887\n",
      "[39,    18] train loss: 0.258 train acc: 0.895\n",
      "[39,    19] train loss: 0.269 train acc: 0.887\n",
      "[39,    20] train loss: 0.227 train acc: 0.910\n",
      "[39] val loss: 0.162 val acc: 0.995\n",
      "[40,     1] train loss: 0.273 train acc: 0.883\n",
      "[40,     2] train loss: 0.227 train acc: 0.891\n",
      "[40,     3] train loss: 0.214 train acc: 0.930\n",
      "[40,     4] train loss: 0.230 train acc: 0.906\n",
      "[40,     5] train loss: 0.279 train acc: 0.895\n",
      "[40,     6] train loss: 0.237 train acc: 0.898\n",
      "[40,     7] train loss: 0.276 train acc: 0.863\n",
      "[40,     8] train loss: 0.245 train acc: 0.895\n",
      "[40,     9] train loss: 0.254 train acc: 0.879\n",
      "[40,    10] train loss: 0.263 train acc: 0.898\n",
      "[40,    11] train loss: 0.232 train acc: 0.895\n",
      "[40,    12] train loss: 0.286 train acc: 0.867\n",
      "[40,    13] train loss: 0.238 train acc: 0.895\n",
      "[40,    14] train loss: 0.261 train acc: 0.867\n",
      "[40,    15] train loss: 0.253 train acc: 0.871\n",
      "[40,    16] train loss: 0.226 train acc: 0.926\n",
      "[40,    17] train loss: 0.291 train acc: 0.902\n",
      "[40,    18] train loss: 0.241 train acc: 0.895\n",
      "[40,    19] train loss: 0.276 train acc: 0.898\n",
      "[40,    20] train loss: 0.233 train acc: 0.923\n",
      "[40] val loss: 0.154 val acc: 0.997\n",
      "[41,     1] train loss: 0.227 train acc: 0.891\n",
      "[41,     2] train loss: 0.232 train acc: 0.922\n",
      "[41,     3] train loss: 0.252 train acc: 0.895\n",
      "[41,     4] train loss: 0.301 train acc: 0.875\n",
      "[41,     5] train loss: 0.182 train acc: 0.934\n",
      "[41,     6] train loss: 0.240 train acc: 0.898\n",
      "[41,     7] train loss: 0.280 train acc: 0.859\n",
      "[41,     8] train loss: 0.236 train acc: 0.895\n",
      "[41,     9] train loss: 0.294 train acc: 0.883\n",
      "[41,    10] train loss: 0.315 train acc: 0.855\n",
      "[41,    11] train loss: 0.288 train acc: 0.871\n",
      "[41,    12] train loss: 0.248 train acc: 0.910\n",
      "[41,    13] train loss: 0.222 train acc: 0.910\n",
      "[41,    14] train loss: 0.243 train acc: 0.898\n",
      "[41,    15] train loss: 0.241 train acc: 0.879\n",
      "[41,    16] train loss: 0.265 train acc: 0.875\n",
      "[41,    17] train loss: 0.257 train acc: 0.879\n",
      "[41,    18] train loss: 0.294 train acc: 0.867\n",
      "[41,    19] train loss: 0.235 train acc: 0.891\n",
      "[41,    20] train loss: 0.256 train acc: 0.865\n",
      "[41] val loss: 0.164 val acc: 0.998\n",
      "[42,     1] train loss: 0.216 train acc: 0.910\n",
      "[42,     2] train loss: 0.281 train acc: 0.871\n",
      "[42,     3] train loss: 0.278 train acc: 0.867\n",
      "[42,     4] train loss: 0.272 train acc: 0.887\n",
      "[42,     5] train loss: 0.291 train acc: 0.891\n",
      "[42,     6] train loss: 0.203 train acc: 0.926\n",
      "[42,     7] train loss: 0.198 train acc: 0.930\n",
      "[42,     8] train loss: 0.228 train acc: 0.906\n",
      "[42,     9] train loss: 0.219 train acc: 0.906\n",
      "[42,    10] train loss: 0.253 train acc: 0.898\n",
      "[42,    11] train loss: 0.211 train acc: 0.922\n",
      "[42,    12] train loss: 0.263 train acc: 0.887\n",
      "[42,    13] train loss: 0.191 train acc: 0.918\n",
      "[42,    14] train loss: 0.246 train acc: 0.891\n",
      "[42,    15] train loss: 0.340 train acc: 0.848\n",
      "[42,    16] train loss: 0.235 train acc: 0.906\n",
      "[42,    17] train loss: 0.226 train acc: 0.898\n",
      "[42,    18] train loss: 0.212 train acc: 0.891\n",
      "[42,    19] train loss: 0.250 train acc: 0.910\n",
      "[42,    20] train loss: 0.278 train acc: 0.897\n",
      "[42] val loss: 0.143 val acc: 0.999\n",
      "[43,     1] train loss: 0.236 train acc: 0.902\n",
      "[43,     2] train loss: 0.238 train acc: 0.898\n",
      "[43,     3] train loss: 0.194 train acc: 0.930\n",
      "[43,     4] train loss: 0.281 train acc: 0.891\n",
      "[43,     5] train loss: 0.259 train acc: 0.879\n",
      "[43,     6] train loss: 0.260 train acc: 0.887\n",
      "[43,     7] train loss: 0.252 train acc: 0.902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43,     8] train loss: 0.254 train acc: 0.910\n",
      "[43,     9] train loss: 0.260 train acc: 0.906\n",
      "[43,    10] train loss: 0.252 train acc: 0.914\n",
      "[43,    11] train loss: 0.272 train acc: 0.883\n",
      "[43,    12] train loss: 0.241 train acc: 0.895\n",
      "[43,    13] train loss: 0.268 train acc: 0.879\n",
      "[43,    14] train loss: 0.254 train acc: 0.875\n",
      "[43,    15] train loss: 0.246 train acc: 0.898\n",
      "[43,    16] train loss: 0.278 train acc: 0.875\n",
      "[43,    17] train loss: 0.247 train acc: 0.887\n",
      "[43,    18] train loss: 0.243 train acc: 0.895\n",
      "[43,    19] train loss: 0.257 train acc: 0.871\n",
      "[43,    20] train loss: 0.295 train acc: 0.845\n",
      "[43] val loss: 0.149 val acc: 0.998\n",
      "[44,     1] train loss: 0.230 train acc: 0.906\n",
      "[44,     2] train loss: 0.240 train acc: 0.895\n",
      "[44,     3] train loss: 0.238 train acc: 0.891\n",
      "[44,     4] train loss: 0.253 train acc: 0.895\n",
      "[44,     5] train loss: 0.215 train acc: 0.922\n",
      "[44,     6] train loss: 0.241 train acc: 0.910\n",
      "[44,     7] train loss: 0.256 train acc: 0.898\n",
      "[44,     8] train loss: 0.244 train acc: 0.914\n",
      "[44,     9] train loss: 0.231 train acc: 0.906\n",
      "[44,    10] train loss: 0.267 train acc: 0.863\n",
      "[44,    11] train loss: 0.232 train acc: 0.902\n",
      "[44,    12] train loss: 0.266 train acc: 0.891\n",
      "[44,    13] train loss: 0.247 train acc: 0.895\n",
      "[44,    14] train loss: 0.306 train acc: 0.875\n",
      "[44,    15] train loss: 0.299 train acc: 0.887\n",
      "[44,    16] train loss: 0.345 train acc: 0.871\n",
      "[44,    17] train loss: 0.269 train acc: 0.910\n",
      "[44,    18] train loss: 0.235 train acc: 0.906\n",
      "[44,    19] train loss: 0.331 train acc: 0.840\n",
      "[44,    20] train loss: 0.304 train acc: 0.858\n",
      "[44] val loss: 0.160 val acc: 0.999\n",
      "[45,     1] train loss: 0.228 train acc: 0.891\n",
      "[45,     2] train loss: 0.199 train acc: 0.926\n",
      "[45,     3] train loss: 0.192 train acc: 0.930\n",
      "[45,     4] train loss: 0.266 train acc: 0.891\n",
      "[45,     5] train loss: 0.189 train acc: 0.926\n",
      "[45,     6] train loss: 0.249 train acc: 0.895\n",
      "[45,     7] train loss: 0.254 train acc: 0.887\n",
      "[45,     8] train loss: 0.262 train acc: 0.887\n",
      "[45,     9] train loss: 0.202 train acc: 0.918\n",
      "[45,    10] train loss: 0.209 train acc: 0.898\n",
      "[45,    11] train loss: 0.230 train acc: 0.891\n",
      "[45,    12] train loss: 0.222 train acc: 0.898\n",
      "[45,    13] train loss: 0.204 train acc: 0.906\n",
      "[45,    14] train loss: 0.244 train acc: 0.918\n",
      "[45,    15] train loss: 0.239 train acc: 0.910\n",
      "[45,    16] train loss: 0.234 train acc: 0.883\n",
      "[45,    17] train loss: 0.235 train acc: 0.895\n",
      "[45,    18] train loss: 0.282 train acc: 0.879\n",
      "[45,    19] train loss: 0.275 train acc: 0.883\n",
      "[45,    20] train loss: 0.266 train acc: 0.890\n",
      "[45] val loss: 0.139 val acc: 0.998\n",
      "[46,     1] train loss: 0.220 train acc: 0.891\n",
      "[46,     2] train loss: 0.241 train acc: 0.895\n",
      "[46,     3] train loss: 0.230 train acc: 0.902\n",
      "[46,     4] train loss: 0.339 train acc: 0.859\n",
      "[46,     5] train loss: 0.315 train acc: 0.871\n",
      "[46,     6] train loss: 0.226 train acc: 0.906\n",
      "[46,     7] train loss: 0.221 train acc: 0.910\n",
      "[46,     8] train loss: 0.255 train acc: 0.883\n",
      "[46,     9] train loss: 0.182 train acc: 0.922\n",
      "[46,    10] train loss: 0.218 train acc: 0.898\n",
      "[46,    11] train loss: 0.292 train acc: 0.895\n",
      "[46,    12] train loss: 0.255 train acc: 0.906\n",
      "[46,    13] train loss: 0.220 train acc: 0.906\n",
      "[46,    14] train loss: 0.242 train acc: 0.898\n",
      "[46,    15] train loss: 0.182 train acc: 0.941\n",
      "[46,    16] train loss: 0.225 train acc: 0.918\n",
      "[46,    17] train loss: 0.234 train acc: 0.906\n",
      "[46,    18] train loss: 0.368 train acc: 0.844\n",
      "[46,    19] train loss: 0.252 train acc: 0.895\n",
      "[46,    20] train loss: 0.254 train acc: 0.890\n",
      "[46] val loss: 0.151 val acc: 0.999\n",
      "[47,     1] train loss: 0.237 train acc: 0.898\n",
      "[47,     2] train loss: 0.208 train acc: 0.906\n",
      "[47,     3] train loss: 0.220 train acc: 0.914\n",
      "[47,     4] train loss: 0.243 train acc: 0.914\n",
      "[47,     5] train loss: 0.203 train acc: 0.930\n",
      "[47,     6] train loss: 0.199 train acc: 0.918\n",
      "[47,     7] train loss: 0.200 train acc: 0.926\n",
      "[47,     8] train loss: 0.253 train acc: 0.887\n",
      "[47,     9] train loss: 0.273 train acc: 0.875\n",
      "[47,    10] train loss: 0.306 train acc: 0.879\n",
      "[47,    11] train loss: 0.263 train acc: 0.898\n",
      "[47,    12] train loss: 0.234 train acc: 0.910\n",
      "[47,    13] train loss: 0.200 train acc: 0.918\n",
      "[47,    14] train loss: 0.279 train acc: 0.879\n",
      "[47,    15] train loss: 0.253 train acc: 0.891\n",
      "[47,    16] train loss: 0.228 train acc: 0.906\n",
      "[47,    17] train loss: 0.270 train acc: 0.883\n",
      "[47,    18] train loss: 0.282 train acc: 0.875\n",
      "[47,    19] train loss: 0.210 train acc: 0.902\n",
      "[47,    20] train loss: 0.234 train acc: 0.877\n",
      "[47] val loss: 0.125 val acc: 0.999\n",
      "[48,     1] train loss: 0.242 train acc: 0.898\n",
      "[48,     2] train loss: 0.216 train acc: 0.910\n",
      "[48,     3] train loss: 0.206 train acc: 0.922\n",
      "[48,     4] train loss: 0.218 train acc: 0.895\n",
      "[48,     5] train loss: 0.249 train acc: 0.906\n",
      "[48,     6] train loss: 0.218 train acc: 0.914\n",
      "[48,     7] train loss: 0.306 train acc: 0.879\n",
      "[48,     8] train loss: 0.212 train acc: 0.918\n",
      "[48,     9] train loss: 0.209 train acc: 0.918\n",
      "[48,    10] train loss: 0.312 train acc: 0.855\n",
      "[48,    11] train loss: 0.203 train acc: 0.918\n",
      "[48,    12] train loss: 0.250 train acc: 0.910\n",
      "[48,    13] train loss: 0.249 train acc: 0.914\n",
      "[48,    14] train loss: 0.173 train acc: 0.941\n",
      "[48,    15] train loss: 0.195 train acc: 0.910\n",
      "[48,    16] train loss: 0.243 train acc: 0.898\n",
      "[48,    17] train loss: 0.234 train acc: 0.887\n",
      "[48,    18] train loss: 0.260 train acc: 0.879\n",
      "[48,    19] train loss: 0.278 train acc: 0.898\n",
      "[48,    20] train loss: 0.181 train acc: 0.916\n",
      "[48] val loss: 0.130 val acc: 0.999\n",
      "[49,     1] train loss: 0.252 train acc: 0.906\n",
      "[49,     2] train loss: 0.182 train acc: 0.926\n",
      "[49,     3] train loss: 0.203 train acc: 0.910\n",
      "[49,     4] train loss: 0.271 train acc: 0.891\n",
      "[49,     5] train loss: 0.277 train acc: 0.875\n",
      "[49,     6] train loss: 0.245 train acc: 0.898\n",
      "[49,     7] train loss: 0.267 train acc: 0.875\n",
      "[49,     8] train loss: 0.258 train acc: 0.910\n",
      "[49,     9] train loss: 0.250 train acc: 0.879\n",
      "[49,    10] train loss: 0.284 train acc: 0.863\n",
      "[49,    11] train loss: 0.249 train acc: 0.906\n",
      "[49,    12] train loss: 0.206 train acc: 0.914\n",
      "[49,    13] train loss: 0.221 train acc: 0.902\n",
      "[49,    14] train loss: 0.242 train acc: 0.902\n",
      "[49,    15] train loss: 0.218 train acc: 0.918\n",
      "[49,    16] train loss: 0.237 train acc: 0.887\n",
      "[49,    17] train loss: 0.257 train acc: 0.898\n",
      "[49,    18] train loss: 0.204 train acc: 0.922\n",
      "[49,    19] train loss: 0.259 train acc: 0.883\n",
      "[49,    20] train loss: 0.136 train acc: 0.955\n",
      "[49] val loss: 0.140 val acc: 0.999\n",
      "[50,     1] train loss: 0.298 train acc: 0.879\n",
      "[50,     2] train loss: 0.256 train acc: 0.910\n",
      "[50,     3] train loss: 0.198 train acc: 0.926\n",
      "[50,     4] train loss: 0.247 train acc: 0.906\n",
      "[50,     5] train loss: 0.251 train acc: 0.891\n",
      "[50,     6] train loss: 0.229 train acc: 0.914\n",
      "[50,     7] train loss: 0.264 train acc: 0.906\n",
      "[50,     8] train loss: 0.200 train acc: 0.906\n",
      "[50,     9] train loss: 0.174 train acc: 0.926\n",
      "[50,    10] train loss: 0.252 train acc: 0.891\n",
      "[50,    11] train loss: 0.259 train acc: 0.883\n",
      "[50,    12] train loss: 0.311 train acc: 0.883\n",
      "[50,    13] train loss: 0.210 train acc: 0.891\n",
      "[50,    14] train loss: 0.230 train acc: 0.914\n",
      "[50,    15] train loss: 0.264 train acc: 0.852\n",
      "[50,    16] train loss: 0.278 train acc: 0.883\n",
      "[50,    17] train loss: 0.191 train acc: 0.926\n",
      "[50,    18] train loss: 0.190 train acc: 0.930\n",
      "[50,    19] train loss: 0.236 train acc: 0.922\n",
      "[50,    20] train loss: 0.166 train acc: 0.961\n",
      "[50] val loss: 0.126 val acc: 0.998\n",
      "[51,     1] train loss: 0.202 train acc: 0.910\n",
      "[51,     2] train loss: 0.218 train acc: 0.898\n",
      "[51,     3] train loss: 0.250 train acc: 0.887\n",
      "[51,     4] train loss: 0.240 train acc: 0.895\n",
      "[51,     5] train loss: 0.254 train acc: 0.891\n",
      "[51,     6] train loss: 0.187 train acc: 0.926\n",
      "[51,     7] train loss: 0.227 train acc: 0.910\n",
      "[51,     8] train loss: 0.223 train acc: 0.898\n",
      "[51,     9] train loss: 0.142 train acc: 0.961\n",
      "[51,    10] train loss: 0.196 train acc: 0.922\n",
      "[51,    11] train loss: 0.304 train acc: 0.855\n",
      "[51,    12] train loss: 0.229 train acc: 0.910\n",
      "[51,    13] train loss: 0.241 train acc: 0.887\n",
      "[51,    14] train loss: 0.187 train acc: 0.918\n",
      "[51,    15] train loss: 0.237 train acc: 0.902\n",
      "[51,    16] train loss: 0.225 train acc: 0.895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51,    17] train loss: 0.230 train acc: 0.914\n",
      "[51,    18] train loss: 0.203 train acc: 0.910\n",
      "[51,    19] train loss: 0.266 train acc: 0.895\n",
      "[51,    20] train loss: 0.199 train acc: 0.916\n",
      "[51] val loss: 0.122 val acc: 0.999\n",
      "[52,     1] train loss: 0.192 train acc: 0.918\n",
      "[52,     2] train loss: 0.249 train acc: 0.895\n",
      "[52,     3] train loss: 0.186 train acc: 0.906\n",
      "[52,     4] train loss: 0.158 train acc: 0.938\n",
      "[52,     5] train loss: 0.184 train acc: 0.930\n",
      "[52,     6] train loss: 0.221 train acc: 0.898\n",
      "[52,     7] train loss: 0.223 train acc: 0.914\n",
      "[52,     8] train loss: 0.308 train acc: 0.875\n",
      "[52,     9] train loss: 0.237 train acc: 0.918\n",
      "[52,    10] train loss: 0.192 train acc: 0.934\n",
      "[52,    11] train loss: 0.243 train acc: 0.875\n",
      "[52,    12] train loss: 0.286 train acc: 0.891\n",
      "[52,    13] train loss: 0.294 train acc: 0.871\n",
      "[52,    14] train loss: 0.238 train acc: 0.918\n",
      "[52,    15] train loss: 0.173 train acc: 0.914\n",
      "[52,    16] train loss: 0.264 train acc: 0.895\n",
      "[52,    17] train loss: 0.212 train acc: 0.914\n",
      "[52,    18] train loss: 0.237 train acc: 0.906\n",
      "[52,    19] train loss: 0.249 train acc: 0.895\n",
      "[52,    20] train loss: 0.251 train acc: 0.916\n",
      "[52] val loss: 0.129 val acc: 0.999\n",
      "[53,     1] train loss: 0.191 train acc: 0.914\n",
      "[53,     2] train loss: 0.250 train acc: 0.875\n",
      "[53,     3] train loss: 0.191 train acc: 0.926\n",
      "[53,     4] train loss: 0.235 train acc: 0.891\n",
      "[53,     5] train loss: 0.314 train acc: 0.859\n",
      "[53,     6] train loss: 0.233 train acc: 0.875\n",
      "[53,     7] train loss: 0.252 train acc: 0.898\n",
      "[53,     8] train loss: 0.225 train acc: 0.891\n",
      "[53,     9] train loss: 0.246 train acc: 0.910\n",
      "[53,    10] train loss: 0.220 train acc: 0.910\n",
      "[53,    11] train loss: 0.218 train acc: 0.910\n",
      "[53,    12] train loss: 0.228 train acc: 0.906\n",
      "[53,    13] train loss: 0.262 train acc: 0.895\n",
      "[53,    14] train loss: 0.257 train acc: 0.895\n",
      "[53,    15] train loss: 0.203 train acc: 0.906\n",
      "[53,    16] train loss: 0.257 train acc: 0.902\n",
      "[53,    17] train loss: 0.180 train acc: 0.922\n",
      "[53,    18] train loss: 0.273 train acc: 0.898\n",
      "[53,    19] train loss: 0.219 train acc: 0.895\n",
      "[53,    20] train loss: 0.182 train acc: 0.935\n",
      "[53] val loss: 0.130 val acc: 1.000\n",
      "[54,     1] train loss: 0.209 train acc: 0.902\n",
      "[54,     2] train loss: 0.243 train acc: 0.906\n",
      "[54,     3] train loss: 0.173 train acc: 0.938\n",
      "[54,     4] train loss: 0.177 train acc: 0.930\n",
      "[54,     5] train loss: 0.275 train acc: 0.883\n",
      "[54,     6] train loss: 0.210 train acc: 0.914\n",
      "[54,     7] train loss: 0.243 train acc: 0.895\n",
      "[54,     8] train loss: 0.220 train acc: 0.891\n",
      "[54,     9] train loss: 0.227 train acc: 0.902\n",
      "[54,    10] train loss: 0.242 train acc: 0.914\n",
      "[54,    11] train loss: 0.236 train acc: 0.898\n",
      "[54,    12] train loss: 0.224 train acc: 0.914\n",
      "[54,    13] train loss: 0.218 train acc: 0.906\n",
      "[54,    14] train loss: 0.196 train acc: 0.926\n",
      "[54,    15] train loss: 0.198 train acc: 0.922\n",
      "[54,    16] train loss: 0.237 train acc: 0.906\n",
      "[54,    17] train loss: 0.236 train acc: 0.910\n",
      "[54,    18] train loss: 0.170 train acc: 0.930\n",
      "[54,    19] train loss: 0.235 train acc: 0.906\n",
      "[54,    20] train loss: 0.190 train acc: 0.903\n",
      "[54] val loss: 0.116 val acc: 0.999\n",
      "[55,     1] train loss: 0.195 train acc: 0.918\n",
      "[55,     2] train loss: 0.166 train acc: 0.938\n",
      "[55,     3] train loss: 0.219 train acc: 0.926\n",
      "[55,     4] train loss: 0.183 train acc: 0.914\n",
      "[55,     5] train loss: 0.213 train acc: 0.898\n",
      "[55,     6] train loss: 0.181 train acc: 0.938\n",
      "[55,     7] train loss: 0.203 train acc: 0.898\n",
      "[55,     8] train loss: 0.189 train acc: 0.930\n",
      "[55,     9] train loss: 0.213 train acc: 0.910\n",
      "[55,    10] train loss: 0.253 train acc: 0.891\n",
      "[55,    11] train loss: 0.273 train acc: 0.895\n",
      "[55,    12] train loss: 0.179 train acc: 0.914\n",
      "[55,    13] train loss: 0.277 train acc: 0.883\n",
      "[55,    14] train loss: 0.202 train acc: 0.902\n",
      "[55,    15] train loss: 0.174 train acc: 0.926\n",
      "[55,    16] train loss: 0.237 train acc: 0.902\n",
      "[55,    17] train loss: 0.217 train acc: 0.891\n",
      "[55,    18] train loss: 0.216 train acc: 0.914\n",
      "[55,    19] train loss: 0.203 train acc: 0.902\n",
      "[55,    20] train loss: 0.188 train acc: 0.910\n",
      "[55] val loss: 0.106 val acc: 0.999\n",
      "[56,     1] train loss: 0.212 train acc: 0.918\n",
      "[56,     2] train loss: 0.181 train acc: 0.922\n",
      "[56,     3] train loss: 0.244 train acc: 0.895\n",
      "[56,     4] train loss: 0.220 train acc: 0.914\n",
      "[56,     5] train loss: 0.212 train acc: 0.930\n",
      "[56,     6] train loss: 0.279 train acc: 0.875\n",
      "[56,     7] train loss: 0.193 train acc: 0.910\n",
      "[56,     8] train loss: 0.186 train acc: 0.934\n",
      "[56,     9] train loss: 0.239 train acc: 0.906\n",
      "[56,    10] train loss: 0.305 train acc: 0.891\n",
      "[56,    11] train loss: 0.219 train acc: 0.895\n",
      "[56,    12] train loss: 0.210 train acc: 0.910\n",
      "[56,    13] train loss: 0.272 train acc: 0.902\n",
      "[56,    14] train loss: 0.203 train acc: 0.910\n",
      "[56,    15] train loss: 0.155 train acc: 0.938\n",
      "[56,    16] train loss: 0.205 train acc: 0.910\n",
      "[56,    17] train loss: 0.175 train acc: 0.918\n",
      "[56,    18] train loss: 0.202 train acc: 0.910\n",
      "[56,    19] train loss: 0.254 train acc: 0.898\n",
      "[56,    20] train loss: 0.172 train acc: 0.923\n",
      "[56] val loss: 0.119 val acc: 0.999\n",
      "[57,     1] train loss: 0.180 train acc: 0.922\n",
      "[57,     2] train loss: 0.231 train acc: 0.910\n",
      "[57,     3] train loss: 0.247 train acc: 0.910\n",
      "[57,     4] train loss: 0.259 train acc: 0.891\n",
      "[57,     5] train loss: 0.255 train acc: 0.891\n",
      "[57,     6] train loss: 0.219 train acc: 0.902\n",
      "[57,     7] train loss: 0.182 train acc: 0.918\n",
      "[57,     8] train loss: 0.194 train acc: 0.949\n",
      "[57,     9] train loss: 0.245 train acc: 0.902\n",
      "[57,    10] train loss: 0.188 train acc: 0.922\n",
      "[57,    11] train loss: 0.168 train acc: 0.926\n",
      "[57,    12] train loss: 0.244 train acc: 0.906\n",
      "[57,    13] train loss: 0.270 train acc: 0.891\n",
      "[57,    14] train loss: 0.171 train acc: 0.926\n",
      "[57,    15] train loss: 0.259 train acc: 0.879\n",
      "[57,    16] train loss: 0.209 train acc: 0.930\n",
      "[57,    17] train loss: 0.208 train acc: 0.926\n",
      "[57,    18] train loss: 0.192 train acc: 0.918\n",
      "[57,    19] train loss: 0.162 train acc: 0.938\n",
      "[57,    20] train loss: 0.238 train acc: 0.897\n",
      "[57] val loss: 0.110 val acc: 1.000\n",
      "[58,     1] train loss: 0.223 train acc: 0.895\n",
      "[58,     2] train loss: 0.168 train acc: 0.926\n",
      "[58,     3] train loss: 0.268 train acc: 0.898\n",
      "[58,     4] train loss: 0.220 train acc: 0.902\n",
      "[58,     5] train loss: 0.221 train acc: 0.918\n",
      "[58,     6] train loss: 0.188 train acc: 0.922\n",
      "[58,     7] train loss: 0.178 train acc: 0.922\n",
      "[58,     8] train loss: 0.163 train acc: 0.926\n",
      "[58,     9] train loss: 0.199 train acc: 0.918\n",
      "[58,    10] train loss: 0.214 train acc: 0.918\n",
      "[58,    11] train loss: 0.220 train acc: 0.898\n",
      "[58,    12] train loss: 0.231 train acc: 0.891\n",
      "[58,    13] train loss: 0.212 train acc: 0.898\n",
      "[58,    14] train loss: 0.209 train acc: 0.910\n",
      "[58,    15] train loss: 0.233 train acc: 0.879\n",
      "[58,    16] train loss: 0.228 train acc: 0.918\n",
      "[58,    17] train loss: 0.248 train acc: 0.910\n",
      "[58,    18] train loss: 0.231 train acc: 0.906\n",
      "[58,    19] train loss: 0.169 train acc: 0.941\n",
      "[58,    20] train loss: 0.226 train acc: 0.916\n",
      "[58] val loss: 0.106 val acc: 1.000\n",
      "[59,     1] train loss: 0.265 train acc: 0.898\n",
      "[59,     2] train loss: 0.197 train acc: 0.926\n",
      "[59,     3] train loss: 0.285 train acc: 0.887\n",
      "[59,     4] train loss: 0.190 train acc: 0.906\n",
      "[59,     5] train loss: 0.246 train acc: 0.891\n",
      "[59,     6] train loss: 0.251 train acc: 0.891\n",
      "[59,     7] train loss: 0.213 train acc: 0.906\n",
      "[59,     8] train loss: 0.149 train acc: 0.930\n",
      "[59,     9] train loss: 0.214 train acc: 0.902\n",
      "[59,    10] train loss: 0.223 train acc: 0.898\n",
      "[59,    11] train loss: 0.172 train acc: 0.941\n",
      "[59,    12] train loss: 0.198 train acc: 0.918\n",
      "[59,    13] train loss: 0.152 train acc: 0.941\n",
      "[59,    14] train loss: 0.212 train acc: 0.898\n",
      "[59,    15] train loss: 0.195 train acc: 0.922\n",
      "[59,    16] train loss: 0.235 train acc: 0.895\n",
      "[59,    17] train loss: 0.205 train acc: 0.910\n",
      "[59,    18] train loss: 0.264 train acc: 0.906\n",
      "[59,    19] train loss: 0.259 train acc: 0.879\n",
      "[59,    20] train loss: 0.254 train acc: 0.897\n",
      "[59] val loss: 0.103 val acc: 1.000\n",
      "[60,     1] train loss: 0.203 train acc: 0.918\n",
      "[60,     2] train loss: 0.206 train acc: 0.930\n",
      "[60,     3] train loss: 0.217 train acc: 0.910\n",
      "[60,     4] train loss: 0.192 train acc: 0.930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60,     5] train loss: 0.177 train acc: 0.926\n",
      "[60,     6] train loss: 0.188 train acc: 0.918\n",
      "[60,     7] train loss: 0.244 train acc: 0.902\n",
      "[60,     8] train loss: 0.203 train acc: 0.910\n",
      "[60,     9] train loss: 0.231 train acc: 0.898\n",
      "[60,    10] train loss: 0.180 train acc: 0.930\n",
      "[60,    11] train loss: 0.183 train acc: 0.922\n",
      "[60,    12] train loss: 0.228 train acc: 0.906\n",
      "[60,    13] train loss: 0.192 train acc: 0.934\n",
      "[60,    14] train loss: 0.252 train acc: 0.902\n",
      "[60,    15] train loss: 0.248 train acc: 0.883\n",
      "[60,    16] train loss: 0.206 train acc: 0.895\n",
      "[60,    17] train loss: 0.211 train acc: 0.918\n",
      "[60,    18] train loss: 0.192 train acc: 0.914\n",
      "[60,    19] train loss: 0.160 train acc: 0.953\n",
      "[60,    20] train loss: 0.233 train acc: 0.923\n",
      "[60] val loss: 0.102 val acc: 0.999\n",
      "[61,     1] train loss: 0.235 train acc: 0.902\n",
      "[61,     2] train loss: 0.230 train acc: 0.922\n",
      "[61,     3] train loss: 0.244 train acc: 0.902\n",
      "[61,     4] train loss: 0.226 train acc: 0.914\n",
      "[61,     5] train loss: 0.227 train acc: 0.906\n",
      "[61,     6] train loss: 0.168 train acc: 0.938\n",
      "[61,     7] train loss: 0.205 train acc: 0.914\n",
      "[61,     8] train loss: 0.231 train acc: 0.887\n",
      "[61,     9] train loss: 0.182 train acc: 0.930\n",
      "[61,    10] train loss: 0.244 train acc: 0.902\n",
      "[61,    11] train loss: 0.220 train acc: 0.891\n",
      "[61,    12] train loss: 0.184 train acc: 0.902\n",
      "[61,    13] train loss: 0.204 train acc: 0.918\n",
      "[61,    14] train loss: 0.176 train acc: 0.934\n",
      "[61,    15] train loss: 0.195 train acc: 0.914\n",
      "[61,    16] train loss: 0.173 train acc: 0.938\n",
      "[61,    17] train loss: 0.192 train acc: 0.930\n",
      "[61,    18] train loss: 0.204 train acc: 0.902\n",
      "[61,    19] train loss: 0.303 train acc: 0.883\n",
      "[61,    20] train loss: 0.160 train acc: 0.916\n",
      "[61] val loss: 0.111 val acc: 1.000\n",
      "[62,     1] train loss: 0.208 train acc: 0.922\n",
      "[62,     2] train loss: 0.262 train acc: 0.895\n",
      "[62,     3] train loss: 0.214 train acc: 0.934\n",
      "[62,     4] train loss: 0.233 train acc: 0.910\n",
      "[62,     5] train loss: 0.233 train acc: 0.914\n",
      "[62,     6] train loss: 0.225 train acc: 0.898\n",
      "[62,     7] train loss: 0.155 train acc: 0.957\n",
      "[62,     8] train loss: 0.191 train acc: 0.914\n",
      "[62,     9] train loss: 0.146 train acc: 0.941\n",
      "[62,    10] train loss: 0.209 train acc: 0.914\n",
      "[62,    11] train loss: 0.244 train acc: 0.914\n",
      "[62,    12] train loss: 0.200 train acc: 0.910\n",
      "[62,    13] train loss: 0.169 train acc: 0.926\n",
      "[62,    14] train loss: 0.176 train acc: 0.926\n",
      "[62,    15] train loss: 0.239 train acc: 0.910\n",
      "[62,    16] train loss: 0.181 train acc: 0.914\n",
      "[62,    17] train loss: 0.272 train acc: 0.906\n",
      "[62,    18] train loss: 0.280 train acc: 0.898\n",
      "[62,    19] train loss: 0.206 train acc: 0.906\n",
      "[62,    20] train loss: 0.201 train acc: 0.929\n",
      "[62] val loss: 0.099 val acc: 1.000\n",
      "[63,     1] train loss: 0.187 train acc: 0.926\n",
      "[63,     2] train loss: 0.229 train acc: 0.906\n",
      "[63,     3] train loss: 0.265 train acc: 0.898\n",
      "[63,     4] train loss: 0.175 train acc: 0.938\n",
      "[63,     5] train loss: 0.170 train acc: 0.930\n",
      "[63,     6] train loss: 0.183 train acc: 0.941\n",
      "[63,     7] train loss: 0.198 train acc: 0.926\n",
      "[63,     8] train loss: 0.197 train acc: 0.930\n",
      "[63,     9] train loss: 0.232 train acc: 0.898\n",
      "[63,    10] train loss: 0.209 train acc: 0.902\n",
      "[63,    11] train loss: 0.230 train acc: 0.918\n",
      "[63,    12] train loss: 0.168 train acc: 0.926\n",
      "[63,    13] train loss: 0.165 train acc: 0.934\n",
      "[63,    14] train loss: 0.201 train acc: 0.914\n",
      "[63,    15] train loss: 0.162 train acc: 0.930\n",
      "[63,    16] train loss: 0.191 train acc: 0.930\n",
      "[63,    17] train loss: 0.191 train acc: 0.926\n",
      "[63,    18] train loss: 0.240 train acc: 0.906\n",
      "[63,    19] train loss: 0.203 train acc: 0.926\n",
      "[63,    20] train loss: 0.275 train acc: 0.890\n",
      "[63] val loss: 0.091 val acc: 1.000\n",
      "[64,     1] train loss: 0.231 train acc: 0.906\n",
      "[64,     2] train loss: 0.236 train acc: 0.914\n",
      "[64,     3] train loss: 0.250 train acc: 0.906\n",
      "[64,     4] train loss: 0.202 train acc: 0.922\n",
      "[64,     5] train loss: 0.188 train acc: 0.930\n",
      "[64,     6] train loss: 0.199 train acc: 0.930\n",
      "[64,     7] train loss: 0.149 train acc: 0.945\n",
      "[64,     8] train loss: 0.210 train acc: 0.922\n",
      "[64,     9] train loss: 0.227 train acc: 0.926\n",
      "[64,    10] train loss: 0.233 train acc: 0.895\n",
      "[64,    11] train loss: 0.200 train acc: 0.910\n",
      "[64,    12] train loss: 0.181 train acc: 0.949\n",
      "[64,    13] train loss: 0.163 train acc: 0.938\n",
      "[64,    14] train loss: 0.178 train acc: 0.918\n",
      "[64,    15] train loss: 0.239 train acc: 0.902\n",
      "[64,    16] train loss: 0.201 train acc: 0.930\n",
      "[64,    17] train loss: 0.153 train acc: 0.938\n",
      "[64,    18] train loss: 0.205 train acc: 0.922\n",
      "[64,    19] train loss: 0.252 train acc: 0.910\n",
      "[64,    20] train loss: 0.212 train acc: 0.877\n",
      "[64] val loss: 0.093 val acc: 1.000\n",
      "[65,     1] train loss: 0.160 train acc: 0.938\n",
      "[65,     2] train loss: 0.172 train acc: 0.918\n",
      "[65,     3] train loss: 0.169 train acc: 0.938\n",
      "[65,     4] train loss: 0.306 train acc: 0.883\n",
      "[65,     5] train loss: 0.166 train acc: 0.934\n",
      "[65,     6] train loss: 0.214 train acc: 0.902\n",
      "[65,     7] train loss: 0.224 train acc: 0.910\n",
      "[65,     8] train loss: 0.215 train acc: 0.887\n",
      "[65,     9] train loss: 0.190 train acc: 0.914\n",
      "[65,    10] train loss: 0.166 train acc: 0.934\n",
      "[65,    11] train loss: 0.191 train acc: 0.914\n",
      "[65,    12] train loss: 0.162 train acc: 0.949\n",
      "[65,    13] train loss: 0.160 train acc: 0.934\n",
      "[65,    14] train loss: 0.193 train acc: 0.914\n",
      "[65,    15] train loss: 0.220 train acc: 0.902\n",
      "[65,    16] train loss: 0.289 train acc: 0.871\n",
      "[65,    17] train loss: 0.191 train acc: 0.918\n",
      "[65,    18] train loss: 0.203 train acc: 0.934\n",
      "[65,    19] train loss: 0.229 train acc: 0.906\n",
      "[65,    20] train loss: 0.183 train acc: 0.923\n",
      "[65] val loss: 0.092 val acc: 1.000\n",
      "[66,     1] train loss: 0.268 train acc: 0.910\n",
      "[66,     2] train loss: 0.154 train acc: 0.953\n",
      "[66,     3] train loss: 0.216 train acc: 0.910\n",
      "[66,     4] train loss: 0.149 train acc: 0.945\n",
      "[66,     5] train loss: 0.167 train acc: 0.926\n",
      "[66,     6] train loss: 0.161 train acc: 0.938\n",
      "[66,     7] train loss: 0.211 train acc: 0.902\n",
      "[66,     8] train loss: 0.144 train acc: 0.938\n",
      "[66,     9] train loss: 0.135 train acc: 0.957\n",
      "[66,    10] train loss: 0.186 train acc: 0.918\n",
      "[66,    11] train loss: 0.235 train acc: 0.895\n",
      "[66,    12] train loss: 0.227 train acc: 0.918\n",
      "[66,    13] train loss: 0.216 train acc: 0.926\n",
      "[66,    14] train loss: 0.170 train acc: 0.941\n",
      "[66,    15] train loss: 0.194 train acc: 0.926\n",
      "[66,    16] train loss: 0.215 train acc: 0.902\n",
      "[66,    17] train loss: 0.275 train acc: 0.906\n",
      "[66,    18] train loss: 0.167 train acc: 0.938\n",
      "[66,    19] train loss: 0.191 train acc: 0.926\n",
      "[66,    20] train loss: 0.228 train acc: 0.897\n",
      "[66] val loss: 0.082 val acc: 1.000\n",
      "[67,     1] train loss: 0.247 train acc: 0.891\n",
      "[67,     2] train loss: 0.211 train acc: 0.910\n",
      "[67,     3] train loss: 0.178 train acc: 0.930\n",
      "[67,     4] train loss: 0.188 train acc: 0.914\n",
      "[67,     5] train loss: 0.201 train acc: 0.938\n",
      "[67,     6] train loss: 0.207 train acc: 0.914\n",
      "[67,     7] train loss: 0.434 train acc: 0.922\n",
      "[67,     8] train loss: 0.170 train acc: 0.957\n",
      "[67,     9] train loss: 0.216 train acc: 0.914\n",
      "[67,    10] train loss: 0.152 train acc: 0.953\n",
      "[67,    11] train loss: 0.209 train acc: 0.914\n",
      "[67,    12] train loss: 0.223 train acc: 0.910\n",
      "[67,    13] train loss: 0.183 train acc: 0.918\n",
      "[67,    14] train loss: 0.210 train acc: 0.926\n",
      "[67,    15] train loss: 0.236 train acc: 0.898\n",
      "[67,    16] train loss: 0.212 train acc: 0.906\n",
      "[67,    17] train loss: 0.198 train acc: 0.934\n",
      "[67,    18] train loss: 0.175 train acc: 0.930\n",
      "[67,    19] train loss: 0.208 train acc: 0.914\n",
      "[67,    20] train loss: 0.189 train acc: 0.910\n",
      "[67] val loss: 0.091 val acc: 1.000\n",
      "[68,     1] train loss: 0.188 train acc: 0.926\n",
      "[68,     2] train loss: 0.160 train acc: 0.922\n",
      "[68,     3] train loss: 0.164 train acc: 0.941\n",
      "[68,     4] train loss: 0.198 train acc: 0.938\n",
      "[68,     5] train loss: 0.192 train acc: 0.918\n",
      "[68,     6] train loss: 0.189 train acc: 0.902\n",
      "[68,     7] train loss: 0.193 train acc: 0.941\n",
      "[68,     8] train loss: 0.163 train acc: 0.914\n",
      "[68,     9] train loss: 0.173 train acc: 0.898\n",
      "[68,    10] train loss: 0.138 train acc: 0.938\n",
      "[68,    11] train loss: 0.176 train acc: 0.941\n",
      "[68,    12] train loss: 0.223 train acc: 0.922\n",
      "[68,    13] train loss: 0.173 train acc: 0.918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[68,    14] train loss: 0.216 train acc: 0.922\n",
      "[68,    15] train loss: 0.199 train acc: 0.906\n",
      "[68,    16] train loss: 0.189 train acc: 0.914\n",
      "[68,    17] train loss: 0.179 train acc: 0.938\n",
      "[68,    18] train loss: 0.173 train acc: 0.934\n",
      "[68,    19] train loss: 0.164 train acc: 0.914\n",
      "[68,    20] train loss: 0.237 train acc: 0.903\n",
      "[68] val loss: 0.081 val acc: 1.000\n",
      "[69,     1] train loss: 0.189 train acc: 0.938\n",
      "[69,     2] train loss: 0.181 train acc: 0.922\n",
      "[69,     3] train loss: 0.190 train acc: 0.914\n",
      "[69,     4] train loss: 0.153 train acc: 0.938\n",
      "[69,     5] train loss: 0.218 train acc: 0.898\n",
      "[69,     6] train loss: 0.213 train acc: 0.938\n",
      "[69,     7] train loss: 0.193 train acc: 0.926\n",
      "[69,     8] train loss: 0.173 train acc: 0.918\n",
      "[69,     9] train loss: 0.176 train acc: 0.941\n",
      "[69,    10] train loss: 0.161 train acc: 0.934\n",
      "[69,    11] train loss: 0.128 train acc: 0.949\n",
      "[69,    12] train loss: 0.149 train acc: 0.949\n",
      "[69,    13] train loss: 0.216 train acc: 0.910\n",
      "[69,    14] train loss: 0.202 train acc: 0.926\n",
      "[69,    15] train loss: 0.241 train acc: 0.875\n",
      "[69,    16] train loss: 0.204 train acc: 0.926\n",
      "[69,    17] train loss: 0.168 train acc: 0.926\n",
      "[69,    18] train loss: 0.158 train acc: 0.938\n",
      "[69,    19] train loss: 0.186 train acc: 0.934\n",
      "[69,    20] train loss: 0.243 train acc: 0.897\n",
      "[69] val loss: 0.076 val acc: 1.000\n",
      "[70,     1] train loss: 0.148 train acc: 0.930\n",
      "[70,     2] train loss: 0.171 train acc: 0.922\n",
      "[70,     3] train loss: 0.275 train acc: 0.887\n",
      "[70,     4] train loss: 0.180 train acc: 0.926\n",
      "[70,     5] train loss: 0.267 train acc: 0.895\n",
      "[70,     6] train loss: 0.213 train acc: 0.922\n",
      "[70,     7] train loss: 0.129 train acc: 0.945\n",
      "[70,     8] train loss: 0.163 train acc: 0.934\n",
      "[70,     9] train loss: 0.185 train acc: 0.922\n",
      "[70,    10] train loss: 0.150 train acc: 0.949\n",
      "[70,    11] train loss: 0.205 train acc: 0.898\n",
      "[70,    12] train loss: 0.183 train acc: 0.930\n",
      "[70,    13] train loss: 0.153 train acc: 0.949\n",
      "[70,    14] train loss: 0.205 train acc: 0.941\n",
      "[70,    15] train loss: 0.126 train acc: 0.957\n",
      "[70,    16] train loss: 0.199 train acc: 0.918\n",
      "[70,    17] train loss: 0.219 train acc: 0.906\n",
      "[70,    18] train loss: 0.183 train acc: 0.938\n",
      "[70,    19] train loss: 0.189 train acc: 0.926\n",
      "[70,    20] train loss: 0.222 train acc: 0.910\n",
      "[70] val loss: 0.087 val acc: 1.000\n",
      "[71,     1] train loss: 0.212 train acc: 0.898\n",
      "[71,     2] train loss: 0.169 train acc: 0.922\n",
      "[71,     3] train loss: 0.174 train acc: 0.945\n",
      "[71,     4] train loss: 0.178 train acc: 0.938\n",
      "[71,     5] train loss: 0.157 train acc: 0.938\n",
      "[71,     6] train loss: 0.180 train acc: 0.914\n",
      "[71,     7] train loss: 0.180 train acc: 0.914\n",
      "[71,     8] train loss: 0.283 train acc: 0.887\n",
      "[71,     9] train loss: 0.237 train acc: 0.910\n",
      "[71,    10] train loss: 0.157 train acc: 0.949\n",
      "[71,    11] train loss: 0.177 train acc: 0.922\n",
      "[71,    12] train loss: 0.173 train acc: 0.941\n",
      "[71,    13] train loss: 0.153 train acc: 0.941\n",
      "[71,    14] train loss: 0.171 train acc: 0.934\n",
      "[71,    15] train loss: 0.177 train acc: 0.930\n",
      "[71,    16] train loss: 0.140 train acc: 0.934\n",
      "[71,    17] train loss: 0.163 train acc: 0.938\n",
      "[71,    18] train loss: 0.211 train acc: 0.914\n",
      "[71,    19] train loss: 0.193 train acc: 0.922\n",
      "[71,    20] train loss: 0.242 train acc: 0.897\n",
      "[71] val loss: 0.076 val acc: 1.000\n",
      "[72,     1] train loss: 0.193 train acc: 0.918\n",
      "[72,     2] train loss: 0.150 train acc: 0.953\n",
      "[72,     3] train loss: 0.178 train acc: 0.934\n",
      "[72,     4] train loss: 0.199 train acc: 0.918\n",
      "[72,     5] train loss: 0.166 train acc: 0.930\n",
      "[72,     6] train loss: 0.184 train acc: 0.922\n",
      "[72,     7] train loss: 0.152 train acc: 0.953\n",
      "[72,     8] train loss: 0.165 train acc: 0.945\n",
      "[72,     9] train loss: 0.181 train acc: 0.930\n",
      "[72,    10] train loss: 0.182 train acc: 0.898\n",
      "[72,    11] train loss: 0.216 train acc: 0.910\n",
      "[72,    12] train loss: 0.181 train acc: 0.930\n",
      "[72,    13] train loss: 0.145 train acc: 0.941\n",
      "[72,    14] train loss: 0.217 train acc: 0.918\n",
      "[72,    15] train loss: 0.208 train acc: 0.895\n",
      "[72,    16] train loss: 0.136 train acc: 0.949\n",
      "[72,    17] train loss: 0.196 train acc: 0.918\n",
      "[72,    18] train loss: 0.225 train acc: 0.906\n",
      "[72,    19] train loss: 0.151 train acc: 0.949\n",
      "[72,    20] train loss: 0.169 train acc: 0.935\n",
      "[72] val loss: 0.075 val acc: 1.000\n",
      "[73,     1] train loss: 0.169 train acc: 0.910\n",
      "[73,     2] train loss: 0.174 train acc: 0.949\n",
      "[73,     3] train loss: 0.124 train acc: 0.949\n",
      "[73,     4] train loss: 0.164 train acc: 0.922\n",
      "[73,     5] train loss: 0.164 train acc: 0.938\n",
      "[73,     6] train loss: 0.214 train acc: 0.906\n",
      "[73,     7] train loss: 0.199 train acc: 0.910\n",
      "[73,     8] train loss: 0.150 train acc: 0.953\n",
      "[73,     9] train loss: 0.125 train acc: 0.953\n",
      "[73,    10] train loss: 0.150 train acc: 0.934\n",
      "[73,    11] train loss: 0.167 train acc: 0.926\n",
      "[73,    12] train loss: 0.209 train acc: 0.902\n",
      "[73,    13] train loss: 0.161 train acc: 0.914\n",
      "[73,    14] train loss: 0.164 train acc: 0.914\n",
      "[73,    15] train loss: 0.189 train acc: 0.930\n",
      "[73,    16] train loss: 0.183 train acc: 0.926\n",
      "[73,    17] train loss: 0.172 train acc: 0.934\n",
      "[73,    18] train loss: 0.185 train acc: 0.930\n",
      "[73,    19] train loss: 0.144 train acc: 0.945\n",
      "[73,    20] train loss: 0.271 train acc: 0.910\n",
      "[73] val loss: 0.065 val acc: 1.000\n",
      "[74,     1] train loss: 0.120 train acc: 0.965\n",
      "[74,     2] train loss: 0.149 train acc: 0.957\n",
      "[74,     3] train loss: 0.243 train acc: 0.898\n",
      "[74,     4] train loss: 0.223 train acc: 0.906\n",
      "[74,     5] train loss: 0.145 train acc: 0.934\n",
      "[74,     6] train loss: 0.143 train acc: 0.945\n",
      "[74,     7] train loss: 0.133 train acc: 0.957\n",
      "[74,     8] train loss: 0.186 train acc: 0.922\n",
      "[74,     9] train loss: 0.164 train acc: 0.938\n",
      "[74,    10] train loss: 0.196 train acc: 0.930\n",
      "[74,    11] train loss: 0.153 train acc: 0.938\n",
      "[74,    12] train loss: 0.169 train acc: 0.941\n",
      "[74,    13] train loss: 0.175 train acc: 0.930\n",
      "[74,    14] train loss: 0.199 train acc: 0.930\n",
      "[74,    15] train loss: 0.192 train acc: 0.930\n",
      "[74,    16] train loss: 0.164 train acc: 0.941\n",
      "[74,    17] train loss: 0.235 train acc: 0.918\n",
      "[74,    18] train loss: 0.199 train acc: 0.914\n",
      "[74,    19] train loss: 0.205 train acc: 0.934\n",
      "[74,    20] train loss: 0.207 train acc: 0.890\n",
      "[74] val loss: 0.077 val acc: 1.000\n",
      "[75,     1] train loss: 0.168 train acc: 0.934\n",
      "[75,     2] train loss: 0.177 train acc: 0.938\n",
      "[75,     3] train loss: 0.162 train acc: 0.934\n",
      "[75,     4] train loss: 0.208 train acc: 0.914\n",
      "[75,     5] train loss: 0.141 train acc: 0.953\n",
      "[75,     6] train loss: 0.179 train acc: 0.930\n",
      "[75,     7] train loss: 0.176 train acc: 0.926\n",
      "[75,     8] train loss: 0.199 train acc: 0.910\n",
      "[75,     9] train loss: 0.114 train acc: 0.965\n",
      "[75,    10] train loss: 0.188 train acc: 0.918\n",
      "[75,    11] train loss: 0.189 train acc: 0.930\n",
      "[75,    12] train loss: 0.205 train acc: 0.898\n",
      "[75,    13] train loss: 0.249 train acc: 0.910\n",
      "[75,    14] train loss: 0.235 train acc: 0.906\n",
      "[75,    15] train loss: 0.246 train acc: 0.863\n",
      "[75,    16] train loss: 0.224 train acc: 0.910\n",
      "[75,    17] train loss: 0.184 train acc: 0.914\n",
      "[75,    18] train loss: 0.212 train acc: 0.918\n",
      "[75,    19] train loss: 0.163 train acc: 0.938\n",
      "[75,    20] train loss: 0.224 train acc: 0.916\n",
      "[75] val loss: 0.089 val acc: 1.000\n",
      "[76,     1] train loss: 0.205 train acc: 0.926\n",
      "[76,     2] train loss: 0.140 train acc: 0.945\n",
      "[76,     3] train loss: 0.176 train acc: 0.930\n",
      "[76,     4] train loss: 0.180 train acc: 0.926\n",
      "[76,     5] train loss: 0.206 train acc: 0.914\n",
      "[76,     6] train loss: 0.172 train acc: 0.941\n",
      "[76,     7] train loss: 0.212 train acc: 0.914\n",
      "[76,     8] train loss: 0.170 train acc: 0.941\n",
      "[76,     9] train loss: 0.157 train acc: 0.938\n",
      "[76,    10] train loss: 0.182 train acc: 0.922\n",
      "[76,    11] train loss: 0.148 train acc: 0.938\n",
      "[76,    12] train loss: 0.214 train acc: 0.914\n",
      "[76,    13] train loss: 0.149 train acc: 0.949\n",
      "[76,    14] train loss: 0.164 train acc: 0.930\n",
      "[76,    15] train loss: 0.179 train acc: 0.934\n",
      "[76,    16] train loss: 0.182 train acc: 0.941\n",
      "[76,    17] train loss: 0.169 train acc: 0.914\n",
      "[76,    18] train loss: 0.174 train acc: 0.930\n",
      "[76,    19] train loss: 0.168 train acc: 0.941\n",
      "[76,    20] train loss: 0.265 train acc: 0.903\n",
      "[76] val loss: 0.074 val acc: 1.000\n",
      "[77,     1] train loss: 0.186 train acc: 0.930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[77,     2] train loss: 0.217 train acc: 0.918\n",
      "[77,     3] train loss: 0.185 train acc: 0.945\n",
      "[77,     4] train loss: 0.153 train acc: 0.938\n",
      "[77,     5] train loss: 0.134 train acc: 0.941\n",
      "[77,     6] train loss: 0.171 train acc: 0.941\n",
      "[77,     7] train loss: 0.251 train acc: 0.887\n",
      "[77,     8] train loss: 0.185 train acc: 0.914\n",
      "[77,     9] train loss: 0.173 train acc: 0.922\n",
      "[77,    10] train loss: 0.159 train acc: 0.938\n",
      "[77,    11] train loss: 0.225 train acc: 0.918\n",
      "[77,    12] train loss: 0.153 train acc: 0.945\n",
      "[77,    13] train loss: 0.170 train acc: 0.941\n",
      "[77,    14] train loss: 0.156 train acc: 0.934\n",
      "[77,    15] train loss: 0.153 train acc: 0.949\n",
      "[77,    16] train loss: 0.128 train acc: 0.941\n",
      "[77,    17] train loss: 0.123 train acc: 0.953\n",
      "[77,    18] train loss: 0.138 train acc: 0.945\n",
      "[77,    19] train loss: 0.148 train acc: 0.934\n",
      "[77,    20] train loss: 0.228 train acc: 0.929\n",
      "[77] val loss: 0.069 val acc: 1.000\n",
      "[78,     1] train loss: 0.161 train acc: 0.930\n",
      "[78,     2] train loss: 0.152 train acc: 0.934\n",
      "[78,     3] train loss: 0.133 train acc: 0.938\n",
      "[78,     4] train loss: 0.114 train acc: 0.965\n",
      "[78,     5] train loss: 0.155 train acc: 0.926\n",
      "[78,     6] train loss: 0.166 train acc: 0.945\n",
      "[78,     7] train loss: 0.156 train acc: 0.945\n",
      "[78,     8] train loss: 0.231 train acc: 0.926\n",
      "[78,     9] train loss: 0.176 train acc: 0.934\n",
      "[78,    10] train loss: 0.159 train acc: 0.922\n",
      "[78,    11] train loss: 0.185 train acc: 0.938\n",
      "[78,    12] train loss: 0.154 train acc: 0.949\n",
      "[78,    13] train loss: 0.200 train acc: 0.918\n",
      "[78,    14] train loss: 0.152 train acc: 0.938\n",
      "[78,    15] train loss: 0.150 train acc: 0.930\n",
      "[78,    16] train loss: 0.138 train acc: 0.941\n",
      "[78,    17] train loss: 0.190 train acc: 0.918\n",
      "[78,    18] train loss: 0.176 train acc: 0.926\n",
      "[78,    19] train loss: 0.195 train acc: 0.910\n",
      "[78,    20] train loss: 0.179 train acc: 0.929\n",
      "[78] val loss: 0.066 val acc: 1.000\n",
      "[79,     1] train loss: 0.178 train acc: 0.922\n",
      "[79,     2] train loss: 0.149 train acc: 0.941\n",
      "[79,     3] train loss: 0.202 train acc: 0.926\n",
      "[79,     4] train loss: 0.216 train acc: 0.898\n",
      "[79,     5] train loss: 0.164 train acc: 0.945\n",
      "[79,     6] train loss: 0.247 train acc: 0.887\n",
      "[79,     7] train loss: 0.148 train acc: 0.953\n",
      "[79,     8] train loss: 0.190 train acc: 0.898\n",
      "[79,     9] train loss: 0.130 train acc: 0.949\n",
      "[79,    10] train loss: 0.175 train acc: 0.934\n",
      "[79,    11] train loss: 0.165 train acc: 0.934\n",
      "[79,    12] train loss: 0.145 train acc: 0.957\n",
      "[79,    13] train loss: 0.199 train acc: 0.910\n",
      "[79,    14] train loss: 0.124 train acc: 0.941\n",
      "[79,    15] train loss: 0.130 train acc: 0.949\n",
      "[79,    16] train loss: 0.182 train acc: 0.914\n",
      "[79,    17] train loss: 0.158 train acc: 0.938\n",
      "[79,    18] train loss: 0.150 train acc: 0.938\n",
      "[79,    19] train loss: 0.174 train acc: 0.938\n",
      "[79,    20] train loss: 0.154 train acc: 0.955\n",
      "[79] val loss: 0.069 val acc: 1.000\n",
      "[80,     1] train loss: 0.172 train acc: 0.938\n",
      "[80,     2] train loss: 0.213 train acc: 0.930\n",
      "[80,     3] train loss: 0.207 train acc: 0.918\n",
      "[80,     4] train loss: 0.172 train acc: 0.922\n",
      "[80,     5] train loss: 0.199 train acc: 0.922\n",
      "[80,     6] train loss: 0.162 train acc: 0.945\n",
      "[80,     7] train loss: 0.210 train acc: 0.906\n",
      "[80,     8] train loss: 0.123 train acc: 0.957\n",
      "[80,     9] train loss: 0.146 train acc: 0.945\n",
      "[80,    10] train loss: 0.218 train acc: 0.926\n",
      "[80,    11] train loss: 0.184 train acc: 0.934\n",
      "[80,    12] train loss: 0.134 train acc: 0.938\n",
      "[80,    13] train loss: 0.144 train acc: 0.949\n",
      "[80,    14] train loss: 0.167 train acc: 0.941\n",
      "[80,    15] train loss: 0.108 train acc: 0.949\n",
      "[80,    16] train loss: 0.233 train acc: 0.926\n",
      "[80,    17] train loss: 0.157 train acc: 0.934\n",
      "[80,    18] train loss: 0.180 train acc: 0.918\n",
      "[80,    19] train loss: 0.188 train acc: 0.902\n",
      "[80,    20] train loss: 0.137 train acc: 0.955\n",
      "[80] val loss: 0.068 val acc: 1.000\n",
      "[81,     1] train loss: 0.200 train acc: 0.922\n",
      "[81,     2] train loss: 0.140 train acc: 0.938\n",
      "[81,     3] train loss: 0.167 train acc: 0.941\n",
      "[81,     4] train loss: 0.225 train acc: 0.906\n",
      "[81,     5] train loss: 0.142 train acc: 0.945\n",
      "[81,     6] train loss: 0.160 train acc: 0.934\n",
      "[81,     7] train loss: 0.131 train acc: 0.941\n",
      "[81,     8] train loss: 0.165 train acc: 0.938\n",
      "[81,     9] train loss: 0.205 train acc: 0.902\n",
      "[81,    10] train loss: 0.135 train acc: 0.953\n",
      "[81,    11] train loss: 0.201 train acc: 0.930\n",
      "[81,    12] train loss: 0.178 train acc: 0.910\n",
      "[81,    13] train loss: 0.204 train acc: 0.902\n",
      "[81,    14] train loss: 0.149 train acc: 0.930\n",
      "[81,    15] train loss: 0.162 train acc: 0.934\n",
      "[81,    16] train loss: 0.188 train acc: 0.926\n",
      "[81,    17] train loss: 0.116 train acc: 0.949\n",
      "[81,    18] train loss: 0.185 train acc: 0.902\n",
      "[81,    19] train loss: 0.182 train acc: 0.926\n",
      "[81,    20] train loss: 0.117 train acc: 0.955\n",
      "[81] val loss: 0.066 val acc: 1.000\n",
      "[82,     1] train loss: 0.176 train acc: 0.934\n",
      "[82,     2] train loss: 0.151 train acc: 0.938\n",
      "[82,     3] train loss: 0.152 train acc: 0.949\n",
      "[82,     4] train loss: 0.153 train acc: 0.969\n",
      "[82,     5] train loss: 0.117 train acc: 0.949\n",
      "[82,     6] train loss: 0.181 train acc: 0.926\n",
      "[82,     7] train loss: 0.124 train acc: 0.953\n",
      "[82,     8] train loss: 0.164 train acc: 0.941\n",
      "[82,     9] train loss: 0.199 train acc: 0.930\n",
      "[82,    10] train loss: 0.157 train acc: 0.945\n",
      "[82,    11] train loss: 0.205 train acc: 0.930\n",
      "[82,    12] train loss: 0.152 train acc: 0.941\n",
      "[82,    13] train loss: 0.159 train acc: 0.934\n",
      "[82,    14] train loss: 0.112 train acc: 0.961\n",
      "[82,    15] train loss: 0.185 train acc: 0.918\n",
      "[82,    16] train loss: 0.134 train acc: 0.957\n",
      "[82,    17] train loss: 0.162 train acc: 0.938\n",
      "[82,    18] train loss: 0.194 train acc: 0.930\n",
      "[82,    19] train loss: 0.138 train acc: 0.953\n",
      "[82,    20] train loss: 0.226 train acc: 0.935\n",
      "[82] val loss: 0.064 val acc: 1.000\n",
      "[83,     1] train loss: 0.148 train acc: 0.941\n",
      "[83,     2] train loss: 0.140 train acc: 0.949\n",
      "[83,     3] train loss: 0.193 train acc: 0.914\n",
      "[83,     4] train loss: 0.177 train acc: 0.922\n",
      "[83,     5] train loss: 0.163 train acc: 0.930\n",
      "[83,     6] train loss: 0.164 train acc: 0.945\n",
      "[83,     7] train loss: 0.182 train acc: 0.938\n",
      "[83,     8] train loss: 0.195 train acc: 0.914\n",
      "[83,     9] train loss: 0.167 train acc: 0.926\n",
      "[83,    10] train loss: 0.151 train acc: 0.945\n",
      "[83,    11] train loss: 0.232 train acc: 0.891\n",
      "[83,    12] train loss: 0.141 train acc: 0.953\n",
      "[83,    13] train loss: 0.228 train acc: 0.934\n",
      "[83,    14] train loss: 0.129 train acc: 0.961\n",
      "[83,    15] train loss: 0.198 train acc: 0.906\n",
      "[83,    16] train loss: 0.179 train acc: 0.910\n",
      "[83,    17] train loss: 0.097 train acc: 0.949\n",
      "[83,    18] train loss: 0.203 train acc: 0.934\n",
      "[83,    19] train loss: 0.138 train acc: 0.941\n",
      "[83,    20] train loss: 0.193 train acc: 0.910\n",
      "[83] val loss: 0.070 val acc: 1.000\n",
      "[84,     1] train loss: 0.180 train acc: 0.918\n",
      "[84,     2] train loss: 0.146 train acc: 0.949\n",
      "[84,     3] train loss: 0.151 train acc: 0.953\n",
      "[84,     4] train loss: 0.148 train acc: 0.941\n",
      "[84,     5] train loss: 0.157 train acc: 0.926\n",
      "[84,     6] train loss: 0.220 train acc: 0.891\n",
      "[84,     7] train loss: 0.103 train acc: 0.969\n",
      "[84,     8] train loss: 0.193 train acc: 0.945\n",
      "[84,     9] train loss: 0.279 train acc: 0.891\n",
      "[84,    10] train loss: 0.205 train acc: 0.898\n",
      "[84,    11] train loss: 0.217 train acc: 0.926\n",
      "[84,    12] train loss: 0.133 train acc: 0.953\n",
      "[84,    13] train loss: 0.205 train acc: 0.910\n",
      "[84,    14] train loss: 0.172 train acc: 0.938\n",
      "[84,    15] train loss: 0.158 train acc: 0.945\n",
      "[84,    16] train loss: 0.130 train acc: 0.945\n",
      "[84,    17] train loss: 0.178 train acc: 0.918\n",
      "[84,    18] train loss: 0.157 train acc: 0.945\n",
      "[84,    19] train loss: 0.144 train acc: 0.953\n",
      "[84,    20] train loss: 0.133 train acc: 0.955\n",
      "[84] val loss: 0.064 val acc: 1.000\n",
      "[85,     1] train loss: 0.155 train acc: 0.938\n",
      "[85,     2] train loss: 0.110 train acc: 0.957\n",
      "[85,     3] train loss: 0.174 train acc: 0.934\n",
      "[85,     4] train loss: 0.204 train acc: 0.934\n",
      "[85,     5] train loss: 0.187 train acc: 0.934\n",
      "[85,     6] train loss: 0.137 train acc: 0.949\n",
      "[85,     7] train loss: 0.166 train acc: 0.938\n",
      "[85,     8] train loss: 0.142 train acc: 0.949\n",
      "[85,     9] train loss: 0.163 train acc: 0.922\n",
      "[85,    10] train loss: 0.132 train acc: 0.953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[85,    11] train loss: 0.174 train acc: 0.930\n",
      "[85,    12] train loss: 0.158 train acc: 0.938\n",
      "[85,    13] train loss: 0.161 train acc: 0.930\n",
      "[85,    14] train loss: 0.163 train acc: 0.941\n",
      "[85,    15] train loss: 0.197 train acc: 0.914\n",
      "[85,    16] train loss: 0.210 train acc: 0.906\n",
      "[85,    17] train loss: 0.164 train acc: 0.949\n",
      "[85,    18] train loss: 0.102 train acc: 0.949\n",
      "[85,    19] train loss: 0.166 train acc: 0.926\n",
      "[85,    20] train loss: 0.134 train acc: 0.948\n",
      "[85] val loss: 0.062 val acc: 1.000\n",
      "[86,     1] train loss: 0.096 train acc: 0.977\n",
      "[86,     2] train loss: 0.113 train acc: 0.965\n",
      "[86,     3] train loss: 0.108 train acc: 0.961\n",
      "[86,     4] train loss: 0.177 train acc: 0.926\n",
      "[86,     5] train loss: 0.156 train acc: 0.930\n",
      "[86,     6] train loss: 0.141 train acc: 0.922\n",
      "[86,     7] train loss: 0.172 train acc: 0.957\n",
      "[86,     8] train loss: 0.142 train acc: 0.941\n",
      "[86,     9] train loss: 0.169 train acc: 0.930\n",
      "[86,    10] train loss: 0.175 train acc: 0.938\n",
      "[86,    11] train loss: 0.178 train acc: 0.922\n",
      "[86,    12] train loss: 0.153 train acc: 0.938\n",
      "[86,    13] train loss: 0.112 train acc: 0.949\n",
      "[86,    14] train loss: 0.130 train acc: 0.961\n",
      "[86,    15] train loss: 0.185 train acc: 0.910\n",
      "[86,    16] train loss: 0.197 train acc: 0.934\n",
      "[86,    17] train loss: 0.131 train acc: 0.957\n",
      "[86,    18] train loss: 0.154 train acc: 0.922\n",
      "[86,    19] train loss: 0.173 train acc: 0.918\n",
      "[86,    20] train loss: 0.135 train acc: 0.955\n",
      "[86] val loss: 0.049 val acc: 1.000\n",
      "[87,     1] train loss: 0.142 train acc: 0.953\n",
      "[87,     2] train loss: 0.171 train acc: 0.938\n",
      "[87,     3] train loss: 0.122 train acc: 0.957\n",
      "[87,     4] train loss: 0.125 train acc: 0.949\n",
      "[87,     5] train loss: 0.237 train acc: 0.926\n",
      "[87,     6] train loss: 0.147 train acc: 0.945\n",
      "[87,     7] train loss: 0.183 train acc: 0.922\n",
      "[87,     8] train loss: 0.177 train acc: 0.922\n",
      "[87,     9] train loss: 0.180 train acc: 0.922\n",
      "[87,    10] train loss: 0.144 train acc: 0.934\n",
      "[87,    11] train loss: 0.137 train acc: 0.938\n",
      "[87,    12] train loss: 0.212 train acc: 0.938\n",
      "[87,    13] train loss: 0.197 train acc: 0.910\n",
      "[87,    14] train loss: 0.136 train acc: 0.941\n",
      "[87,    15] train loss: 0.127 train acc: 0.945\n",
      "[87,    16] train loss: 0.193 train acc: 0.930\n",
      "[87,    17] train loss: 0.136 train acc: 0.949\n",
      "[87,    18] train loss: 0.195 train acc: 0.934\n",
      "[87,    19] train loss: 0.158 train acc: 0.926\n",
      "[87,    20] train loss: 0.146 train acc: 0.935\n",
      "[87] val loss: 0.063 val acc: 1.000\n",
      "[88,     1] train loss: 0.128 train acc: 0.953\n",
      "[88,     2] train loss: 0.164 train acc: 0.941\n",
      "[88,     3] train loss: 0.153 train acc: 0.934\n",
      "[88,     4] train loss: 0.142 train acc: 0.934\n",
      "[88,     5] train loss: 0.170 train acc: 0.930\n",
      "[88,     6] train loss: 0.133 train acc: 0.945\n",
      "[88,     7] train loss: 0.184 train acc: 0.922\n",
      "[88,     8] train loss: 0.148 train acc: 0.945\n",
      "[88,     9] train loss: 0.161 train acc: 0.953\n",
      "[88,    10] train loss: 0.144 train acc: 0.941\n",
      "[88,    11] train loss: 0.178 train acc: 0.922\n",
      "[88,    12] train loss: 0.127 train acc: 0.934\n",
      "[88,    13] train loss: 0.164 train acc: 0.938\n",
      "[88,    14] train loss: 0.194 train acc: 0.930\n",
      "[88,    15] train loss: 0.136 train acc: 0.945\n",
      "[88,    16] train loss: 0.213 train acc: 0.930\n",
      "[88,    17] train loss: 0.180 train acc: 0.926\n",
      "[88,    18] train loss: 0.162 train acc: 0.938\n",
      "[88,    19] train loss: 0.135 train acc: 0.945\n",
      "[88,    20] train loss: 0.134 train acc: 0.942\n",
      "[88] val loss: 0.055 val acc: 1.000\n",
      "[89,     1] train loss: 0.173 train acc: 0.922\n",
      "[89,     2] train loss: 0.145 train acc: 0.949\n",
      "[89,     3] train loss: 0.154 train acc: 0.949\n",
      "[89,     4] train loss: 0.155 train acc: 0.930\n",
      "[89,     5] train loss: 0.086 train acc: 0.965\n",
      "[89,     6] train loss: 0.147 train acc: 0.941\n",
      "[89,     7] train loss: 0.171 train acc: 0.934\n",
      "[89,     8] train loss: 0.178 train acc: 0.941\n",
      "[89,     9] train loss: 0.137 train acc: 0.941\n",
      "[89,    10] train loss: 0.133 train acc: 0.945\n",
      "[89,    11] train loss: 0.172 train acc: 0.934\n",
      "[89,    12] train loss: 0.179 train acc: 0.926\n",
      "[89,    13] train loss: 0.161 train acc: 0.938\n",
      "[89,    14] train loss: 0.175 train acc: 0.934\n",
      "[89,    15] train loss: 0.171 train acc: 0.926\n",
      "[89,    16] train loss: 0.156 train acc: 0.934\n",
      "[89,    17] train loss: 0.166 train acc: 0.930\n",
      "[89,    18] train loss: 0.134 train acc: 0.949\n",
      "[89,    19] train loss: 0.165 train acc: 0.945\n",
      "[89,    20] train loss: 0.176 train acc: 0.942\n",
      "[89] val loss: 0.060 val acc: 1.000\n",
      "[90,     1] train loss: 0.165 train acc: 0.938\n",
      "[90,     2] train loss: 0.207 train acc: 0.922\n",
      "[90,     3] train loss: 0.146 train acc: 0.934\n",
      "[90,     4] train loss: 0.201 train acc: 0.918\n",
      "[90,     5] train loss: 0.168 train acc: 0.930\n",
      "[90,     6] train loss: 0.145 train acc: 0.938\n",
      "[90,     7] train loss: 0.143 train acc: 0.934\n",
      "[90,     8] train loss: 0.214 train acc: 0.941\n",
      "[90,     9] train loss: 0.124 train acc: 0.945\n",
      "[90,    10] train loss: 0.187 train acc: 0.930\n",
      "[90,    11] train loss: 0.176 train acc: 0.938\n",
      "[90,    12] train loss: 0.146 train acc: 0.945\n",
      "[90,    13] train loss: 0.189 train acc: 0.922\n",
      "[90,    14] train loss: 0.152 train acc: 0.918\n",
      "[90,    15] train loss: 0.142 train acc: 0.941\n",
      "[90,    16] train loss: 0.087 train acc: 0.973\n",
      "[90,    17] train loss: 0.188 train acc: 0.918\n",
      "[90,    18] train loss: 0.130 train acc: 0.953\n",
      "[90,    19] train loss: 0.198 train acc: 0.938\n",
      "[90,    20] train loss: 0.137 train acc: 0.935\n",
      "[90] val loss: 0.061 val acc: 1.000\n",
      "[91,     1] train loss: 0.175 train acc: 0.945\n",
      "[91,     2] train loss: 0.164 train acc: 0.934\n",
      "[91,     3] train loss: 0.117 train acc: 0.961\n",
      "[91,     4] train loss: 0.223 train acc: 0.906\n",
      "[91,     5] train loss: 0.147 train acc: 0.945\n",
      "[91,     6] train loss: 0.159 train acc: 0.930\n",
      "[91,     7] train loss: 0.115 train acc: 0.961\n",
      "[91,     8] train loss: 0.173 train acc: 0.945\n",
      "[91,     9] train loss: 0.124 train acc: 0.949\n",
      "[91,    10] train loss: 0.129 train acc: 0.953\n",
      "[91,    11] train loss: 0.144 train acc: 0.945\n",
      "[91,    12] train loss: 0.147 train acc: 0.938\n",
      "[91,    13] train loss: 0.204 train acc: 0.926\n",
      "[91,    14] train loss: 0.217 train acc: 0.887\n",
      "[91,    15] train loss: 0.104 train acc: 0.965\n",
      "[91,    16] train loss: 0.145 train acc: 0.926\n",
      "[91,    17] train loss: 0.157 train acc: 0.926\n",
      "[91,    18] train loss: 0.171 train acc: 0.926\n",
      "[91,    19] train loss: 0.163 train acc: 0.926\n",
      "[91,    20] train loss: 0.126 train acc: 0.935\n",
      "[91] val loss: 0.056 val acc: 1.000\n",
      "[92,     1] train loss: 0.148 train acc: 0.934\n",
      "[92,     2] train loss: 0.127 train acc: 0.957\n",
      "[92,     3] train loss: 0.156 train acc: 0.934\n",
      "[92,     4] train loss: 0.153 train acc: 0.945\n",
      "[92,     5] train loss: 0.119 train acc: 0.965\n",
      "[92,     6] train loss: 0.175 train acc: 0.938\n",
      "[92,     7] train loss: 0.134 train acc: 0.930\n",
      "[92,     8] train loss: 0.120 train acc: 0.949\n",
      "[92,     9] train loss: 0.204 train acc: 0.902\n",
      "[92,    10] train loss: 0.130 train acc: 0.957\n",
      "[92,    11] train loss: 0.159 train acc: 0.938\n",
      "[92,    12] train loss: 0.185 train acc: 0.918\n",
      "[92,    13] train loss: 0.157 train acc: 0.953\n",
      "[92,    14] train loss: 0.212 train acc: 0.914\n",
      "[92,    15] train loss: 0.126 train acc: 0.949\n",
      "[92,    16] train loss: 0.166 train acc: 0.926\n",
      "[92,    17] train loss: 0.157 train acc: 0.941\n",
      "[92,    18] train loss: 0.139 train acc: 0.938\n",
      "[92,    19] train loss: 0.138 train acc: 0.938\n",
      "[92,    20] train loss: 0.165 train acc: 0.923\n",
      "[92] val loss: 0.050 val acc: 1.000\n",
      "[93,     1] train loss: 0.193 train acc: 0.938\n",
      "[93,     2] train loss: 0.196 train acc: 0.902\n",
      "[93,     3] train loss: 0.201 train acc: 0.902\n",
      "[93,     4] train loss: 0.149 train acc: 0.941\n",
      "[93,     5] train loss: 0.153 train acc: 0.934\n",
      "[93,     6] train loss: 0.100 train acc: 0.977\n",
      "[93,     7] train loss: 0.128 train acc: 0.957\n",
      "[93,     8] train loss: 0.174 train acc: 0.938\n",
      "[93,     9] train loss: 0.143 train acc: 0.938\n",
      "[93,    10] train loss: 0.118 train acc: 0.934\n",
      "[93,    11] train loss: 0.166 train acc: 0.941\n",
      "[93,    12] train loss: 0.209 train acc: 0.922\n",
      "[93,    13] train loss: 0.153 train acc: 0.941\n",
      "[93,    14] train loss: 0.125 train acc: 0.957\n",
      "[93,    15] train loss: 0.166 train acc: 0.938\n",
      "[93,    16] train loss: 0.132 train acc: 0.941\n",
      "[93,    17] train loss: 0.159 train acc: 0.930\n",
      "[93,    18] train loss: 0.115 train acc: 0.961\n",
      "[93,    19] train loss: 0.120 train acc: 0.957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[93,    20] train loss: 0.162 train acc: 0.923\n",
      "[93] val loss: 0.046 val acc: 1.000\n",
      "[94,     1] train loss: 0.115 train acc: 0.953\n",
      "[94,     2] train loss: 0.165 train acc: 0.945\n",
      "[94,     3] train loss: 0.161 train acc: 0.930\n",
      "[94,     4] train loss: 0.113 train acc: 0.957\n",
      "[94,     5] train loss: 0.153 train acc: 0.938\n",
      "[94,     6] train loss: 0.149 train acc: 0.941\n",
      "[94,     7] train loss: 0.153 train acc: 0.930\n",
      "[94,     8] train loss: 0.078 train acc: 0.969\n",
      "[94,     9] train loss: 0.126 train acc: 0.953\n",
      "[94,    10] train loss: 0.142 train acc: 0.945\n",
      "[94,    11] train loss: 0.106 train acc: 0.969\n",
      "[94,    12] train loss: 0.153 train acc: 0.961\n",
      "[94,    13] train loss: 0.190 train acc: 0.906\n",
      "[94,    14] train loss: 0.126 train acc: 0.957\n",
      "[94,    15] train loss: 0.221 train acc: 0.914\n",
      "[94,    16] train loss: 0.250 train acc: 0.898\n",
      "[94,    17] train loss: 0.112 train acc: 0.961\n",
      "[94,    18] train loss: 0.111 train acc: 0.949\n",
      "[94,    19] train loss: 0.153 train acc: 0.941\n",
      "[94,    20] train loss: 0.152 train acc: 0.942\n",
      "[94] val loss: 0.050 val acc: 1.000\n",
      "[95,     1] train loss: 0.169 train acc: 0.918\n",
      "[95,     2] train loss: 0.180 train acc: 0.922\n",
      "[95,     3] train loss: 0.140 train acc: 0.945\n",
      "[95,     4] train loss: 0.110 train acc: 0.957\n",
      "[95,     5] train loss: 0.196 train acc: 0.926\n",
      "[95,     6] train loss: 0.122 train acc: 0.945\n",
      "[95,     7] train loss: 0.138 train acc: 0.961\n",
      "[95,     8] train loss: 0.142 train acc: 0.957\n",
      "[95,     9] train loss: 0.159 train acc: 0.938\n",
      "[95,    10] train loss: 0.137 train acc: 0.938\n",
      "[95,    11] train loss: 0.173 train acc: 0.949\n",
      "[95,    12] train loss: 0.192 train acc: 0.922\n",
      "[95,    13] train loss: 0.122 train acc: 0.945\n",
      "[95,    14] train loss: 0.189 train acc: 0.930\n",
      "[95,    15] train loss: 0.176 train acc: 0.945\n",
      "[95,    16] train loss: 0.170 train acc: 0.922\n",
      "[95,    17] train loss: 0.156 train acc: 0.938\n",
      "[95,    18] train loss: 0.174 train acc: 0.938\n",
      "[95,    19] train loss: 0.144 train acc: 0.938\n",
      "[95,    20] train loss: 0.132 train acc: 0.948\n",
      "[95] val loss: 0.066 val acc: 1.000\n",
      "[96,     1] train loss: 0.162 train acc: 0.953\n",
      "[96,     2] train loss: 0.167 train acc: 0.934\n",
      "[96,     3] train loss: 0.145 train acc: 0.934\n",
      "[96,     4] train loss: 0.157 train acc: 0.930\n",
      "[96,     5] train loss: 0.161 train acc: 0.941\n",
      "[96,     6] train loss: 0.141 train acc: 0.957\n",
      "[96,     7] train loss: 0.108 train acc: 0.961\n",
      "[96,     8] train loss: 0.129 train acc: 0.945\n",
      "[96,     9] train loss: 0.184 train acc: 0.926\n",
      "[96,    10] train loss: 0.130 train acc: 0.957\n",
      "[96,    11] train loss: 0.193 train acc: 0.922\n",
      "[96,    12] train loss: 0.131 train acc: 0.945\n",
      "[96,    13] train loss: 0.159 train acc: 0.938\n",
      "[96,    14] train loss: 0.190 train acc: 0.938\n",
      "[96,    15] train loss: 0.179 train acc: 0.938\n",
      "[96,    16] train loss: 0.131 train acc: 0.945\n",
      "[96,    17] train loss: 0.144 train acc: 0.949\n",
      "[96,    18] train loss: 0.110 train acc: 0.949\n",
      "[96,    19] train loss: 0.143 train acc: 0.930\n",
      "[96,    20] train loss: 0.169 train acc: 0.929\n",
      "[96] val loss: 0.052 val acc: 1.000\n",
      "[97,     1] train loss: 0.129 train acc: 0.945\n",
      "[97,     2] train loss: 0.174 train acc: 0.941\n",
      "[97,     3] train loss: 0.107 train acc: 0.957\n",
      "[97,     4] train loss: 0.137 train acc: 0.926\n",
      "[97,     5] train loss: 0.149 train acc: 0.938\n",
      "[97,     6] train loss: 0.126 train acc: 0.953\n",
      "[97,     7] train loss: 0.130 train acc: 0.961\n",
      "[97,     8] train loss: 0.127 train acc: 0.949\n",
      "[97,     9] train loss: 0.113 train acc: 0.953\n",
      "[97,    10] train loss: 0.131 train acc: 0.941\n",
      "[97,    11] train loss: 0.097 train acc: 0.961\n",
      "[97,    12] train loss: 0.155 train acc: 0.934\n",
      "[97,    13] train loss: 0.126 train acc: 0.945\n",
      "[97,    14] train loss: 0.218 train acc: 0.914\n",
      "[97,    15] train loss: 0.116 train acc: 0.953\n",
      "[97,    16] train loss: 0.103 train acc: 0.949\n",
      "[97,    17] train loss: 0.133 train acc: 0.934\n",
      "[97,    18] train loss: 0.200 train acc: 0.914\n",
      "[97,    19] train loss: 0.148 train acc: 0.949\n",
      "[97,    20] train loss: 0.141 train acc: 0.955\n",
      "[97] val loss: 0.043 val acc: 1.000\n",
      "[98,     1] train loss: 0.170 train acc: 0.922\n",
      "[98,     2] train loss: 0.121 train acc: 0.957\n",
      "[98,     3] train loss: 0.160 train acc: 0.930\n",
      "[98,     4] train loss: 0.142 train acc: 0.945\n",
      "[98,     5] train loss: 0.091 train acc: 0.977\n",
      "[98,     6] train loss: 0.127 train acc: 0.941\n",
      "[98,     7] train loss: 0.188 train acc: 0.934\n",
      "[98,     8] train loss: 0.176 train acc: 0.934\n",
      "[98,     9] train loss: 0.166 train acc: 0.938\n",
      "[98,    10] train loss: 0.160 train acc: 0.941\n",
      "[98,    11] train loss: 0.122 train acc: 0.961\n",
      "[98,    12] train loss: 0.156 train acc: 0.941\n",
      "[98,    13] train loss: 0.132 train acc: 0.953\n",
      "[98,    14] train loss: 0.161 train acc: 0.934\n",
      "[98,    15] train loss: 0.131 train acc: 0.949\n",
      "[98,    16] train loss: 0.155 train acc: 0.934\n",
      "[98,    17] train loss: 0.172 train acc: 0.941\n",
      "[98,    18] train loss: 0.193 train acc: 0.934\n",
      "[98,    19] train loss: 0.175 train acc: 0.938\n",
      "[98,    20] train loss: 0.091 train acc: 0.974\n",
      "[98] val loss: 0.046 val acc: 1.000\n",
      "[99,     1] train loss: 0.166 train acc: 0.914\n",
      "[99,     2] train loss: 0.246 train acc: 0.910\n",
      "[99,     3] train loss: 0.149 train acc: 0.949\n",
      "[99,     4] train loss: 0.118 train acc: 0.953\n",
      "[99,     5] train loss: 0.129 train acc: 0.949\n",
      "[99,     6] train loss: 0.153 train acc: 0.938\n",
      "[99,     7] train loss: 0.148 train acc: 0.941\n",
      "[99,     8] train loss: 0.128 train acc: 0.953\n",
      "[99,     9] train loss: 0.148 train acc: 0.949\n",
      "[99,    10] train loss: 0.189 train acc: 0.938\n",
      "[99,    11] train loss: 0.183 train acc: 0.926\n",
      "[99,    12] train loss: 0.127 train acc: 0.957\n",
      "[99,    13] train loss: 0.099 train acc: 0.945\n",
      "[99,    14] train loss: 0.167 train acc: 0.938\n",
      "[99,    15] train loss: 0.156 train acc: 0.938\n",
      "[99,    16] train loss: 0.111 train acc: 0.953\n",
      "[99,    17] train loss: 0.120 train acc: 0.953\n",
      "[99,    18] train loss: 0.113 train acc: 0.961\n",
      "[99,    19] train loss: 0.136 train acc: 0.938\n",
      "[99,    20] train loss: 0.167 train acc: 0.929\n",
      "[99] val loss: 0.048 val acc: 1.000\n",
      "[100,     1] train loss: 0.161 train acc: 0.938\n",
      "[100,     2] train loss: 0.107 train acc: 0.965\n",
      "[100,     3] train loss: 0.141 train acc: 0.930\n",
      "[100,     4] train loss: 0.188 train acc: 0.938\n",
      "[100,     5] train loss: 0.158 train acc: 0.941\n",
      "[100,     6] train loss: 0.126 train acc: 0.926\n",
      "[100,     7] train loss: 0.136 train acc: 0.945\n",
      "[100,     8] train loss: 0.144 train acc: 0.938\n",
      "[100,     9] train loss: 0.134 train acc: 0.949\n",
      "[100,    10] train loss: 0.177 train acc: 0.934\n",
      "[100,    11] train loss: 0.134 train acc: 0.945\n",
      "[100,    12] train loss: 0.132 train acc: 0.949\n",
      "[100,    13] train loss: 0.183 train acc: 0.938\n",
      "[100,    14] train loss: 0.234 train acc: 0.910\n",
      "[100,    15] train loss: 0.186 train acc: 0.918\n",
      "[100,    16] train loss: 0.169 train acc: 0.941\n",
      "[100,    17] train loss: 0.084 train acc: 0.973\n",
      "[100,    18] train loss: 0.119 train acc: 0.941\n",
      "[100,    19] train loss: 0.142 train acc: 0.945\n",
      "[100,    20] train loss: 0.150 train acc: 0.948\n",
      "[100] val loss: 0.056 val acc: 1.000\n",
      "[101,     1] train loss: 0.115 train acc: 0.961\n",
      "[101,     2] train loss: 0.172 train acc: 0.941\n",
      "[101,     3] train loss: 0.144 train acc: 0.934\n",
      "[101,     4] train loss: 0.133 train acc: 0.945\n",
      "[101,     5] train loss: 0.142 train acc: 0.934\n",
      "[101,     6] train loss: 0.152 train acc: 0.930\n",
      "[101,     7] train loss: 0.149 train acc: 0.949\n",
      "[101,     8] train loss: 0.112 train acc: 0.965\n",
      "[101,     9] train loss: 0.143 train acc: 0.957\n",
      "[101,    10] train loss: 0.163 train acc: 0.938\n",
      "[101,    11] train loss: 0.165 train acc: 0.926\n",
      "[101,    12] train loss: 0.209 train acc: 0.918\n",
      "[101,    13] train loss: 0.196 train acc: 0.922\n",
      "[101,    14] train loss: 0.142 train acc: 0.934\n",
      "[101,    15] train loss: 0.164 train acc: 0.941\n",
      "[101,    16] train loss: 0.139 train acc: 0.961\n",
      "[101,    17] train loss: 0.117 train acc: 0.945\n",
      "[101,    18] train loss: 0.141 train acc: 0.953\n",
      "[101,    19] train loss: 0.102 train acc: 0.957\n",
      "[101,    20] train loss: 0.148 train acc: 0.948\n",
      "[101] val loss: 0.055 val acc: 1.000\n",
      "[102,     1] train loss: 0.112 train acc: 0.961\n",
      "[102,     2] train loss: 0.194 train acc: 0.930\n",
      "[102,     3] train loss: 0.135 train acc: 0.949\n",
      "[102,     4] train loss: 0.139 train acc: 0.941\n",
      "[102,     5] train loss: 0.113 train acc: 0.953\n",
      "[102,     6] train loss: 0.168 train acc: 0.941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[102,     7] train loss: 0.100 train acc: 0.969\n",
      "[102,     8] train loss: 0.176 train acc: 0.934\n",
      "[102,     9] train loss: 0.224 train acc: 0.910\n",
      "[102,    10] train loss: 0.082 train acc: 0.965\n",
      "[102,    11] train loss: 0.176 train acc: 0.953\n",
      "[102,    12] train loss: 0.163 train acc: 0.945\n",
      "[102,    13] train loss: 0.134 train acc: 0.941\n",
      "[102,    14] train loss: 0.130 train acc: 0.941\n",
      "[102,    15] train loss: 0.116 train acc: 0.953\n",
      "[102,    16] train loss: 0.137 train acc: 0.941\n",
      "[102,    17] train loss: 0.148 train acc: 0.930\n",
      "[102,    18] train loss: 0.097 train acc: 0.961\n",
      "[102,    19] train loss: 0.161 train acc: 0.938\n",
      "[102,    20] train loss: 0.141 train acc: 0.935\n",
      "[102] val loss: 0.047 val acc: 1.000\n",
      "[103,     1] train loss: 0.138 train acc: 0.938\n",
      "[103,     2] train loss: 0.147 train acc: 0.938\n",
      "[103,     3] train loss: 0.139 train acc: 0.945\n",
      "[103,     4] train loss: 0.109 train acc: 0.945\n",
      "[103,     5] train loss: 0.153 train acc: 0.941\n",
      "[103,     6] train loss: 0.114 train acc: 0.953\n",
      "[103,     7] train loss: 0.108 train acc: 0.961\n",
      "[103,     8] train loss: 0.116 train acc: 0.961\n",
      "[103,     9] train loss: 0.131 train acc: 0.953\n",
      "[103,    10] train loss: 0.104 train acc: 0.957\n",
      "[103,    11] train loss: 0.174 train acc: 0.938\n",
      "[103,    12] train loss: 0.112 train acc: 0.957\n",
      "[103,    13] train loss: 0.126 train acc: 0.945\n",
      "[103,    14] train loss: 0.153 train acc: 0.926\n",
      "[103,    15] train loss: 0.193 train acc: 0.930\n",
      "[103,    16] train loss: 0.146 train acc: 0.938\n",
      "[103,    17] train loss: 0.128 train acc: 0.934\n",
      "[103,    18] train loss: 0.139 train acc: 0.945\n",
      "[103,    19] train loss: 0.162 train acc: 0.941\n",
      "[103,    20] train loss: 0.201 train acc: 0.910\n",
      "[103] val loss: 0.041 val acc: 1.000\n",
      "[104,     1] train loss: 0.144 train acc: 0.945\n",
      "[104,     2] train loss: 0.151 train acc: 0.938\n",
      "[104,     3] train loss: 0.185 train acc: 0.934\n",
      "[104,     4] train loss: 0.175 train acc: 0.934\n",
      "[104,     5] train loss: 0.141 train acc: 0.930\n",
      "[104,     6] train loss: 0.158 train acc: 0.949\n",
      "[104,     7] train loss: 0.160 train acc: 0.941\n",
      "[104,     8] train loss: 0.155 train acc: 0.945\n",
      "[104,     9] train loss: 0.138 train acc: 0.938\n",
      "[104,    10] train loss: 0.159 train acc: 0.945\n",
      "[104,    11] train loss: 0.113 train acc: 0.969\n",
      "[104,    12] train loss: 0.165 train acc: 0.945\n",
      "[104,    13] train loss: 0.140 train acc: 0.945\n",
      "[104,    14] train loss: 0.163 train acc: 0.938\n",
      "[104,    15] train loss: 0.152 train acc: 0.918\n",
      "[104,    16] train loss: 0.134 train acc: 0.949\n",
      "[104,    17] train loss: 0.128 train acc: 0.938\n",
      "[104,    18] train loss: 0.153 train acc: 0.945\n",
      "[104,    19] train loss: 0.157 train acc: 0.949\n",
      "[104,    20] train loss: 0.128 train acc: 0.942\n",
      "[104] val loss: 0.051 val acc: 1.000\n",
      "[105,     1] train loss: 0.172 train acc: 0.949\n",
      "[105,     2] train loss: 0.098 train acc: 0.973\n",
      "[105,     3] train loss: 0.144 train acc: 0.945\n",
      "[105,     4] train loss: 0.144 train acc: 0.930\n",
      "[105,     5] train loss: 0.086 train acc: 0.973\n",
      "[105,     6] train loss: 0.143 train acc: 0.945\n",
      "[105,     7] train loss: 0.114 train acc: 0.953\n",
      "[105,     8] train loss: 0.162 train acc: 0.945\n",
      "[105,     9] train loss: 0.183 train acc: 0.934\n",
      "[105,    10] train loss: 0.128 train acc: 0.953\n",
      "[105,    11] train loss: 0.142 train acc: 0.938\n",
      "[105,    12] train loss: 0.131 train acc: 0.941\n",
      "[105,    13] train loss: 0.138 train acc: 0.953\n",
      "[105,    14] train loss: 0.107 train acc: 0.953\n",
      "[105,    15] train loss: 0.131 train acc: 0.941\n",
      "[105,    16] train loss: 0.183 train acc: 0.930\n",
      "[105,    17] train loss: 0.140 train acc: 0.922\n",
      "[105,    18] train loss: 0.165 train acc: 0.930\n",
      "[105,    19] train loss: 0.119 train acc: 0.953\n",
      "[105,    20] train loss: 0.193 train acc: 0.929\n",
      "[105] val loss: 0.043 val acc: 1.000\n",
      "[106,     1] train loss: 0.129 train acc: 0.945\n",
      "[106,     2] train loss: 0.243 train acc: 0.938\n",
      "[106,     3] train loss: 0.131 train acc: 0.957\n",
      "[106,     4] train loss: 0.159 train acc: 0.945\n",
      "[106,     5] train loss: 0.178 train acc: 0.910\n",
      "[106,     6] train loss: 0.160 train acc: 0.930\n",
      "[106,     7] train loss: 0.108 train acc: 0.953\n",
      "[106,     8] train loss: 0.154 train acc: 0.934\n",
      "[106,     9] train loss: 0.114 train acc: 0.953\n",
      "[106,    10] train loss: 0.171 train acc: 0.918\n",
      "[106,    11] train loss: 0.186 train acc: 0.941\n",
      "[106,    12] train loss: 0.109 train acc: 0.973\n",
      "[106,    13] train loss: 0.163 train acc: 0.930\n",
      "[106,    14] train loss: 0.079 train acc: 0.977\n",
      "[106,    15] train loss: 0.155 train acc: 0.934\n",
      "[106,    16] train loss: 0.109 train acc: 0.957\n",
      "[106,    17] train loss: 0.168 train acc: 0.926\n",
      "[106,    18] train loss: 0.161 train acc: 0.941\n",
      "[106,    19] train loss: 0.135 train acc: 0.949\n",
      "[106,    20] train loss: 0.145 train acc: 0.935\n",
      "[106] val loss: 0.048 val acc: 1.000\n",
      "[107,     1] train loss: 0.126 train acc: 0.957\n",
      "[107,     2] train loss: 0.104 train acc: 0.957\n",
      "[107,     3] train loss: 0.144 train acc: 0.953\n",
      "[107,     4] train loss: 0.100 train acc: 0.969\n",
      "[107,     5] train loss: 0.135 train acc: 0.957\n",
      "[107,     6] train loss: 0.097 train acc: 0.949\n",
      "[107,     7] train loss: 0.096 train acc: 0.961\n",
      "[107,     8] train loss: 0.145 train acc: 0.941\n",
      "[107,     9] train loss: 0.128 train acc: 0.961\n",
      "[107,    10] train loss: 0.214 train acc: 0.910\n",
      "[107,    11] train loss: 0.148 train acc: 0.945\n",
      "[107,    12] train loss: 0.129 train acc: 0.953\n",
      "[107,    13] train loss: 0.157 train acc: 0.926\n",
      "[107,    14] train loss: 0.130 train acc: 0.953\n",
      "[107,    15] train loss: 0.141 train acc: 0.938\n",
      "[107,    16] train loss: 0.153 train acc: 0.938\n",
      "[107,    17] train loss: 0.148 train acc: 0.941\n",
      "[107,    18] train loss: 0.105 train acc: 0.953\n",
      "[107,    19] train loss: 0.114 train acc: 0.957\n",
      "[107,    20] train loss: 0.105 train acc: 0.961\n",
      "[107] val loss: 0.041 val acc: 1.000\n",
      "[108,     1] train loss: 0.141 train acc: 0.945\n",
      "[108,     2] train loss: 0.124 train acc: 0.949\n",
      "[108,     3] train loss: 0.142 train acc: 0.941\n",
      "[108,     4] train loss: 0.090 train acc: 0.961\n",
      "[108,     5] train loss: 0.110 train acc: 0.953\n",
      "[108,     6] train loss: 0.164 train acc: 0.930\n",
      "[108,     7] train loss: 0.154 train acc: 0.949\n",
      "[108,     8] train loss: 0.124 train acc: 0.949\n",
      "[108,     9] train loss: 0.150 train acc: 0.941\n",
      "[108,    10] train loss: 0.137 train acc: 0.949\n",
      "[108,    11] train loss: 0.114 train acc: 0.961\n",
      "[108,    12] train loss: 0.150 train acc: 0.949\n",
      "[108,    13] train loss: 0.146 train acc: 0.949\n",
      "[108,    14] train loss: 0.161 train acc: 0.934\n",
      "[108,    15] train loss: 0.127 train acc: 0.941\n",
      "[108,    16] train loss: 0.128 train acc: 0.957\n",
      "[108,    17] train loss: 0.123 train acc: 0.953\n",
      "[108,    18] train loss: 0.138 train acc: 0.957\n",
      "[108,    19] train loss: 0.125 train acc: 0.941\n",
      "[108,    20] train loss: 0.135 train acc: 0.948\n",
      "[108] val loss: 0.038 val acc: 1.000\n",
      "[109,     1] train loss: 0.106 train acc: 0.953\n",
      "[109,     2] train loss: 0.112 train acc: 0.973\n",
      "[109,     3] train loss: 0.100 train acc: 0.977\n",
      "[109,     4] train loss: 0.106 train acc: 0.961\n",
      "[109,     5] train loss: 0.132 train acc: 0.949\n",
      "[109,     6] train loss: 0.116 train acc: 0.961\n",
      "[109,     7] train loss: 0.165 train acc: 0.934\n",
      "[109,     8] train loss: 0.156 train acc: 0.941\n",
      "[109,     9] train loss: 0.152 train acc: 0.922\n",
      "[109,    10] train loss: 0.104 train acc: 0.953\n",
      "[109,    11] train loss: 0.121 train acc: 0.949\n",
      "[109,    12] train loss: 0.128 train acc: 0.953\n",
      "[109,    13] train loss: 0.120 train acc: 0.965\n",
      "[109,    14] train loss: 0.131 train acc: 0.949\n",
      "[109,    15] train loss: 0.151 train acc: 0.938\n",
      "[109,    16] train loss: 0.144 train acc: 0.949\n",
      "[109,    17] train loss: 0.150 train acc: 0.934\n",
      "[109,    18] train loss: 0.100 train acc: 0.957\n",
      "[109,    19] train loss: 0.118 train acc: 0.949\n",
      "[109,    20] train loss: 0.105 train acc: 0.948\n",
      "[109] val loss: 0.037 val acc: 1.000\n",
      "[110,     1] train loss: 0.130 train acc: 0.957\n",
      "[110,     2] train loss: 0.127 train acc: 0.941\n",
      "[110,     3] train loss: 0.111 train acc: 0.957\n",
      "[110,     4] train loss: 0.141 train acc: 0.938\n",
      "[110,     5] train loss: 0.112 train acc: 0.961\n",
      "[110,     6] train loss: 0.133 train acc: 0.938\n",
      "[110,     7] train loss: 0.140 train acc: 0.934\n",
      "[110,     8] train loss: 0.145 train acc: 0.957\n",
      "[110,     9] train loss: 0.098 train acc: 0.969\n",
      "[110,    10] train loss: 0.142 train acc: 0.938\n",
      "[110,    11] train loss: 0.134 train acc: 0.938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[110,    12] train loss: 0.126 train acc: 0.957\n",
      "[110,    13] train loss: 0.150 train acc: 0.934\n",
      "[110,    14] train loss: 0.118 train acc: 0.945\n",
      "[110,    15] train loss: 0.109 train acc: 0.961\n",
      "[110,    16] train loss: 0.183 train acc: 0.938\n",
      "[110,    17] train loss: 0.119 train acc: 0.941\n",
      "[110,    18] train loss: 0.110 train acc: 0.957\n",
      "[110,    19] train loss: 0.160 train acc: 0.938\n",
      "[110,    20] train loss: 0.176 train acc: 0.923\n",
      "[110] val loss: 0.032 val acc: 1.000\n",
      "[111,     1] train loss: 0.144 train acc: 0.953\n",
      "[111,     2] train loss: 0.096 train acc: 0.965\n",
      "[111,     3] train loss: 0.152 train acc: 0.949\n",
      "[111,     4] train loss: 0.159 train acc: 0.938\n",
      "[111,     5] train loss: 0.157 train acc: 0.945\n",
      "[111,     6] train loss: 0.157 train acc: 0.941\n",
      "[111,     7] train loss: 0.120 train acc: 0.961\n",
      "[111,     8] train loss: 0.155 train acc: 0.941\n",
      "[111,     9] train loss: 0.141 train acc: 0.941\n",
      "[111,    10] train loss: 0.136 train acc: 0.949\n",
      "[111,    11] train loss: 0.110 train acc: 0.961\n",
      "[111,    12] train loss: 0.110 train acc: 0.961\n",
      "[111,    13] train loss: 0.105 train acc: 0.977\n",
      "[111,    14] train loss: 0.140 train acc: 0.945\n",
      "[111,    15] train loss: 0.096 train acc: 0.969\n",
      "[111,    16] train loss: 0.102 train acc: 0.957\n",
      "[111,    17] train loss: 0.155 train acc: 0.949\n",
      "[111,    18] train loss: 0.087 train acc: 0.965\n",
      "[111,    19] train loss: 0.153 train acc: 0.949\n",
      "[111,    20] train loss: 0.121 train acc: 0.961\n",
      "[111] val loss: 0.038 val acc: 1.000\n",
      "[112,     1] train loss: 0.134 train acc: 0.938\n",
      "[112,     2] train loss: 0.118 train acc: 0.945\n",
      "[112,     3] train loss: 0.123 train acc: 0.961\n",
      "[112,     4] train loss: 0.175 train acc: 0.941\n",
      "[112,     5] train loss: 0.074 train acc: 0.980\n",
      "[112,     6] train loss: 0.137 train acc: 0.949\n",
      "[112,     7] train loss: 0.133 train acc: 0.961\n",
      "[112,     8] train loss: 0.122 train acc: 0.949\n",
      "[112,     9] train loss: 0.146 train acc: 0.945\n",
      "[112,    10] train loss: 0.119 train acc: 0.961\n",
      "[112,    11] train loss: 0.114 train acc: 0.949\n",
      "[112,    12] train loss: 0.127 train acc: 0.941\n",
      "[112,    13] train loss: 0.128 train acc: 0.957\n",
      "[112,    14] train loss: 0.090 train acc: 0.969\n",
      "[112,    15] train loss: 0.341 train acc: 0.957\n",
      "[112,    16] train loss: 0.089 train acc: 0.961\n",
      "[112,    17] train loss: 0.175 train acc: 0.922\n",
      "[112,    18] train loss: 0.189 train acc: 0.918\n",
      "[112,    19] train loss: 0.294 train acc: 0.898\n",
      "[112,    20] train loss: 0.346 train acc: 0.858\n",
      "[112] val loss: 0.138 val acc: 0.970\n",
      "[113,     1] train loss: 0.447 train acc: 0.840\n",
      "[113,     2] train loss: 0.315 train acc: 0.895\n",
      "[113,     3] train loss: 0.273 train acc: 0.898\n",
      "[113,     4] train loss: 0.310 train acc: 0.887\n",
      "[113,     5] train loss: 0.372 train acc: 0.844\n",
      "[113,     6] train loss: 0.452 train acc: 0.824\n",
      "[113,     7] train loss: 0.278 train acc: 0.883\n",
      "[113,     8] train loss: 0.316 train acc: 0.871\n",
      "[113,     9] train loss: 0.290 train acc: 0.895\n",
      "[113,    10] train loss: 0.329 train acc: 0.875\n",
      "[113,    11] train loss: 0.298 train acc: 0.875\n",
      "[113,    12] train loss: 0.391 train acc: 0.832\n",
      "[113,    13] train loss: 0.414 train acc: 0.828\n",
      "[113,    14] train loss: 0.325 train acc: 0.875\n",
      "[113,    15] train loss: 0.343 train acc: 0.848\n",
      "[113,    16] train loss: 0.263 train acc: 0.879\n",
      "[113,    17] train loss: 0.325 train acc: 0.852\n",
      "[113,    18] train loss: 0.324 train acc: 0.855\n",
      "[113,    19] train loss: 0.386 train acc: 0.809\n",
      "[113,    20] train loss: 0.356 train acc: 0.839\n",
      "[113] val loss: 0.268 val acc: 0.987\n",
      "[114,     1] train loss: 0.449 train acc: 0.805\n",
      "[114,     2] train loss: 0.313 train acc: 0.859\n",
      "[114,     3] train loss: 0.319 train acc: 0.855\n",
      "[114,     4] train loss: 0.328 train acc: 0.875\n",
      "[114,     5] train loss: 0.332 train acc: 0.840\n",
      "[114,     6] train loss: 0.442 train acc: 0.797\n",
      "[114,     7] train loss: 0.287 train acc: 0.871\n",
      "[114,     8] train loss: 0.280 train acc: 0.891\n",
      "[114,     9] train loss: 0.271 train acc: 0.887\n",
      "[114,    10] train loss: 0.321 train acc: 0.855\n",
      "[114,    11] train loss: 0.310 train acc: 0.879\n",
      "[114,    12] train loss: 0.307 train acc: 0.879\n",
      "[114,    13] train loss: 0.331 train acc: 0.867\n",
      "[114,    14] train loss: 0.337 train acc: 0.875\n",
      "[114,    15] train loss: 0.277 train acc: 0.895\n",
      "[114,    16] train loss: 0.259 train acc: 0.875\n",
      "[114,    17] train loss: 0.292 train acc: 0.887\n",
      "[114,    18] train loss: 0.269 train acc: 0.895\n",
      "[114,    19] train loss: 0.342 train acc: 0.844\n",
      "[114,    20] train loss: 0.284 train acc: 0.865\n",
      "[114] val loss: 0.193 val acc: 0.996\n",
      "[115,     1] train loss: 0.295 train acc: 0.875\n",
      "[115,     2] train loss: 0.306 train acc: 0.859\n",
      "[115,     3] train loss: 0.265 train acc: 0.871\n",
      "[115,     4] train loss: 0.270 train acc: 0.871\n",
      "[115,     5] train loss: 0.283 train acc: 0.867\n",
      "[115,     6] train loss: 0.341 train acc: 0.871\n",
      "[115,     7] train loss: 0.266 train acc: 0.879\n",
      "[115,     8] train loss: 0.418 train acc: 0.832\n",
      "[115,     9] train loss: 0.296 train acc: 0.863\n",
      "[115,    10] train loss: 0.257 train acc: 0.898\n",
      "[115,    11] train loss: 0.246 train acc: 0.895\n",
      "[115,    12] train loss: 0.303 train acc: 0.875\n",
      "[115,    13] train loss: 0.277 train acc: 0.895\n",
      "[115,    14] train loss: 0.293 train acc: 0.887\n",
      "[115,    15] train loss: 0.303 train acc: 0.867\n",
      "[115,    16] train loss: 0.293 train acc: 0.879\n",
      "[115,    17] train loss: 0.278 train acc: 0.863\n",
      "[115,    18] train loss: 0.296 train acc: 0.875\n",
      "[115,    19] train loss: 0.317 train acc: 0.867\n",
      "[115,    20] train loss: 0.177 train acc: 0.916\n",
      "[115] val loss: 0.188 val acc: 1.000\n",
      "[116,     1] train loss: 0.283 train acc: 0.863\n",
      "[116,     2] train loss: 0.287 train acc: 0.871\n",
      "[116,     3] train loss: 0.243 train acc: 0.898\n",
      "[116,     4] train loss: 0.277 train acc: 0.867\n",
      "[116,     5] train loss: 0.195 train acc: 0.926\n",
      "[116,     6] train loss: 0.255 train acc: 0.875\n",
      "[116,     7] train loss: 0.252 train acc: 0.879\n",
      "[116,     8] train loss: 0.242 train acc: 0.898\n",
      "[116,     9] train loss: 0.229 train acc: 0.902\n",
      "[116,    10] train loss: 0.173 train acc: 0.934\n",
      "[116,    11] train loss: 0.277 train acc: 0.867\n",
      "[116,    12] train loss: 0.247 train acc: 0.887\n",
      "[116,    13] train loss: 0.280 train acc: 0.887\n",
      "[116,    14] train loss: 0.217 train acc: 0.895\n",
      "[116,    15] train loss: 0.215 train acc: 0.902\n",
      "[116,    16] train loss: 0.341 train acc: 0.871\n",
      "[116,    17] train loss: 0.190 train acc: 0.922\n",
      "[116,    18] train loss: 0.221 train acc: 0.902\n",
      "[116,    19] train loss: 0.281 train acc: 0.891\n",
      "[116,    20] train loss: 0.209 train acc: 0.897\n",
      "[116] val loss: 0.130 val acc: 0.999\n",
      "[117,     1] train loss: 0.236 train acc: 0.902\n",
      "[117,     2] train loss: 0.216 train acc: 0.902\n",
      "[117,     3] train loss: 0.217 train acc: 0.910\n",
      "[117,     4] train loss: 0.234 train acc: 0.914\n",
      "[117,     5] train loss: 0.230 train acc: 0.906\n",
      "[117,     6] train loss: 0.211 train acc: 0.898\n",
      "[117,     7] train loss: 0.282 train acc: 0.875\n",
      "[117,     8] train loss: 0.250 train acc: 0.863\n",
      "[117,     9] train loss: 0.268 train acc: 0.887\n",
      "[117,    10] train loss: 0.218 train acc: 0.914\n",
      "[117,    11] train loss: 0.209 train acc: 0.938\n",
      "[117,    12] train loss: 0.262 train acc: 0.895\n",
      "[117,    13] train loss: 0.185 train acc: 0.930\n",
      "[117,    14] train loss: 0.259 train acc: 0.887\n",
      "[117,    15] train loss: 0.264 train acc: 0.891\n",
      "[117,    16] train loss: 0.236 train acc: 0.914\n",
      "[117,    17] train loss: 0.221 train acc: 0.875\n",
      "[117,    18] train loss: 0.286 train acc: 0.852\n",
      "[117,    19] train loss: 0.222 train acc: 0.914\n",
      "[117,    20] train loss: 0.233 train acc: 0.897\n",
      "[117] val loss: 0.135 val acc: 1.000\n",
      "[118,     1] train loss: 0.192 train acc: 0.918\n",
      "[118,     2] train loss: 0.266 train acc: 0.891\n",
      "[118,     3] train loss: 0.195 train acc: 0.914\n",
      "[118,     4] train loss: 0.233 train acc: 0.918\n",
      "[118,     5] train loss: 0.269 train acc: 0.906\n",
      "[118,     6] train loss: 0.184 train acc: 0.930\n",
      "[118,     7] train loss: 0.248 train acc: 0.910\n",
      "[118,     8] train loss: 0.206 train acc: 0.918\n",
      "[118,     9] train loss: 0.179 train acc: 0.930\n",
      "[118,    10] train loss: 0.203 train acc: 0.902\n",
      "[118,    11] train loss: 0.227 train acc: 0.914\n",
      "[118,    12] train loss: 0.268 train acc: 0.879\n",
      "[118,    13] train loss: 0.253 train acc: 0.910\n",
      "[118,    14] train loss: 0.208 train acc: 0.910\n",
      "[118,    15] train loss: 0.219 train acc: 0.918\n",
      "[118,    16] train loss: 0.192 train acc: 0.930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[118,    17] train loss: 0.227 train acc: 0.910\n",
      "[118,    18] train loss: 0.237 train acc: 0.906\n",
      "[118,    19] train loss: 0.239 train acc: 0.902\n",
      "[118,    20] train loss: 0.247 train acc: 0.890\n",
      "[118] val loss: 0.113 val acc: 1.000\n",
      "[119,     1] train loss: 0.202 train acc: 0.926\n",
      "[119,     2] train loss: 0.201 train acc: 0.902\n",
      "[119,     3] train loss: 0.232 train acc: 0.902\n",
      "[119,     4] train loss: 0.248 train acc: 0.883\n",
      "[119,     5] train loss: 0.149 train acc: 0.949\n",
      "[119,     6] train loss: 0.203 train acc: 0.934\n",
      "[119,     7] train loss: 0.238 train acc: 0.918\n",
      "[119,     8] train loss: 0.200 train acc: 0.922\n",
      "[119,     9] train loss: 0.165 train acc: 0.930\n",
      "[119,    10] train loss: 0.201 train acc: 0.918\n",
      "[119,    11] train loss: 0.191 train acc: 0.906\n",
      "[119,    12] train loss: 0.162 train acc: 0.945\n",
      "[119,    13] train loss: 0.232 train acc: 0.879\n",
      "[119,    14] train loss: 0.182 train acc: 0.934\n",
      "[119,    15] train loss: 0.235 train acc: 0.895\n",
      "[119,    16] train loss: 0.234 train acc: 0.910\n",
      "[119,    17] train loss: 0.151 train acc: 0.934\n",
      "[119,    18] train loss: 0.242 train acc: 0.902\n",
      "[119,    19] train loss: 0.233 train acc: 0.898\n",
      "[119,    20] train loss: 0.243 train acc: 0.910\n",
      "[119] val loss: 0.090 val acc: 1.000\n",
      "[120,     1] train loss: 0.185 train acc: 0.926\n",
      "[120,     2] train loss: 0.235 train acc: 0.910\n",
      "[120,     3] train loss: 0.209 train acc: 0.906\n",
      "[120,     4] train loss: 0.173 train acc: 0.934\n",
      "[120,     5] train loss: 0.230 train acc: 0.918\n",
      "[120,     6] train loss: 0.247 train acc: 0.883\n",
      "[120,     7] train loss: 0.174 train acc: 0.910\n",
      "[120,     8] train loss: 0.267 train acc: 0.891\n",
      "[120,     9] train loss: 0.220 train acc: 0.922\n",
      "[120,    10] train loss: 0.211 train acc: 0.918\n",
      "[120,    11] train loss: 0.211 train acc: 0.918\n",
      "[120,    12] train loss: 0.151 train acc: 0.941\n",
      "[120,    13] train loss: 0.235 train acc: 0.910\n",
      "[120,    14] train loss: 0.243 train acc: 0.914\n",
      "[120,    15] train loss: 0.201 train acc: 0.906\n",
      "[120,    16] train loss: 0.215 train acc: 0.906\n",
      "[120,    17] train loss: 0.207 train acc: 0.918\n",
      "[120,    18] train loss: 0.226 train acc: 0.914\n",
      "[120,    19] train loss: 0.185 train acc: 0.934\n",
      "[120,    20] train loss: 0.197 train acc: 0.923\n",
      "[120] val loss: 0.103 val acc: 1.000\n",
      "[121,     1] train loss: 0.172 train acc: 0.934\n",
      "[121,     2] train loss: 0.192 train acc: 0.934\n",
      "[121,     3] train loss: 0.176 train acc: 0.934\n",
      "[121,     4] train loss: 0.192 train acc: 0.906\n",
      "[121,     5] train loss: 0.205 train acc: 0.914\n",
      "[121,     6] train loss: 0.184 train acc: 0.922\n",
      "[121,     7] train loss: 0.160 train acc: 0.938\n",
      "[121,     8] train loss: 0.186 train acc: 0.922\n",
      "[121,     9] train loss: 0.257 train acc: 0.895\n",
      "[121,    10] train loss: 0.153 train acc: 0.930\n",
      "[121,    11] train loss: 0.210 train acc: 0.930\n",
      "[121,    12] train loss: 0.172 train acc: 0.926\n",
      "[121,    13] train loss: 0.201 train acc: 0.910\n",
      "[121,    14] train loss: 0.164 train acc: 0.941\n",
      "[121,    15] train loss: 0.243 train acc: 0.895\n",
      "[121,    16] train loss: 0.168 train acc: 0.930\n",
      "[121,    17] train loss: 0.172 train acc: 0.926\n",
      "[121,    18] train loss: 0.215 train acc: 0.914\n",
      "[121,    19] train loss: 0.172 train acc: 0.938\n",
      "[121,    20] train loss: 0.209 train acc: 0.890\n",
      "[121] val loss: 0.080 val acc: 1.000\n",
      "[122,     1] train loss: 0.142 train acc: 0.930\n",
      "[122,     2] train loss: 0.177 train acc: 0.938\n",
      "[122,     3] train loss: 0.163 train acc: 0.918\n",
      "[122,     4] train loss: 0.141 train acc: 0.953\n",
      "[122,     5] train loss: 0.204 train acc: 0.918\n",
      "[122,     6] train loss: 0.163 train acc: 0.926\n",
      "[122,     7] train loss: 0.192 train acc: 0.922\n",
      "[122,     8] train loss: 0.212 train acc: 0.926\n",
      "[122,     9] train loss: 0.176 train acc: 0.941\n",
      "[122,    10] train loss: 0.219 train acc: 0.914\n",
      "[122,    11] train loss: 0.147 train acc: 0.949\n",
      "[122,    12] train loss: 0.164 train acc: 0.934\n",
      "[122,    13] train loss: 0.199 train acc: 0.910\n",
      "[122,    14] train loss: 0.241 train acc: 0.910\n",
      "[122,    15] train loss: 0.182 train acc: 0.934\n",
      "[122,    16] train loss: 0.232 train acc: 0.891\n",
      "[122,    17] train loss: 0.218 train acc: 0.914\n",
      "[122,    18] train loss: 0.124 train acc: 0.949\n",
      "[122,    19] train loss: 0.188 train acc: 0.910\n",
      "[122,    20] train loss: 0.209 train acc: 0.942\n",
      "[122] val loss: 0.083 val acc: 1.000\n",
      "[123,     1] train loss: 0.180 train acc: 0.930\n",
      "[123,     2] train loss: 0.215 train acc: 0.914\n",
      "[123,     3] train loss: 0.163 train acc: 0.926\n",
      "[123,     4] train loss: 0.138 train acc: 0.941\n",
      "[123,     5] train loss: 0.190 train acc: 0.914\n",
      "[123,     6] train loss: 0.199 train acc: 0.926\n",
      "[123,     7] train loss: 0.159 train acc: 0.945\n",
      "[123,     8] train loss: 0.161 train acc: 0.930\n",
      "[123,     9] train loss: 0.217 train acc: 0.930\n",
      "[123,    10] train loss: 0.239 train acc: 0.922\n",
      "[123,    11] train loss: 0.167 train acc: 0.914\n",
      "[123,    12] train loss: 0.211 train acc: 0.938\n",
      "[123,    13] train loss: 0.179 train acc: 0.930\n",
      "[123,    14] train loss: 0.191 train acc: 0.938\n",
      "[123,    15] train loss: 0.156 train acc: 0.934\n",
      "[123,    16] train loss: 0.199 train acc: 0.910\n",
      "[123,    17] train loss: 0.177 train acc: 0.926\n",
      "[123,    18] train loss: 0.245 train acc: 0.898\n",
      "[123,    19] train loss: 0.161 train acc: 0.941\n",
      "[123,    20] train loss: 0.180 train acc: 0.929\n",
      "[123] val loss: 0.075 val acc: 1.000\n",
      "[124,     1] train loss: 0.180 train acc: 0.910\n",
      "[124,     2] train loss: 0.143 train acc: 0.945\n",
      "[124,     3] train loss: 0.155 train acc: 0.941\n",
      "[124,     4] train loss: 0.158 train acc: 0.914\n",
      "[124,     5] train loss: 0.141 train acc: 0.941\n",
      "[124,     6] train loss: 0.163 train acc: 0.938\n",
      "[124,     7] train loss: 0.172 train acc: 0.938\n",
      "[124,     8] train loss: 0.159 train acc: 0.938\n",
      "[124,     9] train loss: 0.230 train acc: 0.922\n",
      "[124,    10] train loss: 0.264 train acc: 0.902\n",
      "[124,    11] train loss: 0.155 train acc: 0.941\n",
      "[124,    12] train loss: 0.195 train acc: 0.910\n",
      "[124,    13] train loss: 0.172 train acc: 0.918\n",
      "[124,    14] train loss: 0.150 train acc: 0.941\n",
      "[124,    15] train loss: 0.192 train acc: 0.938\n",
      "[124,    16] train loss: 0.191 train acc: 0.938\n",
      "[124,    17] train loss: 0.169 train acc: 0.926\n",
      "[124,    18] train loss: 0.245 train acc: 0.883\n",
      "[124,    19] train loss: 0.197 train acc: 0.910\n",
      "[124,    20] train loss: 0.195 train acc: 0.923\n",
      "[124] val loss: 0.068 val acc: 1.000\n",
      "[125,     1] train loss: 0.229 train acc: 0.895\n",
      "[125,     2] train loss: 0.182 train acc: 0.941\n",
      "[125,     3] train loss: 0.207 train acc: 0.906\n",
      "[125,     4] train loss: 0.214 train acc: 0.922\n",
      "[125,     5] train loss: 0.171 train acc: 0.934\n",
      "[125,     6] train loss: 0.219 train acc: 0.926\n",
      "[125,     7] train loss: 0.249 train acc: 0.914\n",
      "[125,     8] train loss: 0.230 train acc: 0.883\n",
      "[125,     9] train loss: 0.154 train acc: 0.926\n",
      "[125,    10] train loss: 0.172 train acc: 0.949\n",
      "[125,    11] train loss: 0.192 train acc: 0.914\n",
      "[125,    12] train loss: 0.180 train acc: 0.922\n",
      "[125,    13] train loss: 0.214 train acc: 0.895\n",
      "[125,    14] train loss: 0.103 train acc: 0.965\n",
      "[125,    15] train loss: 0.221 train acc: 0.895\n",
      "[125,    16] train loss: 0.240 train acc: 0.906\n",
      "[125,    17] train loss: 0.217 train acc: 0.918\n",
      "[125,    18] train loss: 0.224 train acc: 0.910\n",
      "[125,    19] train loss: 0.246 train acc: 0.883\n",
      "[125,    20] train loss: 0.181 train acc: 0.903\n",
      "[125] val loss: 0.088 val acc: 1.000\n",
      "[126,     1] train loss: 0.180 train acc: 0.906\n",
      "[126,     2] train loss: 0.226 train acc: 0.906\n",
      "[126,     3] train loss: 0.151 train acc: 0.922\n",
      "[126,     4] train loss: 0.165 train acc: 0.930\n",
      "[126,     5] train loss: 0.155 train acc: 0.945\n",
      "[126,     6] train loss: 0.177 train acc: 0.918\n",
      "[126,     7] train loss: 0.170 train acc: 0.930\n",
      "[126,     8] train loss: 0.192 train acc: 0.926\n",
      "[126,     9] train loss: 0.178 train acc: 0.914\n",
      "[126,    10] train loss: 0.160 train acc: 0.930\n",
      "[126,    11] train loss: 0.137 train acc: 0.945\n",
      "[126,    12] train loss: 0.224 train acc: 0.895\n",
      "[126,    13] train loss: 0.178 train acc: 0.930\n",
      "[126,    14] train loss: 0.235 train acc: 0.910\n",
      "[126,    15] train loss: 0.181 train acc: 0.930\n",
      "[126,    16] train loss: 0.212 train acc: 0.922\n",
      "[126,    17] train loss: 0.179 train acc: 0.926\n",
      "[126,    18] train loss: 0.212 train acc: 0.930\n",
      "[126,    19] train loss: 0.196 train acc: 0.930\n",
      "[126,    20] train loss: 0.106 train acc: 0.968\n",
      "[126] val loss: 0.078 val acc: 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[127,     1] train loss: 0.143 train acc: 0.945\n",
      "[127,     2] train loss: 0.140 train acc: 0.938\n",
      "[127,     3] train loss: 0.188 train acc: 0.930\n",
      "[127,     4] train loss: 0.131 train acc: 0.953\n",
      "[127,     5] train loss: 0.154 train acc: 0.934\n",
      "[127,     6] train loss: 0.178 train acc: 0.938\n",
      "[127,     7] train loss: 0.149 train acc: 0.934\n",
      "[127,     8] train loss: 0.139 train acc: 0.941\n",
      "[127,     9] train loss: 0.176 train acc: 0.934\n",
      "[127,    10] train loss: 0.178 train acc: 0.930\n",
      "[127,    11] train loss: 0.187 train acc: 0.938\n",
      "[127,    12] train loss: 0.179 train acc: 0.938\n",
      "[127,    13] train loss: 0.153 train acc: 0.941\n",
      "[127,    14] train loss: 0.138 train acc: 0.949\n",
      "[127,    15] train loss: 0.217 train acc: 0.922\n",
      "[127,    16] train loss: 0.201 train acc: 0.914\n",
      "[127,    17] train loss: 0.155 train acc: 0.914\n",
      "[127,    18] train loss: 0.177 train acc: 0.934\n",
      "[127,    19] train loss: 0.197 train acc: 0.922\n",
      "[127,    20] train loss: 0.203 train acc: 0.916\n",
      "[127] val loss: 0.056 val acc: 1.000\n",
      "[128,     1] train loss: 0.117 train acc: 0.957\n",
      "[128,     2] train loss: 0.184 train acc: 0.930\n",
      "[128,     3] train loss: 0.113 train acc: 0.953\n",
      "[128,     4] train loss: 0.129 train acc: 0.941\n",
      "[128,     5] train loss: 0.165 train acc: 0.930\n",
      "[128,     6] train loss: 0.156 train acc: 0.938\n",
      "[128,     7] train loss: 0.139 train acc: 0.953\n",
      "[128,     8] train loss: 0.166 train acc: 0.941\n",
      "[128,     9] train loss: 0.155 train acc: 0.938\n",
      "[128,    10] train loss: 0.210 train acc: 0.902\n",
      "[128,    11] train loss: 0.141 train acc: 0.941\n",
      "[128,    12] train loss: 0.156 train acc: 0.934\n",
      "[128,    13] train loss: 0.188 train acc: 0.941\n",
      "[128,    14] train loss: 0.151 train acc: 0.941\n",
      "[128,    15] train loss: 0.146 train acc: 0.941\n",
      "[128,    16] train loss: 0.193 train acc: 0.922\n",
      "[128,    17] train loss: 0.111 train acc: 0.957\n",
      "[128,    18] train loss: 0.167 train acc: 0.926\n",
      "[128,    19] train loss: 0.175 train acc: 0.922\n",
      "[128,    20] train loss: 0.157 train acc: 0.929\n",
      "[128] val loss: 0.056 val acc: 1.000\n",
      "[129,     1] train loss: 0.156 train acc: 0.938\n",
      "[129,     2] train loss: 0.138 train acc: 0.945\n",
      "[129,     3] train loss: 0.179 train acc: 0.941\n",
      "[129,     4] train loss: 0.167 train acc: 0.945\n",
      "[129,     5] train loss: 0.141 train acc: 0.945\n",
      "[129,     6] train loss: 0.172 train acc: 0.945\n",
      "[129,     7] train loss: 0.138 train acc: 0.941\n",
      "[129,     8] train loss: 0.146 train acc: 0.941\n",
      "[129,     9] train loss: 0.124 train acc: 0.957\n",
      "[129,    10] train loss: 0.157 train acc: 0.949\n",
      "[129,    11] train loss: 0.151 train acc: 0.941\n",
      "[129,    12] train loss: 0.135 train acc: 0.957\n",
      "[129,    13] train loss: 0.130 train acc: 0.930\n",
      "[129,    14] train loss: 0.138 train acc: 0.930\n",
      "[129,    15] train loss: 0.226 train acc: 0.914\n",
      "[129,    16] train loss: 0.200 train acc: 0.918\n",
      "[129,    17] train loss: 0.174 train acc: 0.922\n",
      "[129,    18] train loss: 0.146 train acc: 0.941\n",
      "[129,    19] train loss: 0.187 train acc: 0.926\n",
      "[129,    20] train loss: 0.250 train acc: 0.884\n",
      "[129] val loss: 0.054 val acc: 1.000\n",
      "[130,     1] train loss: 0.156 train acc: 0.926\n",
      "[130,     2] train loss: 0.149 train acc: 0.930\n",
      "[130,     3] train loss: 0.164 train acc: 0.926\n",
      "[130,     4] train loss: 0.163 train acc: 0.938\n",
      "[130,     5] train loss: 0.167 train acc: 0.941\n",
      "[130,     6] train loss: 0.115 train acc: 0.957\n",
      "[130,     7] train loss: 0.116 train acc: 0.957\n",
      "[130,     8] train loss: 0.129 train acc: 0.957\n",
      "[130,     9] train loss: 0.145 train acc: 0.945\n",
      "[130,    10] train loss: 0.129 train acc: 0.949\n",
      "[130,    11] train loss: 0.131 train acc: 0.953\n",
      "[130,    12] train loss: 0.185 train acc: 0.918\n",
      "[130,    13] train loss: 0.215 train acc: 0.922\n",
      "[130,    14] train loss: 0.236 train acc: 0.898\n",
      "[130,    15] train loss: 0.176 train acc: 0.934\n",
      "[130,    16] train loss: 0.145 train acc: 0.938\n",
      "[130,    17] train loss: 0.193 train acc: 0.922\n",
      "[130,    18] train loss: 0.111 train acc: 0.961\n",
      "[130,    19] train loss: 0.168 train acc: 0.926\n",
      "[130,    20] train loss: 0.140 train acc: 0.955\n",
      "[130] val loss: 0.055 val acc: 1.000\n",
      "[131,     1] train loss: 0.173 train acc: 0.934\n",
      "[131,     2] train loss: 0.149 train acc: 0.934\n",
      "[131,     3] train loss: 0.154 train acc: 0.938\n",
      "[131,     4] train loss: 0.129 train acc: 0.945\n",
      "[131,     5] train loss: 0.101 train acc: 0.949\n",
      "[131,     6] train loss: 0.137 train acc: 0.949\n",
      "[131,     7] train loss: 0.126 train acc: 0.961\n",
      "[131,     8] train loss: 0.148 train acc: 0.957\n",
      "[131,     9] train loss: 0.152 train acc: 0.938\n",
      "[131,    10] train loss: 0.125 train acc: 0.949\n",
      "[131,    11] train loss: 0.203 train acc: 0.930\n",
      "[131,    12] train loss: 0.157 train acc: 0.938\n",
      "[131,    13] train loss: 0.188 train acc: 0.934\n",
      "[131,    14] train loss: 0.162 train acc: 0.934\n",
      "[131,    15] train loss: 0.209 train acc: 0.918\n",
      "[131,    16] train loss: 0.188 train acc: 0.926\n",
      "[131,    17] train loss: 0.175 train acc: 0.938\n",
      "[131,    18] train loss: 0.134 train acc: 0.953\n",
      "[131,    19] train loss: 0.203 train acc: 0.914\n",
      "[131,    20] train loss: 0.123 train acc: 0.955\n",
      "[131] val loss: 0.050 val acc: 1.000\n",
      "[132,     1] train loss: 0.151 train acc: 0.945\n",
      "[132,     2] train loss: 0.113 train acc: 0.957\n",
      "[132,     3] train loss: 0.172 train acc: 0.926\n",
      "[132,     4] train loss: 0.114 train acc: 0.957\n",
      "[132,     5] train loss: 0.151 train acc: 0.930\n",
      "[132,     6] train loss: 0.146 train acc: 0.945\n",
      "[132,     7] train loss: 0.116 train acc: 0.945\n",
      "[132,     8] train loss: 0.167 train acc: 0.953\n",
      "[132,     9] train loss: 0.174 train acc: 0.930\n",
      "[132,    10] train loss: 0.181 train acc: 0.945\n",
      "[132,    11] train loss: 0.137 train acc: 0.949\n",
      "[132,    12] train loss: 0.199 train acc: 0.926\n",
      "[132,    13] train loss: 0.107 train acc: 0.953\n",
      "[132,    14] train loss: 0.091 train acc: 0.980\n",
      "[132,    15] train loss: 0.160 train acc: 0.930\n",
      "[132,    16] train loss: 0.199 train acc: 0.914\n",
      "[132,    17] train loss: 0.160 train acc: 0.941\n",
      "[132,    18] train loss: 0.132 train acc: 0.953\n",
      "[132,    19] train loss: 0.176 train acc: 0.922\n",
      "[132,    20] train loss: 0.137 train acc: 0.948\n",
      "[132] val loss: 0.056 val acc: 1.000\n",
      "[133,     1] train loss: 0.138 train acc: 0.945\n",
      "[133,     2] train loss: 0.149 train acc: 0.953\n",
      "[133,     3] train loss: 0.165 train acc: 0.930\n",
      "[133,     4] train loss: 0.113 train acc: 0.961\n",
      "[133,     5] train loss: 0.206 train acc: 0.930\n",
      "[133,     6] train loss: 0.169 train acc: 0.934\n",
      "[133,     7] train loss: 0.176 train acc: 0.926\n",
      "[133,     8] train loss: 0.125 train acc: 0.953\n",
      "[133,     9] train loss: 0.140 train acc: 0.938\n",
      "[133,    10] train loss: 0.133 train acc: 0.945\n",
      "[133,    11] train loss: 0.214 train acc: 0.930\n",
      "[133,    12] train loss: 0.114 train acc: 0.965\n",
      "[133,    13] train loss: 0.184 train acc: 0.930\n",
      "[133,    14] train loss: 0.174 train acc: 0.918\n",
      "[133,    15] train loss: 0.131 train acc: 0.938\n",
      "[133,    16] train loss: 0.118 train acc: 0.953\n",
      "[133,    17] train loss: 0.162 train acc: 0.945\n",
      "[133,    18] train loss: 0.134 train acc: 0.930\n",
      "[133,    19] train loss: 0.192 train acc: 0.918\n",
      "[133,    20] train loss: 0.155 train acc: 0.929\n",
      "[133] val loss: 0.053 val acc: 1.000\n",
      "[134,     1] train loss: 0.137 train acc: 0.949\n",
      "[134,     2] train loss: 0.109 train acc: 0.957\n",
      "[134,     3] train loss: 0.136 train acc: 0.957\n",
      "[134,     4] train loss: 0.143 train acc: 0.941\n",
      "[134,     5] train loss: 0.142 train acc: 0.930\n",
      "[134,     6] train loss: 0.171 train acc: 0.938\n",
      "[134,     7] train loss: 0.163 train acc: 0.934\n",
      "[134,     8] train loss: 0.148 train acc: 0.949\n",
      "[134,     9] train loss: 0.125 train acc: 0.957\n",
      "[134,    10] train loss: 0.115 train acc: 0.949\n",
      "[134,    11] train loss: 0.151 train acc: 0.926\n",
      "[134,    12] train loss: 0.178 train acc: 0.918\n",
      "[134,    13] train loss: 0.137 train acc: 0.957\n",
      "[134,    14] train loss: 0.151 train acc: 0.949\n",
      "[134,    15] train loss: 0.160 train acc: 0.941\n",
      "[134,    16] train loss: 0.106 train acc: 0.957\n",
      "[134,    17] train loss: 0.177 train acc: 0.918\n",
      "[134,    18] train loss: 0.214 train acc: 0.934\n",
      "[134,    19] train loss: 0.121 train acc: 0.949\n",
      "[134,    20] train loss: 0.195 train acc: 0.929\n",
      "[134] val loss: 0.046 val acc: 1.000\n",
      "[135,     1] train loss: 0.164 train acc: 0.953\n",
      "[135,     2] train loss: 0.167 train acc: 0.926\n",
      "[135,     3] train loss: 0.139 train acc: 0.926\n",
      "[135,     4] train loss: 0.213 train acc: 0.926\n",
      "[135,     5] train loss: 0.111 train acc: 0.957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[135,     6] train loss: 0.120 train acc: 0.945\n",
      "[135,     7] train loss: 0.184 train acc: 0.922\n",
      "[135,     8] train loss: 0.151 train acc: 0.949\n",
      "[135,     9] train loss: 0.125 train acc: 0.938\n",
      "[135,    10] train loss: 0.141 train acc: 0.949\n",
      "[135,    11] train loss: 0.224 train acc: 0.906\n",
      "[135,    12] train loss: 0.128 train acc: 0.961\n",
      "[135,    13] train loss: 0.155 train acc: 0.941\n",
      "[135,    14] train loss: 0.215 train acc: 0.918\n",
      "[135,    15] train loss: 0.176 train acc: 0.934\n",
      "[135,    16] train loss: 0.151 train acc: 0.930\n",
      "[135,    17] train loss: 0.163 train acc: 0.934\n",
      "[135,    18] train loss: 0.165 train acc: 0.941\n",
      "[135,    19] train loss: 0.112 train acc: 0.957\n",
      "[135,    20] train loss: 0.128 train acc: 0.935\n",
      "[135] val loss: 0.056 val acc: 1.000\n",
      "[136,     1] train loss: 0.116 train acc: 0.945\n",
      "[136,     2] train loss: 0.128 train acc: 0.941\n",
      "[136,     3] train loss: 0.211 train acc: 0.918\n",
      "[136,     4] train loss: 0.137 train acc: 0.945\n",
      "[136,     5] train loss: 0.151 train acc: 0.945\n",
      "[136,     6] train loss: 0.135 train acc: 0.953\n",
      "[136,     7] train loss: 0.126 train acc: 0.941\n",
      "[136,     8] train loss: 0.173 train acc: 0.930\n",
      "[136,     9] train loss: 0.129 train acc: 0.953\n",
      "[136,    10] train loss: 0.144 train acc: 0.941\n",
      "[136,    11] train loss: 0.167 train acc: 0.930\n",
      "[136,    12] train loss: 0.163 train acc: 0.934\n",
      "[136,    13] train loss: 0.124 train acc: 0.930\n",
      "[136,    14] train loss: 0.115 train acc: 0.945\n",
      "[136,    15] train loss: 0.128 train acc: 0.945\n",
      "[136,    16] train loss: 0.143 train acc: 0.957\n",
      "[136,    17] train loss: 0.150 train acc: 0.930\n",
      "[136,    18] train loss: 0.167 train acc: 0.938\n",
      "[136,    19] train loss: 0.169 train acc: 0.938\n",
      "[136,    20] train loss: 0.165 train acc: 0.948\n",
      "[136] val loss: 0.048 val acc: 1.000\n",
      "[137,     1] train loss: 0.125 train acc: 0.945\n",
      "[137,     2] train loss: 0.143 train acc: 0.957\n",
      "[137,     3] train loss: 0.173 train acc: 0.930\n",
      "[137,     4] train loss: 0.132 train acc: 0.949\n",
      "[137,     5] train loss: 0.153 train acc: 0.941\n",
      "[137,     6] train loss: 0.163 train acc: 0.934\n",
      "[137,     7] train loss: 0.142 train acc: 0.938\n",
      "[137,     8] train loss: 0.158 train acc: 0.941\n",
      "[137,     9] train loss: 0.121 train acc: 0.949\n",
      "[137,    10] train loss: 0.173 train acc: 0.934\n",
      "[137,    11] train loss: 0.167 train acc: 0.918\n",
      "[137,    12] train loss: 0.127 train acc: 0.949\n",
      "[137,    13] train loss: 0.121 train acc: 0.953\n",
      "[137,    14] train loss: 0.173 train acc: 0.938\n",
      "[137,    15] train loss: 0.110 train acc: 0.957\n",
      "[137,    16] train loss: 0.159 train acc: 0.934\n",
      "[137,    17] train loss: 0.160 train acc: 0.938\n",
      "[137,    18] train loss: 0.127 train acc: 0.957\n",
      "[137,    19] train loss: 0.145 train acc: 0.945\n",
      "[137,    20] train loss: 0.204 train acc: 0.929\n",
      "[137] val loss: 0.047 val acc: 1.000\n",
      "[138,     1] train loss: 0.099 train acc: 0.953\n",
      "[138,     2] train loss: 0.161 train acc: 0.930\n",
      "[138,     3] train loss: 0.105 train acc: 0.961\n",
      "[138,     4] train loss: 0.175 train acc: 0.941\n",
      "[138,     5] train loss: 0.160 train acc: 0.941\n",
      "[138,     6] train loss: 0.157 train acc: 0.941\n",
      "[138,     7] train loss: 0.121 train acc: 0.965\n",
      "[138,     8] train loss: 0.143 train acc: 0.938\n",
      "[138,     9] train loss: 0.172 train acc: 0.938\n",
      "[138,    10] train loss: 0.127 train acc: 0.945\n",
      "[138,    11] train loss: 0.145 train acc: 0.941\n",
      "[138,    12] train loss: 0.154 train acc: 0.953\n",
      "[138,    13] train loss: 0.164 train acc: 0.938\n",
      "[138,    14] train loss: 0.137 train acc: 0.945\n",
      "[138,    15] train loss: 0.124 train acc: 0.941\n",
      "[138,    16] train loss: 0.162 train acc: 0.926\n",
      "[138,    17] train loss: 0.105 train acc: 0.973\n",
      "[138,    18] train loss: 0.184 train acc: 0.914\n",
      "[138,    19] train loss: 0.122 train acc: 0.945\n",
      "[138,    20] train loss: 0.107 train acc: 0.955\n",
      "[138] val loss: 0.048 val acc: 1.000\n",
      "[139,     1] train loss: 0.149 train acc: 0.938\n",
      "[139,     2] train loss: 0.173 train acc: 0.930\n",
      "[139,     3] train loss: 0.112 train acc: 0.953\n",
      "[139,     4] train loss: 0.164 train acc: 0.934\n",
      "[139,     5] train loss: 0.141 train acc: 0.949\n",
      "[139,     6] train loss: 0.127 train acc: 0.941\n",
      "[139,     7] train loss: 0.143 train acc: 0.934\n",
      "[139,     8] train loss: 0.192 train acc: 0.922\n",
      "[139,     9] train loss: 0.178 train acc: 0.918\n",
      "[139,    10] train loss: 0.150 train acc: 0.918\n",
      "[139,    11] train loss: 0.133 train acc: 0.957\n",
      "[139,    12] train loss: 0.130 train acc: 0.953\n",
      "[139,    13] train loss: 0.144 train acc: 0.945\n",
      "[139,    14] train loss: 0.175 train acc: 0.934\n",
      "[139,    15] train loss: 0.136 train acc: 0.957\n",
      "[139,    16] train loss: 0.135 train acc: 0.945\n",
      "[139,    17] train loss: 0.139 train acc: 0.930\n",
      "[139,    18] train loss: 0.121 train acc: 0.949\n",
      "[139,    19] train loss: 0.124 train acc: 0.957\n",
      "[139,    20] train loss: 0.152 train acc: 0.942\n",
      "[139] val loss: 0.041 val acc: 1.000\n",
      "[140,     1] train loss: 0.113 train acc: 0.957\n",
      "[140,     2] train loss: 0.118 train acc: 0.957\n",
      "[140,     3] train loss: 0.141 train acc: 0.953\n",
      "[140,     4] train loss: 0.145 train acc: 0.945\n",
      "[140,     5] train loss: 0.114 train acc: 0.965\n",
      "[140,     6] train loss: 0.132 train acc: 0.945\n",
      "[140,     7] train loss: 0.195 train acc: 0.918\n",
      "[140,     8] train loss: 0.100 train acc: 0.953\n",
      "[140,     9] train loss: 0.113 train acc: 0.961\n",
      "[140,    10] train loss: 0.131 train acc: 0.949\n",
      "[140,    11] train loss: 0.178 train acc: 0.938\n",
      "[140,    12] train loss: 0.114 train acc: 0.945\n",
      "[140,    13] train loss: 0.152 train acc: 0.941\n",
      "[140,    14] train loss: 0.141 train acc: 0.945\n",
      "[140,    15] train loss: 0.153 train acc: 0.945\n",
      "[140,    16] train loss: 0.129 train acc: 0.953\n",
      "[140,    17] train loss: 0.126 train acc: 0.941\n",
      "[140,    18] train loss: 0.192 train acc: 0.926\n",
      "[140,    19] train loss: 0.090 train acc: 0.969\n",
      "[140,    20] train loss: 0.139 train acc: 0.942\n",
      "[140] val loss: 0.038 val acc: 1.000\n",
      "[141,     1] train loss: 0.150 train acc: 0.941\n",
      "[141,     2] train loss: 0.148 train acc: 0.930\n",
      "[141,     3] train loss: 0.121 train acc: 0.957\n",
      "[141,     4] train loss: 0.152 train acc: 0.922\n",
      "[141,     5] train loss: 0.219 train acc: 0.934\n",
      "[141,     6] train loss: 0.109 train acc: 0.953\n",
      "[141,     7] train loss: 0.169 train acc: 0.930\n",
      "[141,     8] train loss: 0.113 train acc: 0.945\n",
      "[141,     9] train loss: 0.134 train acc: 0.941\n",
      "[141,    10] train loss: 0.094 train acc: 0.961\n",
      "[141,    11] train loss: 0.154 train acc: 0.914\n",
      "[141,    12] train loss: 0.128 train acc: 0.953\n",
      "[141,    13] train loss: 0.166 train acc: 0.953\n",
      "[141,    14] train loss: 0.116 train acc: 0.945\n",
      "[141,    15] train loss: 0.110 train acc: 0.953\n",
      "[141,    16] train loss: 0.139 train acc: 0.941\n",
      "[141,    17] train loss: 0.150 train acc: 0.949\n",
      "[141,    18] train loss: 0.139 train acc: 0.945\n",
      "[141,    19] train loss: 0.110 train acc: 0.953\n",
      "[141,    20] train loss: 0.213 train acc: 0.935\n",
      "[141] val loss: 0.038 val acc: 1.000\n",
      "[142,     1] train loss: 0.090 train acc: 0.965\n",
      "[142,     2] train loss: 0.116 train acc: 0.961\n",
      "[142,     3] train loss: 0.119 train acc: 0.953\n",
      "[142,     4] train loss: 0.125 train acc: 0.949\n",
      "[142,     5] train loss: 0.122 train acc: 0.949\n",
      "[142,     6] train loss: 0.207 train acc: 0.930\n",
      "[142,     7] train loss: 0.137 train acc: 0.938\n",
      "[142,     8] train loss: 0.099 train acc: 0.949\n",
      "[142,     9] train loss: 0.195 train acc: 0.934\n",
      "[142,    10] train loss: 0.132 train acc: 0.949\n",
      "[142,    11] train loss: 0.164 train acc: 0.930\n",
      "[142,    12] train loss: 0.159 train acc: 0.926\n",
      "[142,    13] train loss: 0.136 train acc: 0.930\n",
      "[142,    14] train loss: 0.185 train acc: 0.906\n",
      "[142,    15] train loss: 0.091 train acc: 0.977\n",
      "[142,    16] train loss: 0.082 train acc: 0.965\n",
      "[142,    17] train loss: 0.129 train acc: 0.949\n",
      "[142,    18] train loss: 0.130 train acc: 0.945\n",
      "[142,    19] train loss: 0.162 train acc: 0.938\n",
      "[142,    20] train loss: 0.162 train acc: 0.935\n",
      "[142] val loss: 0.041 val acc: 1.000\n",
      "[143,     1] train loss: 0.135 train acc: 0.949\n",
      "[143,     2] train loss: 0.158 train acc: 0.941\n",
      "[143,     3] train loss: 0.157 train acc: 0.945\n",
      "[143,     4] train loss: 0.130 train acc: 0.934\n",
      "[143,     5] train loss: 0.108 train acc: 0.973\n",
      "[143,     6] train loss: 0.120 train acc: 0.953\n",
      "[143,     7] train loss: 0.131 train acc: 0.941\n",
      "[143,     8] train loss: 0.126 train acc: 0.945\n",
      "[143,     9] train loss: 0.155 train acc: 0.926\n",
      "[143,    10] train loss: 0.209 train acc: 0.914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[143,    11] train loss: 0.141 train acc: 0.945\n",
      "[143,    12] train loss: 0.112 train acc: 0.965\n",
      "[143,    13] train loss: 0.144 train acc: 0.949\n",
      "[143,    14] train loss: 0.141 train acc: 0.945\n",
      "[143,    15] train loss: 0.154 train acc: 0.949\n",
      "[143,    16] train loss: 0.130 train acc: 0.957\n",
      "[143,    17] train loss: 0.216 train acc: 0.918\n",
      "[143,    18] train loss: 0.118 train acc: 0.953\n",
      "[143,    19] train loss: 0.148 train acc: 0.949\n",
      "[143,    20] train loss: 0.075 train acc: 0.981\n",
      "[143] val loss: 0.042 val acc: 1.000\n",
      "[144,     1] train loss: 0.146 train acc: 0.938\n",
      "[144,     2] train loss: 0.143 train acc: 0.941\n",
      "[144,     3] train loss: 0.082 train acc: 0.965\n",
      "[144,     4] train loss: 0.147 train acc: 0.926\n",
      "[144,     5] train loss: 0.162 train acc: 0.941\n",
      "[144,     6] train loss: 0.149 train acc: 0.961\n",
      "[144,     7] train loss: 0.145 train acc: 0.945\n",
      "[144,     8] train loss: 0.162 train acc: 0.945\n",
      "[144,     9] train loss: 0.122 train acc: 0.949\n",
      "[144,    10] train loss: 0.120 train acc: 0.957\n",
      "[144,    11] train loss: 0.157 train acc: 0.930\n",
      "[144,    12] train loss: 0.093 train acc: 0.961\n",
      "[144,    13] train loss: 0.148 train acc: 0.949\n",
      "[144,    14] train loss: 0.161 train acc: 0.949\n",
      "[144,    15] train loss: 0.147 train acc: 0.930\n",
      "[144,    16] train loss: 0.159 train acc: 0.953\n",
      "[144,    17] train loss: 0.134 train acc: 0.945\n",
      "[144,    18] train loss: 0.127 train acc: 0.941\n",
      "[144,    19] train loss: 0.159 train acc: 0.930\n",
      "[144,    20] train loss: 0.082 train acc: 0.955\n",
      "[144] val loss: 0.036 val acc: 1.000\n",
      "[145,     1] train loss: 0.127 train acc: 0.961\n",
      "[145,     2] train loss: 0.132 train acc: 0.938\n",
      "[145,     3] train loss: 0.132 train acc: 0.949\n",
      "[145,     4] train loss: 0.162 train acc: 0.941\n",
      "[145,     5] train loss: 0.128 train acc: 0.965\n",
      "[145,     6] train loss: 0.198 train acc: 0.930\n",
      "[145,     7] train loss: 0.134 train acc: 0.941\n",
      "[145,     8] train loss: 0.116 train acc: 0.945\n",
      "[145,     9] train loss: 0.136 train acc: 0.949\n",
      "[145,    10] train loss: 0.192 train acc: 0.945\n",
      "[145,    11] train loss: 0.114 train acc: 0.953\n",
      "[145,    12] train loss: 0.136 train acc: 0.945\n",
      "[145,    13] train loss: 0.114 train acc: 0.957\n",
      "[145,    14] train loss: 0.165 train acc: 0.941\n",
      "[145,    15] train loss: 0.186 train acc: 0.949\n",
      "[145,    16] train loss: 0.098 train acc: 0.961\n",
      "[145,    17] train loss: 0.130 train acc: 0.945\n",
      "[145,    18] train loss: 0.113 train acc: 0.945\n",
      "[145,    19] train loss: 0.081 train acc: 0.965\n",
      "[145,    20] train loss: 0.079 train acc: 0.974\n",
      "[145] val loss: 0.038 val acc: 1.000\n",
      "[146,     1] train loss: 0.148 train acc: 0.926\n",
      "[146,     2] train loss: 0.137 train acc: 0.965\n",
      "[146,     3] train loss: 0.176 train acc: 0.922\n",
      "[146,     4] train loss: 0.149 train acc: 0.957\n",
      "[146,     5] train loss: 0.127 train acc: 0.953\n",
      "[146,     6] train loss: 0.105 train acc: 0.977\n",
      "[146,     7] train loss: 0.104 train acc: 0.965\n",
      "[146,     8] train loss: 0.130 train acc: 0.949\n",
      "[146,     9] train loss: 0.100 train acc: 0.965\n",
      "[146,    10] train loss: 0.152 train acc: 0.930\n",
      "[146,    11] train loss: 0.140 train acc: 0.945\n",
      "[146,    12] train loss: 0.122 train acc: 0.961\n",
      "[146,    13] train loss: 0.163 train acc: 0.938\n",
      "[146,    14] train loss: 0.145 train acc: 0.938\n",
      "[146,    15] train loss: 0.130 train acc: 0.945\n",
      "[146,    16] train loss: 0.107 train acc: 0.961\n",
      "[146,    17] train loss: 0.108 train acc: 0.961\n",
      "[146,    18] train loss: 0.096 train acc: 0.965\n",
      "[146,    19] train loss: 0.133 train acc: 0.949\n",
      "[146,    20] train loss: 0.105 train acc: 0.961\n",
      "[146] val loss: 0.033 val acc: 1.000\n",
      "[147,     1] train loss: 0.179 train acc: 0.926\n",
      "[147,     2] train loss: 0.127 train acc: 0.949\n",
      "[147,     3] train loss: 0.114 train acc: 0.957\n",
      "[147,     4] train loss: 0.111 train acc: 0.957\n",
      "[147,     5] train loss: 0.136 train acc: 0.945\n",
      "[147,     6] train loss: 0.109 train acc: 0.961\n",
      "[147,     7] train loss: 0.132 train acc: 0.945\n",
      "[147,     8] train loss: 0.186 train acc: 0.941\n",
      "[147,     9] train loss: 0.138 train acc: 0.922\n",
      "[147,    10] train loss: 0.093 train acc: 0.961\n",
      "[147,    11] train loss: 0.175 train acc: 0.934\n",
      "[147,    12] train loss: 0.118 train acc: 0.965\n",
      "[147,    13] train loss: 0.148 train acc: 0.938\n",
      "[147,    14] train loss: 0.122 train acc: 0.949\n",
      "[147,    15] train loss: 0.132 train acc: 0.953\n",
      "[147,    16] train loss: 0.178 train acc: 0.930\n",
      "[147,    17] train loss: 0.162 train acc: 0.938\n",
      "[147,    18] train loss: 0.173 train acc: 0.945\n",
      "[147,    19] train loss: 0.143 train acc: 0.941\n",
      "[147,    20] train loss: 0.191 train acc: 0.942\n",
      "[147] val loss: 0.035 val acc: 1.000\n",
      "[148,     1] train loss: 0.100 train acc: 0.957\n",
      "[148,     2] train loss: 0.171 train acc: 0.938\n",
      "[148,     3] train loss: 0.125 train acc: 0.957\n",
      "[148,     4] train loss: 0.096 train acc: 0.965\n",
      "[148,     5] train loss: 0.102 train acc: 0.969\n",
      "[148,     6] train loss: 0.135 train acc: 0.941\n",
      "[148,     7] train loss: 0.137 train acc: 0.949\n",
      "[148,     8] train loss: 0.123 train acc: 0.941\n",
      "[148,     9] train loss: 0.127 train acc: 0.941\n",
      "[148,    10] train loss: 0.111 train acc: 0.957\n",
      "[148,    11] train loss: 0.133 train acc: 0.949\n",
      "[148,    12] train loss: 0.116 train acc: 0.941\n",
      "[148,    13] train loss: 0.098 train acc: 0.953\n",
      "[148,    14] train loss: 0.084 train acc: 0.965\n",
      "[148,    15] train loss: 0.124 train acc: 0.953\n",
      "[148,    16] train loss: 0.152 train acc: 0.957\n",
      "[148,    17] train loss: 0.108 train acc: 0.969\n",
      "[148,    18] train loss: 0.172 train acc: 0.930\n",
      "[148,    19] train loss: 0.157 train acc: 0.938\n",
      "[148,    20] train loss: 0.162 train acc: 0.942\n",
      "[148] val loss: 0.031 val acc: 1.000\n",
      "[149,     1] train loss: 0.149 train acc: 0.938\n",
      "[149,     2] train loss: 0.142 train acc: 0.949\n",
      "[149,     3] train loss: 0.129 train acc: 0.949\n",
      "[149,     4] train loss: 0.113 train acc: 0.953\n",
      "[149,     5] train loss: 0.151 train acc: 0.941\n",
      "[149,     6] train loss: 0.112 train acc: 0.957\n",
      "[149,     7] train loss: 0.113 train acc: 0.938\n",
      "[149,     8] train loss: 0.114 train acc: 0.949\n",
      "[149,     9] train loss: 0.100 train acc: 0.969\n",
      "[149,    10] train loss: 0.109 train acc: 0.957\n",
      "[149,    11] train loss: 0.100 train acc: 0.969\n",
      "[149,    12] train loss: 0.135 train acc: 0.949\n",
      "[149,    13] train loss: 0.169 train acc: 0.945\n",
      "[149,    14] train loss: 0.151 train acc: 0.941\n",
      "[149,    15] train loss: 0.124 train acc: 0.957\n",
      "[149,    16] train loss: 0.158 train acc: 0.945\n",
      "[149,    17] train loss: 0.092 train acc: 0.965\n",
      "[149,    18] train loss: 0.174 train acc: 0.938\n",
      "[149,    19] train loss: 0.149 train acc: 0.938\n",
      "[149,    20] train loss: 0.198 train acc: 0.935\n",
      "[149] val loss: 0.032 val acc: 1.000\n",
      "[150,     1] train loss: 0.138 train acc: 0.949\n",
      "[150,     2] train loss: 0.127 train acc: 0.961\n",
      "[150,     3] train loss: 0.099 train acc: 0.953\n",
      "[150,     4] train loss: 0.158 train acc: 0.941\n",
      "[150,     5] train loss: 0.156 train acc: 0.930\n",
      "[150,     6] train loss: 0.115 train acc: 0.973\n",
      "[150,     7] train loss: 0.105 train acc: 0.953\n",
      "[150,     8] train loss: 0.171 train acc: 0.926\n",
      "[150,     9] train loss: 0.142 train acc: 0.930\n",
      "[150,    10] train loss: 0.138 train acc: 0.938\n",
      "[150,    11] train loss: 0.108 train acc: 0.977\n",
      "[150,    12] train loss: 0.157 train acc: 0.941\n",
      "[150,    13] train loss: 0.121 train acc: 0.961\n",
      "[150,    14] train loss: 0.079 train acc: 0.969\n",
      "[150,    15] train loss: 0.117 train acc: 0.941\n",
      "[150,    16] train loss: 0.144 train acc: 0.945\n",
      "[150,    17] train loss: 0.119 train acc: 0.938\n",
      "[150,    18] train loss: 0.115 train acc: 0.945\n",
      "[150,    19] train loss: 0.161 train acc: 0.934\n",
      "[150,    20] train loss: 0.145 train acc: 0.929\n",
      "[150] val loss: 0.037 val acc: 1.000\n",
      "[151,     1] train loss: 0.141 train acc: 0.953\n",
      "[151,     2] train loss: 0.108 train acc: 0.969\n",
      "[151,     3] train loss: 0.096 train acc: 0.969\n",
      "[151,     4] train loss: 0.134 train acc: 0.945\n",
      "[151,     5] train loss: 0.102 train acc: 0.957\n",
      "[151,     6] train loss: 0.146 train acc: 0.941\n",
      "[151,     7] train loss: 0.168 train acc: 0.941\n",
      "[151,     8] train loss: 0.134 train acc: 0.938\n",
      "[151,     9] train loss: 0.099 train acc: 0.969\n",
      "[151,    10] train loss: 0.106 train acc: 0.953\n",
      "[151,    11] train loss: 0.162 train acc: 0.934\n",
      "[151,    12] train loss: 0.211 train acc: 0.922\n",
      "[151,    13] train loss: 0.108 train acc: 0.953\n",
      "[151,    14] train loss: 0.136 train acc: 0.949\n",
      "[151,    15] train loss: 0.146 train acc: 0.934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[151,    16] train loss: 0.119 train acc: 0.953\n",
      "[151,    17] train loss: 0.135 train acc: 0.941\n",
      "[151,    18] train loss: 0.197 train acc: 0.926\n",
      "[151,    19] train loss: 0.142 train acc: 0.938\n",
      "[151,    20] train loss: 0.112 train acc: 0.974\n",
      "[151] val loss: 0.036 val acc: 1.000\n",
      "[152,     1] train loss: 0.125 train acc: 0.953\n",
      "[152,     2] train loss: 0.084 train acc: 0.973\n",
      "[152,     3] train loss: 0.184 train acc: 0.918\n",
      "[152,     4] train loss: 0.087 train acc: 0.969\n",
      "[152,     5] train loss: 0.116 train acc: 0.961\n",
      "[152,     6] train loss: 0.104 train acc: 0.961\n",
      "[152,     7] train loss: 0.103 train acc: 0.961\n",
      "[152,     8] train loss: 0.094 train acc: 0.953\n",
      "[152,     9] train loss: 0.120 train acc: 0.961\n",
      "[152,    10] train loss: 0.144 train acc: 0.926\n",
      "[152,    11] train loss: 0.093 train acc: 0.969\n",
      "[152,    12] train loss: 0.129 train acc: 0.938\n",
      "[152,    13] train loss: 0.151 train acc: 0.953\n",
      "[152,    14] train loss: 0.081 train acc: 0.980\n",
      "[152,    15] train loss: 0.110 train acc: 0.953\n",
      "[152,    16] train loss: 0.153 train acc: 0.934\n",
      "[152,    17] train loss: 0.098 train acc: 0.961\n",
      "[152,    18] train loss: 0.124 train acc: 0.938\n",
      "[152,    19] train loss: 0.139 train acc: 0.949\n",
      "[152,    20] train loss: 0.135 train acc: 0.955\n",
      "[152] val loss: 0.026 val acc: 1.000\n",
      "[153,     1] train loss: 0.123 train acc: 0.957\n",
      "[153,     2] train loss: 0.173 train acc: 0.930\n",
      "[153,     3] train loss: 0.122 train acc: 0.953\n",
      "[153,     4] train loss: 0.094 train acc: 0.965\n",
      "[153,     5] train loss: 0.159 train acc: 0.941\n",
      "[153,     6] train loss: 0.100 train acc: 0.965\n",
      "[153,     7] train loss: 0.143 train acc: 0.934\n",
      "[153,     8] train loss: 0.080 train acc: 0.973\n",
      "[153,     9] train loss: 0.178 train acc: 0.945\n",
      "[153,    10] train loss: 0.140 train acc: 0.930\n",
      "[153,    11] train loss: 0.109 train acc: 0.949\n",
      "[153,    12] train loss: 0.153 train acc: 0.941\n",
      "[153,    13] train loss: 0.114 train acc: 0.941\n",
      "[153,    14] train loss: 0.120 train acc: 0.953\n",
      "[153,    15] train loss: 0.137 train acc: 0.953\n",
      "[153,    16] train loss: 0.162 train acc: 0.949\n",
      "[153,    17] train loss: 0.168 train acc: 0.934\n",
      "[153,    18] train loss: 0.101 train acc: 0.953\n",
      "[153,    19] train loss: 0.113 train acc: 0.949\n",
      "[153,    20] train loss: 0.129 train acc: 0.961\n",
      "[153] val loss: 0.039 val acc: 1.000\n",
      "[154,     1] train loss: 0.143 train acc: 0.934\n",
      "[154,     2] train loss: 0.164 train acc: 0.938\n",
      "[154,     3] train loss: 0.123 train acc: 0.953\n",
      "[154,     4] train loss: 0.118 train acc: 0.949\n",
      "[154,     5] train loss: 0.121 train acc: 0.965\n",
      "[154,     6] train loss: 0.093 train acc: 0.969\n",
      "[154,     7] train loss: 0.134 train acc: 0.953\n",
      "[154,     8] train loss: 0.146 train acc: 0.941\n",
      "[154,     9] train loss: 0.152 train acc: 0.945\n",
      "[154,    10] train loss: 0.147 train acc: 0.934\n",
      "[154,    11] train loss: 0.128 train acc: 0.938\n",
      "[154,    12] train loss: 0.107 train acc: 0.961\n",
      "[154,    13] train loss: 0.143 train acc: 0.945\n",
      "[154,    14] train loss: 0.138 train acc: 0.945\n",
      "[154,    15] train loss: 0.097 train acc: 0.973\n",
      "[154,    16] train loss: 0.115 train acc: 0.965\n",
      "[154,    17] train loss: 0.151 train acc: 0.941\n",
      "[154,    18] train loss: 0.159 train acc: 0.938\n",
      "[154,    19] train loss: 0.115 train acc: 0.969\n",
      "[154,    20] train loss: 0.064 train acc: 0.981\n",
      "[154] val loss: 0.038 val acc: 1.000\n",
      "[155,     1] train loss: 0.120 train acc: 0.969\n",
      "[155,     2] train loss: 0.166 train acc: 0.918\n",
      "[155,     3] train loss: 0.137 train acc: 0.938\n",
      "[155,     4] train loss: 0.091 train acc: 0.961\n",
      "[155,     5] train loss: 0.139 train acc: 0.957\n",
      "[155,     6] train loss: 0.146 train acc: 0.934\n",
      "[155,     7] train loss: 0.078 train acc: 0.969\n",
      "[155,     8] train loss: 0.083 train acc: 0.977\n",
      "[155,     9] train loss: 0.157 train acc: 0.949\n",
      "[155,    10] train loss: 0.092 train acc: 0.961\n",
      "[155,    11] train loss: 0.113 train acc: 0.961\n",
      "[155,    12] train loss: 0.095 train acc: 0.965\n",
      "[155,    13] train loss: 0.109 train acc: 0.957\n",
      "[155,    14] train loss: 0.127 train acc: 0.941\n",
      "[155,    15] train loss: 0.122 train acc: 0.949\n",
      "[155,    16] train loss: 0.111 train acc: 0.957\n",
      "[155,    17] train loss: 0.132 train acc: 0.961\n",
      "[155,    18] train loss: 0.068 train acc: 0.969\n",
      "[155,    19] train loss: 0.121 train acc: 0.965\n",
      "[155,    20] train loss: 0.094 train acc: 0.948\n",
      "[155] val loss: 0.027 val acc: 1.000\n",
      "[156,     1] train loss: 0.078 train acc: 0.977\n",
      "[156,     2] train loss: 0.102 train acc: 0.953\n",
      "[156,     3] train loss: 0.088 train acc: 0.961\n",
      "[156,     4] train loss: 0.155 train acc: 0.934\n",
      "[156,     5] train loss: 0.155 train acc: 0.938\n",
      "[156,     6] train loss: 0.115 train acc: 0.945\n",
      "[156,     7] train loss: 0.085 train acc: 0.973\n",
      "[156,     8] train loss: 0.098 train acc: 0.953\n",
      "[156,     9] train loss: 0.119 train acc: 0.953\n",
      "[156,    10] train loss: 0.131 train acc: 0.957\n",
      "[156,    11] train loss: 0.104 train acc: 0.961\n",
      "[156,    12] train loss: 0.126 train acc: 0.957\n",
      "[156,    13] train loss: 0.084 train acc: 0.973\n",
      "[156,    14] train loss: 0.089 train acc: 0.969\n",
      "[156,    15] train loss: 0.102 train acc: 0.965\n",
      "[156,    16] train loss: 0.114 train acc: 0.957\n",
      "[156,    17] train loss: 0.102 train acc: 0.961\n",
      "[156,    18] train loss: 0.090 train acc: 0.965\n",
      "[156,    19] train loss: 0.158 train acc: 0.930\n",
      "[156,    20] train loss: 0.113 train acc: 0.955\n",
      "[156] val loss: 0.021 val acc: 1.000\n",
      "[157,     1] train loss: 0.154 train acc: 0.953\n",
      "[157,     2] train loss: 0.111 train acc: 0.961\n",
      "[157,     3] train loss: 0.091 train acc: 0.961\n",
      "[157,     4] train loss: 0.135 train acc: 0.953\n",
      "[157,     5] train loss: 0.136 train acc: 0.934\n",
      "[157,     6] train loss: 0.107 train acc: 0.953\n",
      "[157,     7] train loss: 0.153 train acc: 0.965\n",
      "[157,     8] train loss: 0.067 train acc: 0.977\n",
      "[157,     9] train loss: 0.117 train acc: 0.941\n",
      "[157,    10] train loss: 0.109 train acc: 0.949\n",
      "[157,    11] train loss: 0.109 train acc: 0.957\n",
      "[157,    12] train loss: 0.106 train acc: 0.957\n",
      "[157,    13] train loss: 0.141 train acc: 0.945\n",
      "[157,    14] train loss: 0.145 train acc: 0.941\n",
      "[157,    15] train loss: 0.092 train acc: 0.957\n",
      "[157,    16] train loss: 0.120 train acc: 0.957\n",
      "[157,    17] train loss: 0.099 train acc: 0.961\n",
      "[157,    18] train loss: 0.167 train acc: 0.926\n",
      "[157,    19] train loss: 0.157 train acc: 0.961\n",
      "[157,    20] train loss: 0.088 train acc: 0.968\n",
      "[157] val loss: 0.026 val acc: 1.000\n",
      "[158,     1] train loss: 0.120 train acc: 0.945\n",
      "[158,     2] train loss: 0.153 train acc: 0.945\n",
      "[158,     3] train loss: 0.096 train acc: 0.961\n",
      "[158,     4] train loss: 0.129 train acc: 0.945\n",
      "[158,     5] train loss: 0.192 train acc: 0.922\n",
      "[158,     6] train loss: 0.064 train acc: 0.977\n",
      "[158,     7] train loss: 0.105 train acc: 0.961\n",
      "[158,     8] train loss: 0.103 train acc: 0.957\n",
      "[158,     9] train loss: 0.125 train acc: 0.941\n",
      "[158,    10] train loss: 0.117 train acc: 0.941\n",
      "[158,    11] train loss: 0.101 train acc: 0.965\n",
      "[158,    12] train loss: 0.106 train acc: 0.961\n",
      "[158,    13] train loss: 0.109 train acc: 0.965\n",
      "[158,    14] train loss: 0.200 train acc: 0.922\n",
      "[158,    15] train loss: 0.069 train acc: 0.969\n",
      "[158,    16] train loss: 0.114 train acc: 0.961\n",
      "[158,    17] train loss: 0.105 train acc: 0.969\n",
      "[158,    18] train loss: 0.124 train acc: 0.957\n",
      "[158,    19] train loss: 0.145 train acc: 0.934\n",
      "[158,    20] train loss: 0.155 train acc: 0.942\n",
      "[158] val loss: 0.027 val acc: 1.000\n",
      "[159,     1] train loss: 0.147 train acc: 0.938\n",
      "[159,     2] train loss: 0.118 train acc: 0.941\n",
      "[159,     3] train loss: 0.156 train acc: 0.953\n",
      "[159,     4] train loss: 0.100 train acc: 0.957\n",
      "[159,     5] train loss: 0.111 train acc: 0.961\n",
      "[159,     6] train loss: 0.121 train acc: 0.926\n",
      "[159,     7] train loss: 0.180 train acc: 0.914\n",
      "[159,     8] train loss: 0.137 train acc: 0.949\n",
      "[159,     9] train loss: 0.160 train acc: 0.926\n",
      "[159,    10] train loss: 0.167 train acc: 0.930\n",
      "[159,    11] train loss: 0.106 train acc: 0.965\n",
      "[159,    12] train loss: 0.131 train acc: 0.938\n",
      "[159,    13] train loss: 0.100 train acc: 0.953\n",
      "[159,    14] train loss: 0.109 train acc: 0.953\n",
      "[159,    15] train loss: 0.092 train acc: 0.957\n",
      "[159,    16] train loss: 0.120 train acc: 0.965\n",
      "[159,    17] train loss: 0.103 train acc: 0.969\n",
      "[159,    18] train loss: 0.142 train acc: 0.941\n",
      "[159,    19] train loss: 0.082 train acc: 0.973\n",
      "[159,    20] train loss: 0.085 train acc: 0.968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[159] val loss: 0.031 val acc: 1.000\n",
      "[160,     1] train loss: 0.136 train acc: 0.949\n",
      "[160,     2] train loss: 0.098 train acc: 0.949\n",
      "[160,     3] train loss: 0.100 train acc: 0.949\n",
      "[160,     4] train loss: 0.093 train acc: 0.969\n",
      "[160,     5] train loss: 0.088 train acc: 0.980\n",
      "[160,     6] train loss: 0.148 train acc: 0.945\n",
      "[160,     7] train loss: 0.112 train acc: 0.949\n",
      "[160,     8] train loss: 0.121 train acc: 0.957\n",
      "[160,     9] train loss: 0.079 train acc: 0.961\n",
      "[160,    10] train loss: 0.147 train acc: 0.949\n",
      "[160,    11] train loss: 0.140 train acc: 0.930\n",
      "[160,    12] train loss: 0.071 train acc: 0.965\n",
      "[160,    13] train loss: 0.157 train acc: 0.949\n",
      "[160,    14] train loss: 0.114 train acc: 0.961\n",
      "[160,    15] train loss: 0.099 train acc: 0.957\n",
      "[160,    16] train loss: 0.078 train acc: 0.973\n",
      "[160,    17] train loss: 0.092 train acc: 0.965\n",
      "[160,    18] train loss: 0.081 train acc: 0.969\n",
      "[160,    19] train loss: 0.150 train acc: 0.949\n",
      "[160,    20] train loss: 0.133 train acc: 0.948\n",
      "[160] val loss: 0.024 val acc: 1.000\n",
      "[161,     1] train loss: 0.096 train acc: 0.961\n",
      "[161,     2] train loss: 0.069 train acc: 0.984\n",
      "[161,     3] train loss: 0.088 train acc: 0.965\n",
      "[161,     4] train loss: 0.106 train acc: 0.973\n",
      "[161,     5] train loss: 0.137 train acc: 0.965\n",
      "[161,     6] train loss: 0.126 train acc: 0.945\n",
      "[161,     7] train loss: 0.136 train acc: 0.938\n",
      "[161,     8] train loss: 0.080 train acc: 0.980\n",
      "[161,     9] train loss: 0.136 train acc: 0.945\n",
      "[161,    10] train loss: 0.142 train acc: 0.941\n",
      "[161,    11] train loss: 0.116 train acc: 0.973\n",
      "[161,    12] train loss: 0.094 train acc: 0.965\n",
      "[161,    13] train loss: 0.090 train acc: 0.969\n",
      "[161,    14] train loss: 0.087 train acc: 0.973\n",
      "[161,    15] train loss: 0.071 train acc: 0.977\n",
      "[161,    16] train loss: 0.146 train acc: 0.926\n",
      "[161,    17] train loss: 0.103 train acc: 0.957\n",
      "[161,    18] train loss: 0.159 train acc: 0.938\n",
      "[161,    19] train loss: 0.136 train acc: 0.961\n",
      "[161,    20] train loss: 0.085 train acc: 0.961\n",
      "[161] val loss: 0.022 val acc: 1.000\n",
      "[162,     1] train loss: 0.125 train acc: 0.961\n",
      "[162,     2] train loss: 0.174 train acc: 0.930\n",
      "[162,     3] train loss: 0.081 train acc: 0.969\n",
      "[162,     4] train loss: 0.136 train acc: 0.949\n",
      "[162,     5] train loss: 0.141 train acc: 0.941\n",
      "[162,     6] train loss: 0.128 train acc: 0.949\n",
      "[162,     7] train loss: 0.106 train acc: 0.953\n",
      "[162,     8] train loss: 0.124 train acc: 0.945\n",
      "[162,     9] train loss: 0.126 train acc: 0.941\n",
      "[162,    10] train loss: 0.137 train acc: 0.941\n",
      "[162,    11] train loss: 0.096 train acc: 0.957\n",
      "[162,    12] train loss: 0.139 train acc: 0.945\n",
      "[162,    13] train loss: 0.095 train acc: 0.961\n",
      "[162,    14] train loss: 0.091 train acc: 0.953\n",
      "[162,    15] train loss: 0.096 train acc: 0.961\n",
      "[162,    16] train loss: 0.128 train acc: 0.957\n",
      "[162,    17] train loss: 0.110 train acc: 0.969\n",
      "[162,    18] train loss: 0.090 train acc: 0.961\n",
      "[162,    19] train loss: 0.094 train acc: 0.965\n",
      "[162,    20] train loss: 0.125 train acc: 0.948\n",
      "[162] val loss: 0.024 val acc: 1.000\n",
      "[163,     1] train loss: 0.133 train acc: 0.945\n",
      "[163,     2] train loss: 0.140 train acc: 0.965\n",
      "[163,     3] train loss: 0.135 train acc: 0.949\n",
      "[163,     4] train loss: 0.106 train acc: 0.965\n",
      "[163,     5] train loss: 0.163 train acc: 0.922\n",
      "[163,     6] train loss: 0.066 train acc: 0.984\n",
      "[163,     7] train loss: 0.114 train acc: 0.965\n",
      "[163,     8] train loss: 0.140 train acc: 0.930\n",
      "[163,     9] train loss: 0.133 train acc: 0.941\n",
      "[163,    10] train loss: 0.093 train acc: 0.953\n",
      "[163,    11] train loss: 0.096 train acc: 0.973\n",
      "[163,    12] train loss: 0.089 train acc: 0.969\n",
      "[163,    13] train loss: 0.129 train acc: 0.961\n",
      "[163,    14] train loss: 0.114 train acc: 0.961\n",
      "[163,    15] train loss: 0.113 train acc: 0.953\n",
      "[163,    16] train loss: 0.114 train acc: 0.949\n",
      "[163,    17] train loss: 0.124 train acc: 0.934\n",
      "[163,    18] train loss: 0.163 train acc: 0.938\n",
      "[163,    19] train loss: 0.121 train acc: 0.965\n",
      "[163,    20] train loss: 0.135 train acc: 0.935\n",
      "[163] val loss: 0.026 val acc: 1.000\n",
      "[164,     1] train loss: 0.123 train acc: 0.949\n",
      "[164,     2] train loss: 0.127 train acc: 0.953\n",
      "[164,     3] train loss: 0.147 train acc: 0.930\n",
      "[164,     4] train loss: 0.127 train acc: 0.969\n",
      "[164,     5] train loss: 0.102 train acc: 0.949\n",
      "[164,     6] train loss: 0.117 train acc: 0.949\n",
      "[164,     7] train loss: 0.097 train acc: 0.961\n",
      "[164,     8] train loss: 0.077 train acc: 0.980\n",
      "[164,     9] train loss: 0.108 train acc: 0.949\n",
      "[164,    10] train loss: 0.088 train acc: 0.961\n",
      "[164,    11] train loss: 0.121 train acc: 0.957\n",
      "[164,    12] train loss: 0.144 train acc: 0.934\n",
      "[164,    13] train loss: 0.120 train acc: 0.961\n",
      "[164,    14] train loss: 0.085 train acc: 0.973\n",
      "[164,    15] train loss: 0.111 train acc: 0.969\n",
      "[164,    16] train loss: 0.130 train acc: 0.938\n",
      "[164,    17] train loss: 0.131 train acc: 0.945\n",
      "[164,    18] train loss: 0.163 train acc: 0.941\n",
      "[164,    19] train loss: 0.115 train acc: 0.949\n",
      "[164,    20] train loss: 0.072 train acc: 0.981\n",
      "[164] val loss: 0.023 val acc: 1.000\n",
      "[165,     1] train loss: 0.178 train acc: 0.941\n",
      "[165,     2] train loss: 0.085 train acc: 0.973\n",
      "[165,     3] train loss: 0.095 train acc: 0.965\n",
      "[165,     4] train loss: 0.105 train acc: 0.961\n",
      "[165,     5] train loss: 0.118 train acc: 0.957\n",
      "[165,     6] train loss: 0.078 train acc: 0.984\n",
      "[165,     7] train loss: 0.089 train acc: 0.957\n",
      "[165,     8] train loss: 0.126 train acc: 0.953\n",
      "[165,     9] train loss: 0.091 train acc: 0.977\n",
      "[165,    10] train loss: 0.096 train acc: 0.957\n",
      "[165,    11] train loss: 0.187 train acc: 0.941\n",
      "[165,    12] train loss: 0.117 train acc: 0.949\n",
      "[165,    13] train loss: 0.130 train acc: 0.957\n",
      "[165,    14] train loss: 0.122 train acc: 0.953\n",
      "[165,    15] train loss: 0.112 train acc: 0.941\n",
      "[165,    16] train loss: 0.134 train acc: 0.941\n",
      "[165,    17] train loss: 0.118 train acc: 0.945\n",
      "[165,    18] train loss: 0.137 train acc: 0.953\n",
      "[165,    19] train loss: 0.108 train acc: 0.957\n",
      "[165,    20] train loss: 0.159 train acc: 0.935\n",
      "[165] val loss: 0.026 val acc: 1.000\n",
      "[166,     1] train loss: 0.117 train acc: 0.949\n",
      "[166,     2] train loss: 0.156 train acc: 0.930\n",
      "[166,     3] train loss: 0.071 train acc: 0.977\n",
      "[166,     4] train loss: 0.092 train acc: 0.973\n",
      "[166,     5] train loss: 0.098 train acc: 0.965\n",
      "[166,     6] train loss: 0.137 train acc: 0.957\n",
      "[166,     7] train loss: 0.077 train acc: 0.973\n",
      "[166,     8] train loss: 0.114 train acc: 0.953\n",
      "[166,     9] train loss: 0.103 train acc: 0.957\n",
      "[166,    10] train loss: 0.087 train acc: 0.965\n",
      "[166,    11] train loss: 0.109 train acc: 0.957\n",
      "[166,    12] train loss: 0.145 train acc: 0.938\n",
      "[166,    13] train loss: 0.112 train acc: 0.957\n",
      "[166,    14] train loss: 0.137 train acc: 0.945\n",
      "[166,    15] train loss: 0.091 train acc: 0.961\n",
      "[166,    16] train loss: 0.088 train acc: 0.973\n",
      "[166,    17] train loss: 0.121 train acc: 0.949\n",
      "[166,    18] train loss: 0.110 train acc: 0.945\n",
      "[166,    19] train loss: 0.072 train acc: 0.977\n",
      "[166,    20] train loss: 0.133 train acc: 0.961\n",
      "[166] val loss: 0.025 val acc: 1.000\n",
      "[167,     1] train loss: 0.100 train acc: 0.965\n",
      "[167,     2] train loss: 0.120 train acc: 0.945\n",
      "[167,     3] train loss: 0.121 train acc: 0.957\n",
      "[167,     4] train loss: 0.134 train acc: 0.945\n",
      "[167,     5] train loss: 0.112 train acc: 0.953\n",
      "[167,     6] train loss: 0.108 train acc: 0.957\n",
      "[167,     7] train loss: 0.118 train acc: 0.957\n",
      "[167,     8] train loss: 0.117 train acc: 0.945\n",
      "[167,     9] train loss: 0.112 train acc: 0.965\n",
      "[167,    10] train loss: 0.120 train acc: 0.945\n",
      "[167,    11] train loss: 0.094 train acc: 0.957\n",
      "[167,    12] train loss: 0.122 train acc: 0.949\n",
      "[167,    13] train loss: 0.126 train acc: 0.961\n",
      "[167,    14] train loss: 0.108 train acc: 0.949\n",
      "[167,    15] train loss: 0.108 train acc: 0.961\n",
      "[167,    16] train loss: 0.154 train acc: 0.957\n",
      "[167,    17] train loss: 0.112 train acc: 0.953\n",
      "[167,    18] train loss: 0.111 train acc: 0.945\n",
      "[167,    19] train loss: 0.089 train acc: 0.969\n",
      "[167,    20] train loss: 0.108 train acc: 0.955\n",
      "[167] val loss: 0.025 val acc: 1.000\n",
      "[168,     1] train loss: 0.066 train acc: 0.980\n",
      "[168,     2] train loss: 0.104 train acc: 0.957\n",
      "[168,     3] train loss: 0.082 train acc: 0.969\n",
      "[168,     4] train loss: 0.111 train acc: 0.965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[168,     5] train loss: 0.135 train acc: 0.961\n",
      "[168,     6] train loss: 0.101 train acc: 0.961\n",
      "[168,     7] train loss: 0.094 train acc: 0.961\n",
      "[168,     8] train loss: 0.106 train acc: 0.953\n",
      "[168,     9] train loss: 0.107 train acc: 0.965\n",
      "[168,    10] train loss: 0.139 train acc: 0.941\n",
      "[168,    11] train loss: 0.186 train acc: 0.922\n",
      "[168,    12] train loss: 0.117 train acc: 0.953\n",
      "[168,    13] train loss: 0.128 train acc: 0.945\n",
      "[168,    14] train loss: 0.113 train acc: 0.961\n",
      "[168,    15] train loss: 0.117 train acc: 0.949\n",
      "[168,    16] train loss: 0.072 train acc: 0.977\n",
      "[168,    17] train loss: 0.092 train acc: 0.961\n",
      "[168,    18] train loss: 0.081 train acc: 0.969\n",
      "[168,    19] train loss: 0.168 train acc: 0.934\n",
      "[168,    20] train loss: 0.093 train acc: 0.968\n",
      "[168] val loss: 0.023 val acc: 1.000\n",
      "[169,     1] train loss: 0.078 train acc: 0.973\n",
      "[169,     2] train loss: 0.110 train acc: 0.949\n",
      "[169,     3] train loss: 0.134 train acc: 0.945\n",
      "[169,     4] train loss: 0.072 train acc: 0.973\n",
      "[169,     5] train loss: 0.155 train acc: 0.938\n",
      "[169,     6] train loss: 0.123 train acc: 0.949\n",
      "[169,     7] train loss: 0.136 train acc: 0.945\n",
      "[169,     8] train loss: 0.124 train acc: 0.938\n",
      "[169,     9] train loss: 0.129 train acc: 0.945\n",
      "[169,    10] train loss: 0.090 train acc: 0.961\n",
      "[169,    11] train loss: 0.082 train acc: 0.969\n",
      "[169,    12] train loss: 0.106 train acc: 0.961\n",
      "[169,    13] train loss: 0.111 train acc: 0.973\n",
      "[169,    14] train loss: 0.111 train acc: 0.953\n",
      "[169,    15] train loss: 0.089 train acc: 0.969\n",
      "[169,    16] train loss: 0.063 train acc: 0.977\n",
      "[169,    17] train loss: 0.078 train acc: 0.965\n",
      "[169,    18] train loss: 0.148 train acc: 0.969\n",
      "[169,    19] train loss: 0.058 train acc: 0.980\n",
      "[169,    20] train loss: 0.123 train acc: 0.942\n",
      "[169] val loss: 0.022 val acc: 1.000\n",
      "[170,     1] train loss: 0.121 train acc: 0.961\n",
      "[170,     2] train loss: 0.096 train acc: 0.953\n",
      "[170,     3] train loss: 0.104 train acc: 0.961\n",
      "[170,     4] train loss: 0.120 train acc: 0.961\n",
      "[170,     5] train loss: 0.125 train acc: 0.949\n",
      "[170,     6] train loss: 0.084 train acc: 0.969\n",
      "[170,     7] train loss: 0.110 train acc: 0.973\n",
      "[170,     8] train loss: 0.125 train acc: 0.953\n",
      "[170,     9] train loss: 0.112 train acc: 0.957\n",
      "[170,    10] train loss: 0.056 train acc: 0.984\n",
      "[170,    11] train loss: 0.135 train acc: 0.953\n",
      "[170,    12] train loss: 0.089 train acc: 0.973\n",
      "[170,    13] train loss: 0.113 train acc: 0.953\n",
      "[170,    14] train loss: 0.109 train acc: 0.969\n",
      "[170,    15] train loss: 0.101 train acc: 0.965\n",
      "[170,    16] train loss: 0.213 train acc: 0.926\n",
      "[170,    17] train loss: 0.072 train acc: 0.973\n",
      "[170,    18] train loss: 0.086 train acc: 0.969\n",
      "[170,    19] train loss: 0.129 train acc: 0.961\n",
      "[170,    20] train loss: 0.116 train acc: 0.942\n",
      "[170] val loss: 0.022 val acc: 1.000\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MALDataset(Dataset):\n",
    "    def __init__(self, r_test_x, r_test_y):\n",
    "        self.r_test_x = r_test_x\n",
    "        self.r_test_y = r_test_y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.r_test_x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = torch.from_numpy(np.array(r_test_x[idx]))\n",
    "        label = [[1,0],[0,1]]\n",
    "        label = torch.from_numpy(np.array(label[r_test_y[idx]], dtype='float32'))\n",
    "        return data, label\n",
    "\n",
    "ratio = 0.7\n",
    "\n",
    "trainset = MALDataset(r_test_x[:int(len(r_test_x)*ratio)], r_test_y[:int(len(r_test_y)*ratio)])\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=256,\n",
    "                                          shuffle=True, num_workers=4)\n",
    "\n",
    "valset = MALDataset(r_test_x[int(len(r_test_x)*ratio):], r_test_y[int(len(r_test_y)*ratio):])\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=128,\n",
    "                                          shuffle=True, num_workers=4)\n",
    "# Define a Loss function and optimizer\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "train_accs = []\n",
    "train_losses = []\n",
    "val_accs = []\n",
    "val_losses = []\n",
    "\n",
    "\n",
    "#Train the network\n",
    "for epoch in range(170):  # loop over the dataset multiple times\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    train_tot_acc = 0\n",
    "    train_tot_loss = 0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        outputs = F.softmax(outputs, dim=1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        outputs = outputs.detach().cpu().numpy()\n",
    "        labels = labels.detach().cpu().numpy()\n",
    "        outputs = outputs[:,1] > outputs[:,0]\n",
    "        labels = labels[:,1] > labels[:,0]\n",
    "        acc = np.sum(outputs.astype(\"int32\") == labels.astype(\"int32\"))/len(labels)\n",
    "#         print(outputs.astype('int32'), labels.astype(\"int32\"))\n",
    "        train_acc += acc\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        train_tot_loss += loss.item()\n",
    "        train_tot_acc += acc\n",
    "        if i % 1 == 0: \n",
    "            print('[%d, %5d] train loss: %.3f train acc: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 1, train_acc/ 1))\n",
    "            running_loss = 0.0\n",
    "            train_acc = 0.0\n",
    "    \n",
    "    net.eval()\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    for i, data in enumerate(valloader, 0):\n",
    "        inputs, labels = data\n",
    "        outputs = net(inputs)\n",
    "        outputs = F.softmax(outputs, dim=1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        val_loss += loss.item()\n",
    "        outputs = outputs.detach().cpu().numpy()\n",
    "        labels = labels.detach().cpu().numpy()\n",
    "        outputs = outputs[:,1] > outputs[:,0]\n",
    "        labels = labels[:,1] > labels[:,0]\n",
    "        acc = np.sum(outputs.astype(\"int32\") == labels.astype(\"int32\"))/len(labels)\n",
    "        val_acc += acc\n",
    "    print('[%d] val loss: %.3f val acc: %.3f' %\n",
    "              (epoch + 1, val_loss / len(valloader), val_acc/len(valloader)))\n",
    "    train_accs.append(train_tot_acc/len(trainloader))\n",
    "    train_losses.append(train_tot_loss/len(trainloader))\n",
    "    val_accs.append(val_acc / len(valloader))\n",
    "    val_losses.append(val_loss / len(valloader))\n",
    "\n",
    "PATH = './Path/dlmal_e_net.pth'\n",
    "torch.save(net, PATH)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97b1168e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(train_accs)\n",
    "plt.plot(val_accs)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train_losses)\n",
    "plt.plot(val_losses)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss', 'val_loss'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "892f8dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITACLFGGIIEKGLVTYMALGLAL\n",
      "LQSVNQLLLTATKERIDFLPHYDTL\n",
      "QPLLLSEDEEDTKRVVRSAKDKRFE\n",
      "QPLLLSEDEEDTKRVVRSAKDKRFE Q 302\n",
      "INTKFFQEENTEKLKLKYYNLMIQL\n",
      "SATVDQRLPECAKLAKEGRLQEVIE\n",
      "QVRVLELENELQKERQKLGELRKKH\n",
      "QVRVLELENELQKERQKLGELRKKH Q 305\n",
      "VYEWARDHRAHHKFSETHADPHNSR\n",
      "AEKFPSPHPSPAKLKATAGHOOOOO\n",
      "GGDGLDPAAMEGKDEPLEFKRVLDN\n",
      "KLYSILQGDSPTKWRTEDFRMFKNG\n",
      "SSSGRRVKSPSPKSERSERSERSHK\n",
      "MESLEQRAIDLYKQLKHRPSDHSYS\n",
      "LIYITLYISECLKKLQKCNSKSQGE\n",
      "ETLYVYELLGVPKPKESTTGLLKAR\n",
      "NLPHTPRYYDILKKRLQLPVWEYKD\n",
      "SVVGTDALKKTKKDDEKSKKSKEEY\n",
      "TNWNKRDFNQFIKANEKWGRDDIEN\n",
      "IRQDIEDSVSRMKPWQSEYGGVVFG\n",
      "AKKGKDEWFSRGKKPIEDPANDTVD\n",
      "SKTIRKEVGRFEKERVKDFKTVIIK\n",
      "KATVKAMQEALAKLKEEEERQKREE\n",
      "DIGKPIEKGPRAKOOOOOOOOOOOO\n",
      "KLRENKEFLEFRKARSDMLLSRKNQ\n",
      "QPVRKVQSATHFKKVRGPSRADPNH\n",
      "QPVRKVQSATHFKKVRGPSRADPNH Q 323\n",
      "FPSIGSGRNGFPKQTAAQLILKAIS\n",
      "SGTKAEVSIQNNKDGTYAVTYVPLT\n",
      "QPQHNGESNEDSKDNHEASTKKKPS\n",
      "QPQHNGESNEDSKDNHEASTKKKPS Q 326\n",
      "LVEQTLSDLEQSKCISIEDEMDVAP\n",
      "DMDYSRIIERLLKLAVPNHLIWLIF\n",
      "ARREKELEARVRKPAEAERYKLERL\n",
      "DWIENHGEAFLSKHTGVGKSLHRAR\n",
      "LLDMSVSFHTHVKELWTWLEELQKE\n",
      "NTSTAEEELCRLKLLAKHPCHIKKF\n",
      "ENLERQQKQQVEKMEQDHAVRRREE\n",
      "GFLAAFDTAWMVKSWNQGTPPLELL\n",
      "GSTSKEGEPNLDKKNTPVQSPVSLG\n",
      "SVFAEDDVKVVEKYFSGPAITLENT\n",
      "ALKNKAAKGSATKDFSVFFQKIRET\n",
      "QLKIKELDHNISKHKREAEDGAAKV\n",
      "QLKIKELDHNISKHKREAEDGAAKV Q 338\n",
      "CSWVASATQNVPKPPSLTVLEGDGR\n",
      "OOOOMEIIRSNFKSNLHKVYQAIEE\n",
      "MVLCPVIGKLLHKRVVLASASPRRQ\n",
      "ITPMLQVIRAIMKDPDDHTVCHLLF\n",
      "EISDGDVIISGNKNLCYANTINWKK\n",
      "TFNPSSDVAALHKAIMVKGVDEATI\n",
      "EITYDKLNKWTSKDKMAEDEVEVYI\n",
      "IVLIGLALLLIWKLLMIIHDRREFA\n",
      "KGPQVRDWSHYFKIIEDLRAQIFAN\n",
      "RKAPSDLYQIILKALERGSLLGCSI\n",
      "GYLTAEQFDEWVKPKDMLGPKOOOO\n",
      "EKSNKSTKSDAPKEKGKKAPRVWEL\n",
      "SGGLPTDEITFAKLLKDQGYSTALI\n",
      "FTLTISALFVTPKTTGARVELSEQQ\n",
      "LLPDNFIAACTEKKIPVVFRLQEGY\n",
      "QYEGTYKWVNPHKLOOOOOOOOOOO\n",
      "QYEGTYKWVNPHKLOOOOOOOOOOO Q 354\n",
      "SEYTVVADISVAKIDPLAPLDKVCL\n",
      "NKRINKYLDEIVKEVEAKAPILKRQ\n",
      "QDVDMVFASFIRKASDVHEVRKVLG\n",
      "QDVDMVFASFIRKASDVHEVRKVLG Q 357\n",
      "AHLYRGIFPVLCKDPVQEAWAEDVD\n",
      "EEEETAKESTAEKDELOOOOOOOOO\n",
      "SLEEIYLFSLPIKESEIIDFFLGAS\n",
      "LQTQWSWILQITKCIDVHLKENAAY\n",
      "NSQGSEMFGDDDKRKIQSQFTDAQK\n",
      "VAKSPKKAKAAAKPKKATKSPAKPK\n",
      "PKAAKAKKAAAKKKOOOOOOOOOOO\n",
      "GRGGGGDHKPQGKKTKFEOOOOOOO\n",
      "AEQQPSEKSTEPKTKPQDMISAGGE\n",
      "NSSAQIDIVISNKAAVAGLDKAERA\n",
      "KLRVLARSSPTDKHTLVKGIIDSTV\n",
      "LTTKNVSIGIVGKDLEFTIYDDDDV\n",
      "QVIMSIRTKLQNKEHVIEALRRAKF\n",
      "QVIMSIRTKLQNKEHVIEALRRAKF Q 370\n",
      "GLSMGTMICGWDKRGPGLYYVDSEG\n",
      "DDLNNYDSDDQEKQSKKKPRLFCDI\n",
      "TAEFAELKTQIEKMRLDYQHEIENL\n",
      "VQNCSLEDSQIEKERDVILREMQEN\n",
      "QLLKEQERTLALKLQEQEQLLKEGF\n",
      "QLLKEQERTLALKLQEQEQLLKEGF Q 375\n",
      "LTEEEEKSKSLAKLKNKHEAMITDL\n",
      "IDPTVTMMQVEEKPDVTYSDVGGCK\n",
      "VENLQDDFDFNYKTLKSQGDMQDLN\n",
      "AMTIPFVRQQVYKKVEEKVRKQTKG\n",
      "QLLADHANSPNKKFYQOOOOOOOOO\n",
      "QLLADHANSPNKKFYQOOOOOOOOO Q 380\n",
      "PLVLKTGVQFTVKLRLLVKLQELNY\n",
      "TGELEAAKALVLKRIQIWKRQQQLA\n",
      "KPFSLMKASSRFKAHQDALPRLPVP\n",
      "LKKEFLHAQEEVKRIQSIPLVIGQF\n",
      "QRELTNLLGLHPKIEMARASCSALM\n",
      "QRELTNLLGLHPKIEMARASCSALM Q 385\n",
      "GGLKALSKEKREKLEAYQHLFYLLQ\n",
      "GMYEQLKGEWNRKSPNLSKCGEELG\n",
      "LLELNFLPTTGTKLTKQQLILARDI\n",
      "GLAAAAGTRIMGKEIEAEAQRPLRQ\n",
      "KAAPAPKAQKGQKAPAQKAPAPKAS\n",
      "NQYVNKKFSNQYKATIGADFLTKEV\n",
      "TATSGFAGAIGQKLPPFSYAYTELE\n",
      "LRDTPPPQSLMVKITLDLLSRIPQP\n",
      "YQEGLRVMGEVGKTTGIPIHVFGTE\n",
      "ATILHLGKSSLPKKPITDDDVDRIS\n",
      "AAKALDDKNCWEKLGEVALLQGNHQ\n",
      "NILRKSLQAERNKPTKNMINIISRL\n",
      "NSDLQGVNVISVKDNDSLAARLAVE\n",
      "LESKKPKGFFGYKSEIFNENFGPDF\n",
      "QDEYALRSHSLAKKAQDEGLLSDVV\n",
      "QDEYALRSHSLAKKAQDEGLLSDVV Q 400\n",
      "HATGFNYQNEDEKVTLSFPSTLQTG\n",
      "FLSRKTLVEFPQKVLSPFRKQGSDS\n",
      "NWDAAMEDLTRLKETIDNNSVSSPL\n",
      "AVVVTNTIPQEDKMKHCSKIQVIDI\n",
      "OOOOOOMAPIGLKAVVGEKIMHDVI\n",
      "EGKELEFYLRKIKARKGKOOOOOOO\n",
      "WDLEGKIIVDELKQEVISTSSKAEP\n",
      "RRYQKSTELLIRKLPFQRLVREIAQ\n",
      "QGQSKDMPPRFSKKGQLNADEISLR\n",
      "QGQSKDMPPRFSKKGQLNADEISLR Q 409\n",
      "EIIKTLSKEEETKKOOOOOOOOOOO\n",
      "FQVWLKNGVILSKLVNSLYPDGSKP\n",
      "QEREDVLAGMSGKAIKGKVGKPKVK\n",
      "QEREDVLAGMSGKAIKGKVGKPKVK Q 412\n",
      "KPSDLRPGDVSSKRNLWEKQSVDKV\n",
      "INANIIMPEFETKCNNSKPKKSYIA\n",
      "GIWRRVALGHGLKLLTKNGHVYKYD\n",
      "SATPRSKPVCIHKNSECLKEQQKRY\n",
      "PKMKGDYDVTVPKVEGEIKAPDVDI\n",
      "QDLRRTESDSGLKKGGNANLVFMLK\n",
      "QDLRRTESDSGLKKGGNANLVFMLK Q 418\n",
      "CLLIADQHCRTRKYFLCLASGIPCV\n",
      "YQIKGSPNLTLPKESYIQEDDIYDD\n",
      "VHPFPDHELEDMKMKISALKSEIQK\n",
      "EGTVKAYVWDNNKDLAEWLEKQLTE\n",
      "KLEKLDTDLKNYKGNSIKESIRRGH\n",
      "AAVFRSMNSALGKSPWLAGNELTVA\n",
      "RKFFGDKTIVPWKVFRQCLHEVHQI\n",
      "GSVKSFSLGPLRKAVTLNPDNSYIK\n",
      "YVLRYAAKFYRRKNSWNKALELLKK\n",
      "MALGGTIGLTIAKRIQISDLPQLVA\n",
      "LKNYNQQKDIEHKELVQKLQHFQEL\n",
      "AIGPFSGLKEVRKVVLDTMKNIHPI\n",
      "GLELYKRLKEFLKNYLTNLLKDGED\n",
      "CTELNQAWSSLGKRADQRKAKLGDS\n",
      "DVGSLVYVMEDGKVEVTKEGVKLCT\n",
      "HVAVTEMAALFPKKPKSDMVRTSLR\n",
      "QKLKQDGDSFRMKLNTQEIFDDWAR\n",
      "QKLKQDGDSFRMKLNTQEIFDDWAR Q 435\n",
      "ITQAVIFLNTRRKVDWLTEKMHARD\n",
      "APVPPVNEPETLKQQNQYQASYNQS\n",
      "TANQWDYKNIIEKLQDIITALEERL\n",
      "ASNYELSDNAGCKEVNSVNCNTSWK\n",
      "AKHKGYSPPESRKSNSKAPKVQSNT\n",
      "LKEKKERLTEELKEQMKAKRKEAEL\n",
      "KDIKKEKVLLRRKSELPQDVYTIKA\n",
      "QFTVLSLSAGRPKRPHARRALCLLL\n",
      "QFTVLSLSAGRPKRPHARRALCLLL Q 443\n",
      "SALQGGTSVAQIKAQLKEIEAEKVE\n",
      "ELNFHKAQEIYEKNLDEKAKEISNL\n",
      "LQMEKAKTHYDAKKQQNQELQEQLR\n",
      "EWNALETECHSLKRENVLLSSELQR\n",
      "IIKVAISNPPQRKVPEKPETRKAPG\n",
      "EDVKGRIYQLLAKASYKKAIILTRE\n",
      "YLDLILNDFVRQKFIIRSKIITYIR\n",
      "LDSGNESKEKLLKGESALQRVQCIP\n",
      "LVTLWHQLHVDMKSLLAWQSLRRDV\n",
      "VIAGVWLEEAGQKLSIYNALKKDLL\n",
      "QLTGLSLLPLSEKAARARQEELYSE\n",
      "QLTGLSLLPLSEKAARARQEELYSE Q 454\n",
      "CFAKTLVEHVGMKNLKSWASVNRGA\n",
      "PEDDTKEKIGPSKPNEIPQQPPPPS\n",
      "SSASVIFEGVDIKNGTEDLPYAMKP\n",
      "SALDSTNVEEAFKNILTEIYRIVSQ\n",
      "FDIQNDRNSILPKSQSEYKPDTPQS\n",
      "ALLGVFCHTDLRKNLTVDEGTMKVE\n",
      "QLKDLNLLDRCIKETLRLRPPIMIM\n",
      "QLKDLNLLDRCIKETLRLRPPIMIM Q 461\n",
      "FLGGARITVLASKTSQRYRIQSEQF\n",
      "SEVFKFSSKNQLKTLQEVHFLLHPS\n",
      "INISLDHKRPLIKVLGISRDVMQAR\n",
      "RIEVENKEVLHGKKWKGLTHNLLKK\n",
      "MLTGDMGSLDDPKMKSMMPTDEQFA\n",
      "LPHPRWSAEASGKPSPSDPGSGTAT\n",
      "AMSTTAKGSKSLKVELIEDKIDYTK\n",
      "YPPNKVMIWDDLKKKTVIEIEFSTE\n",
      "PPSAASAAPSSSKQPAADTEASEQQ\n",
      "PSPSSAEKVKANKDVASPLKELGLR\n",
      "QLSALLKQADSSKRKLTLTRLASAP\n",
      "QLSALLKQADSSKRKLTLTRLASAP Q 472\n",
      "NNGTVLRASHGTKMMTPEVLAEAYG\n",
      "QAVHAAKVILQVKESLGLNGDFSVL\n",
      "QAVHAAKVILQVKESLGLNGDFSVL Q 474\n",
      "LAIGVCYHASLEKKDSYRKAIARFF\n",
      "PFEAVMRTLCECKETASKTLSRFGI\n",
      "HTIALWQFLSAHKSEQLLRLHKEPF\n",
      "DIVYMKPHGRLQKVMNHITDGPRKD\n",
      "VSRTSTAPLDRLKIMMQVHGSKSDK\n",
      "LSGRVLQEMASLKRQFTELLSDIGF\n",
      "KARLGRMVVASDKSGQPVTADDLGV\n",
      "MEVLHLYGSEEQKKQWLEPLLQGNI\n",
      "IFSLSNLQELDLKSNNIRTIEEIIS\n",
      "PGQKEKRVRPEEKQQAKPVKVERTR\n",
      "PPALRPKPAVLPKTNPTIGPAPPPQ\n",
      "KVRKEALLLLSWKQMLDHFQATPHH\n",
      "FKHTVDDGLDIRKAAFECMYTLLDS\n",
      "KPYVENIWALLLKHCECAEEGTRNV\n",
      "LIAAAKYPSYIHKMVIWGANAYVTD\n",
      "DQSERNKVISDFKKKDIPVLVATDV\n",
      "NNSREGTGGSNGKRERYTENRGSSR\n",
      "EKVSLLQGDLSEKEASLLDLKEHAS\n",
      "DIKGPKLDLKDPKVEMRVPDVEVSL\n",
      "QAFTCNTADAPSKDIFVKLTTMAMY\n",
      "QAFTCNTADAPSKDIFVKLTTMAMY Q 494\n",
      "FLCDLLLRLEQAKEAESKDALKDLV\n",
      "GYRWERQLVFRSKLTMHTAFDRKDN\n",
      "AVRFLGCFSDLRKISAMNVFPSNTQ\n",
      "YHSVSTPPVYPPKNVADLKLHVTTS\n",
      "FSSMVESELHAAKTKQAWNFLSHLP\n",
      "FPTQGHDYVLAEKQVQRSRNKQVRE\n",
      "AVKKLKNSLPLRKELDRLKDELSHQ\n",
      "TFEELEHVSAPYKTGSKGTKAQRAR\n",
      "GEGEVKLNMAIGKGEQALRSSNKEG\n",
      "DAESTAVHLEALKKLALALQERKYA\n",
      "RTFTKWINSHLAKRKPPMVVDDLFE\n",
      "IGRLLSEDFVSVKVDREERPDVDKV\n",
      "QVKLYKLNLESSKQELIDYKQKATR\n",
      "QVKLYKLNLESSKQELIDYKQKATR Q 507\n",
      "GLSAFLSQEEINKSLDLARRAIADS\n",
      "SKVALQAQIENHKVFFQKLVADMLL\n",
      "IAKLEEQWLSLNKKIDHELHRLQAL\n",
      "SPSVISDLFTDIKKGHVLLDLLEVL\n",
      "VQALTQQQQSPTKAVPALGKSPPHH\n",
      "LGRLRRATEYAPKKRIEPLSPELVA\n",
      "QKIKEKLEIALEKHQDSSMRKFQEQ\n",
      "QKIKEKLEIALEKHQDSSMRKFQEQ Q 514\n",
      "RTILPMSRAFRGKHLSFVVRFPNQG\n",
      "OMQELTLSPGPAKLTPTLDPTHRME\n",
      "SGSIYSSPGLYSKTMTPTYDAHDGS\n",
      "LNPIEVAIDEMSKKVSELNQLCTME\n",
      "DARRFDGVDAEFKELMFKTAKVENV\n",
      "FEKLERLEFGGTKGAILNGQVHEMS\n",
      "LDVCKQLYNEHMKQIECGHVVLNKN\n",
      "LAEAYEVLSDEVKRKQYDAYGSAGF\n",
      "HFPIGPDVEDLVKEAVSQVRAEATT\n",
      "VYQLLVNEQEPCKFLLDAVFAKGMT\n",
      "AVYLTPESKSSFKQALEALPQLSSG\n",
      "VLNRRWSRLCLPKQYLFTMKLQSPE\n",
      "SKVDDKWEKKCQKIFSFAHQTISAL\n",
      "NTDKNGEELHGGKRVMECLKKALKI\n",
      "HKAAIEVYNEAAKLNQKDWEISHNL\n",
      "RPQSPSPRRETGKESRKSQSPSPKN\n",
      "LDDAIEDCTNAVKLDDTYIKAYLRR\n",
      "AEPSTVPGTPPPKKFRSLFFGSILA\n",
      "AWVQTLCRNAFPKGSWTLAPTDNPP\n",
      "LNKRRGFVFITFKEEEPVKKVLEKK\n",
      "AIVDAEWNILYDKLEKIHHSGAKVV\n",
      "GPVEQQLLQETEKLMKEKLEVQCQA\n",
      "LVKDQEALMKSVKLLQALAQYQNHL\n",
      "SIRRIKDYDANFKIKDFPEKAKDIF\n",
      "GSSGGAPPEEPPKEGNPAEINVERD\n",
      "SFEQMTDAHVWNKSVTLYTVKDKAT\n",
      "PWVRAKKPENCEKLVTLLENYKEMY\n",
      "TIGKLEPSYVIRKFLDAQRIHNLTA\n",
      "SNKPIRELIAEAKAEVTEEVEDGKE\n",
      "ECAIQTCPELLRKDFESLFPEVANG\n",
      "GQGRDNALTLLIKAVPRKSLKDPNN\n",
      "ADSETVKAAKVWKLAEVLVGEQQQC\n",
      "QYLKQIEPSLYPKLFQKNLDPDVFN\n",
      "QYLKQIEPSLYPKLFQKNLDPDVFN Q 547\n",
      "RGPSCRQGRGIQKPQRQALYRGLEN\n",
      "KGKMWEKAIKLSKELAETYESKVFD\n",
      "NLVTFTPSKDSTKDSFQIATLICST\n",
      "VEKFFTEEVDSRKIDQEGKIPDETL\n",
      "GQDVGSFAYLTIKDRIPQILTKVID\n",
      "ASEELQKDLEEVKVLLEKATRKRVR\n",
      "EEVKVLLEKATRKRVRDALTAEKSK\n",
      "ENTVAALKSEFQKTLNDKTENQKSL\n",
      "GSGDTNNFPYLEKTAKKGRPMVISS\n",
      "NIFIECTGTDFTKAKIVLDIIVTMF\n",
      "KNYRHLCAVYYNKNPGFEIIHGLLD\n",
      "IDRVSTEVTLAVKKDVPPSAVTRPI\n",
      "KKRKLPSDVNEGKTVFIRNLSFDSE\n",
      "LRIQRSLQKMRSKPATGEPQKGQPE\n",
      "RKRRHSEVETDSKKKKMKLPEHPEG\n",
      "KSHVYSLEGQDCKYTPMFGPEARTL\n",
      "SSSNKKLPSDEPKSSCILQITVEEF\n",
      "LPLELGTFHQLFKHLGTEDIISTKQ\n",
      "TYSQRFFVPPTFKSVGNPVEARRWL\n",
      "AQEEIMKLKDTLKSQMTQEASDEAE\n",
      "EVVQIRSEVSQVKREKENIQTLLKS\n",
      "NANSCPVDRTLFKCICIRAQFGGKI\n",
      "FLVPELQATEEEKSKLESGLTNGDE\n",
      "EWPFLIITDLFLKSPELVQAMFPKL\n",
      "RTGLGRLGVSLSKGLHHKAVLAVRR\n",
      "EYRGQAQAIEFLKEQISLAEKKMLD\n",
      "VSALESKCKSGEKKVDALLKEKRRL\n",
      "FKRDGSNIIYTAKISLREALCGCSI\n",
      "SVVRDLGFFGIYKGAKACFLRDIPF\n",
      "TVELLSGVVDQTKDGLISFQEFVAF\n",
      "FCRVKDPNSGLPKFVLINWTGEGVN\n",
      "OOOOOOOOOMSLKLQASNVTNKNDP\n",
      "RVKPEEMMDERPKTRSQEQEVLERG\n",
      "GGLSPLSSPSDTKAESPAEKVPEES\n",
      "AGLQLVVVILPGKTPVYAEVKRVGD\n",
      "KRLKLRFYRTSVKEDLNVNEVFKYL\n",
      "LKGDLKGVKGDLKKPFDKAWKDYET\n",
      "EKPTVQQLQILWKAINCPEDIVFPA\n",
      "ATLALNYSVCFHKDHNIEGKAQCLS\n",
      "MTMYNQATQEIAKPSELLTSVRAYM\n",
      "VDTEIEEKDEETKAFEALLSNIVKP\n",
      "IRVAAKWYNEHLKKMSADNQLQVIF\n",
      "RPAGPELQTPPGKDGAVEDEEGEGE\n",
      "EQQQHRSGGRGNKTRNSNNNNTAAA\n",
      "SALLSAAFLLVRKLPPLCHGLPTQR\n",
      "FLEKINKNCWRIKKGFVPNMQVEGV\n",
      "PPPNTDPWLLRSKSPVGNPQLIQFS\n",
      "DKNIVVDDITEQKPEPQDDGKSTES\n",
      "KKYATLSLFNTYKGKSLETQKTTVA\n",
      "LKNTPSFLIACNKQDIAMAKSAKLI\n",
      "RKNTKEMFGGFFKSVVKSADEVLFT\n",
      "IFTVQMDDYLGGKPVQNRELQGYES\n",
      "(600, 1, 25)\n",
      "[[[ 5  2 15 ...  9 11 11]]\n",
      "\n",
      " [[ 1 13 12 ... 20 12  3]]\n",
      "\n",
      " [[ 3 14  1 ...  6  2 12]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[11 12  3 ... 12 11 10]]\n",
      "\n",
      " [[ 2 12  3 ... 11 14 17]]\n",
      "\n",
      " [[10 14 17 ... 19  7 16]]]\n"
     ]
    }
   ],
   "source": [
    "r_test_x = []\n",
    "r_test_y = []\n",
    "posit_1 = 1;\n",
    "negat_0 = 0;\n",
    "\n",
    "# define universe of possible input values\n",
    "alphabet = 'OARNDCQEGHILKMFPSTWYV'\n",
    "# define a mapping of chars to integers\n",
    "char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
    "\n",
    "i = 0\n",
    "#-------------------------TEST DATASET----------------------------------------\n",
    "#for positive sequence\n",
    "def innertest1():\n",
    "    #Input\n",
    "    data = seq_record.seq\n",
    "    #rint(data) \n",
    "    # integer encode input data\n",
    "    for char in data:\n",
    "        if char not in alphabet:\n",
    "            return\n",
    "    integer_encoded = [char_to_int[char] for char in data]\n",
    "    r_test_x.append(integer_encoded)\n",
    "    r_test_y.append(posit_1)\n",
    "for seq_record in SeqIO.parse(\"./Datasets/independent_data/H_test.fasta\", \"fasta\"):\n",
    "    innertest1()\n",
    "    i += 1\n",
    "\n",
    "\n",
    "#for negative sequence\n",
    "def innertest2():\n",
    "    #Input\n",
    "    data = seq_record.seq\n",
    "    print(data) \n",
    "    # integer encode input data\n",
    "    for char in data:\n",
    "        if char not in alphabet:\n",
    "#             print(data, i)\n",
    "            return\n",
    "    integer_encoded = [char_to_int[char] for char in data]\n",
    "    if integer_encoded[0] == 6: print(data, int_to_char[6], len(r_test_x))\n",
    "    r_test_x.append(integer_encoded) \n",
    "    r_test_y.append(negat_0)\n",
    "for seq_record in SeqIO.parse(\"./Datasets/independent_data/H_test_neg.fasta\", \"fasta\"):\n",
    "    innertest2()\n",
    "# Changing to array (matrix)    \n",
    "r_test_x = np.array(r_test_x)\n",
    "r_test_y = np.array(r_test_y)\n",
    "\n",
    "# Balancing test dataset\n",
    "# Testing Data Balancing by undersampling####################################\n",
    "# rus = RandomUnderSampler(random_state=7)\n",
    "# x_res3, y_res3 = rus.fit_resample(r_test_x, r_test_y)\n",
    "# #Shuffling\n",
    "# r_test_x, r_test_y = shuffle(x_res3, y_res3, random_state=7)\n",
    "# r_test_x = np.array(r_test_x)\n",
    "# r_test_y = np.array(r_test_y)\n",
    "\n",
    "r_test_x = np.expand_dims(r_test_x, 1)\n",
    "print(r_test_x.shape)\n",
    "print(r_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c82050f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5  2 15 18  1 16  2  1  1  1  2 15 12 15 16  1 16  7 20 11 17  2  9 11\n",
      "  11]]\n",
      "['C', 'R', 'P', 'W', 'A', 'S', 'R', 'A', 'A', 'A', 'R', 'P', 'K', 'P', 'S', 'A', 'S', 'E', 'V', 'L', 'T', 'R', 'H', 'L', 'L']\n",
      "tensor([[0.6445, 0.3555]], grad_fn=<SoftmaxBackward>)\n",
      "[[10 14 17 20  6 13  4  4 19 11  8  8 12 15 20  6  3  2  7 11  6  8 19  7\n",
      "  16]]\n",
      "['I', 'F', 'T', 'V', 'Q', 'M', 'D', 'D', 'Y', 'L', 'G', 'G', 'K', 'P', 'V', 'Q', 'N', 'R', 'E', 'L', 'Q', 'G', 'Y', 'E', 'S']\n",
      "tensor([[0.7703, 0.2297]], grad_fn=<SoftmaxBackward>)\n",
      "['C', 'R', 'P', 'W', 'A', 'S', 'R', 'A', 'A', 'A', 'R', 'P', 'K', 'P', 'S', 'A', 'S', 'E', 'V', 'L', 'T', 'R', 'H', 'L', 'L'] [[0.6445085  0.35549146]]\n",
      "['L', 'G', 'S', 'I', 'L', 'K', 'T', 'N', 'V', 'R', 'A', 'C', 'K', 'A', 'V', 'G', 'H', 'P', 'F', 'V', 'I', 'Q', 'L', 'G', 'R'] [[0.504349   0.49565095]]\n",
      "['S', 'S', 'Y', 'N', 'L', 'V', 'P', 'R', 'Y', 'I', 'P', 'Q', 'K', 'Q', 'S', 'E', 'D', 'M', 'H', 'A', 'F', 'V', 'T', 'E', 'V'] [[0.6211862  0.37881377]]\n",
      "['A', 'Q', 'L', 'A', 'Q', 'R', 'I', 'S', 'S', 'N', 'I', 'Q', 'K', 'I', 'T', 'Q', 'C', 'S', 'V', 'E', 'I', 'Q', 'R', 'T', 'L'] [[0.7420042  0.25799578]]\n",
      "['V', 'A', 'A', 'T', 'L', 'K', 'K', 'Q', 'K', 'K', 'N', 'T', 'K', 'D', 'E', 'F', 'E', 'E', 'R', 'A', 'K', 'A', 'I', 'I', 'V'] [[0.60786784 0.39213213]]\n",
      "['P', 'D', 'S', 'T', 'H', 'L', 'L', 'S', 'A', 'S', 'G', 'D', 'K', 'T', 'S', 'K', 'I', 'W', 'D', 'V', 'S', 'V', 'N', 'S', 'V'] [[0.5750065  0.42499352]]\n",
      "['N', 'S', 'L', 'C', 'F', 'P', 'E', 'D', 'A', 'E', 'I', 'S', 'K', 'H', 'A', 'K', 'N', 'L', 'I', 'C', 'A', 'F', 'L', 'T', 'D'] [[0.7156842  0.28431582]]\n",
      "['G', 'C', 'G', 'R', 'T', 'D', 'F', 'Q', 'Q', 'G', 'C', 'A', 'K', 'T', 'L', 'Y', 'H', 'S', 'V', 'H', 'E', 'K', 'I', 'F', 'T'] [[0.7886904  0.21130958]]\n",
      "['K', 'Q', 'S', 'A', 'A', 'L', 'C', 'L', 'L', 'R', 'L', 'Y', 'K', 'A', 'S', 'P', 'D', 'L', 'V', 'P', 'M', 'G', 'E', 'W', 'T'] [[0.6021792  0.39782086]]\n",
      "['N', 'L', 'N', 'H', 'V', 'S', 'Y', 'G', 'R', 'L', 'T', 'F', 'K', 'Y', 'E', 'R', 'D', 'S', 'N', 'Y', 'H', 'L', 'L', 'M', 'S'] [[0.5219822  0.47801775]]\n",
      "['H', 'L', 'G', 'R', 'P', 'D', 'G', 'V', 'P', 'M', 'P', 'D', 'K', 'Y', 'S', 'L', 'E', 'P', 'V', 'A', 'V', 'E', 'L', 'K', 'S'] [[0.84640896 0.15359104]]\n",
      "['R', 'C', 'L', 'V', 'E', 'K', 'G', 'D', 'V', 'A', 'F', 'V', 'K', 'H', 'Q', 'T', 'V', 'P', 'Q', 'N', 'T', 'G', 'G', 'K', 'N'] [[0.5312554  0.46874458]]\n",
      "['Y', 'S', 'R', 'L', 'N', 'L', 'N', 'N', 'T', 'V', 'L', 'S', 'K', 'R', 'K', 'L', 'T', 'W', 'F', 'V', 'N', 'E', 'G', 'L', 'V'] [[0.54601747 0.4539825 ]]\n",
      "['G', 'Q', 'T', 'Y', 'C', 'D', 'L', 'R', 'S', 'L', 'N', 'A', 'K', 'A', 'V', 'V', 'A', 'A', 'L', 'M', 'K', 'A', 'O', 'O', 'O'] [[0.63446355 0.36553645]]\n",
      "['I', 'N', 'T', 'E', 'F', 'K', 'N', 'T', 'R', 'T', 'N', 'E', 'K', 'V', 'E', 'L', 'Q', 'E', 'L', 'N', 'D', 'R', 'F', 'A', 'N'] [[0.5611686  0.43883142]]\n",
      "['L', 'N', 'N', 'S', 'H', 'Y', 'Y', 'H', 'M', 'A', 'H', 'G', 'K', 'D', 'F', 'A', 'S', 'R', 'G', 'I', 'E', 'M', 'S', 'E', 'V'] [[0.70757467 0.29242536]]\n",
      "['D', 'L', 'I', 'K', 'M', 'I', 'F', 'D', 'V', 'E', 'S', 'M', 'K', 'K', 'A', 'M', 'V', 'E', 'Y', 'E', 'I', 'D', 'L', 'Q', 'K'] [[0.78654104 0.21345894]]\n",
      "['L', 'G', 'S', 'I', 'K', 'A', 'I', 'P', 'R', 'F', 'N', 'Q', 'K', 'G', 'E', 'V', 'Y', 'K', 'A', 'Q', 'I', 'M', 'N', 'V', 'S'] [[0.51939 0.48061]]\n",
      "['K', 'T', 'L', 'L', 'A', 'R', 'A', 'C', 'A', 'A', 'Q', 'T', 'K', 'A', 'T', 'F', 'L', 'K', 'L', 'A', 'G', 'P', 'Q', 'L', 'V'] [[0.63725775 0.36274225]]\n",
      "['M', 'V', 'R', 'Y', 'S', 'L', 'D', 'P', 'E', 'N', 'P', 'T', 'K', 'S', 'C', 'K', 'S', 'R', 'G', 'S', 'N', 'L', 'R', 'V', 'H'] [[0.5418822 0.4581178]]\n",
      "['S', 'R', 'N', 'Y', 'L', 'S', 'Q', 'P', 'R', 'L', 'T', 'Y', 'K', 'T', 'V', 'S', 'G', 'V', 'N', 'G', 'P', 'L', 'V', 'I', 'L'] [[0.53651077 0.46348926]]\n",
      "['R', 'S', 'I', 'V', 'D', 'N', 'W', 'P', 'E', 'N', 'H', 'V', 'K', 'A', 'V', 'V', 'V', 'T', 'D', 'G', 'E', 'R', 'I', 'L', 'G'] [[0.58619 0.41381]]\n",
      "['O', 'O', 'O', 'M', 'A', 'D', 'L', 'A', 'E', 'C', 'N', 'I', 'K', 'V', 'M', 'C', 'R', 'F', 'R', 'P', 'L', 'N', 'E', 'S', 'E'] [[0.8247281  0.17527193]]\n",
      "['G', 'L', 'V', 'A', 'A', 'K', 'V', 'I', 'P', 'S', 'P', 'F', 'K', 'H', 'A', 'D', 'I', 'V', 'T', 'T', 'T', 'T', 'H', 'K', 'T'] [[0.55883443 0.44116554]]\n",
      "['K', 'L', 'R', 'N', 'W', 'Q', 'W', 'W', 'R', 'L', 'F', 'T', 'K', 'V', 'K', 'P', 'L', 'L', 'Q', 'V', 'S', 'R', 'Q', 'E', 'E'] [[0.59483707 0.40516293]]\n",
      "['L', 'E', 'A', 'L', 'M', 'F', 'D', 'R', 'S', 'F', 'V', 'G', 'K', 'Q', 'F', 'S', 'A', 'N', 'D', 'K', 'V', 'Y', 'T', 'V', 'E'] [[0.5137309  0.48626906]]\n",
      "['R', 'T', 'D', 'F', 'K', 'E', 'E', 'P', 'E', 'P', 'G', 'F', 'K', 'R', 'L', 'A', 'W', 'G', 'Q', 'P', 'V', 'G', 'L', 'R', 'H'] [[0.7421337 0.2578663]]\n",
      "['A', 'D', 'E', 'A', 'S', 'E', 'L', 'A', 'C', 'P', 'T', 'P', 'K', 'E', 'D', 'G', 'L', 'A', 'Q', 'Q', 'Q', 'T', 'Q', 'L', 'N'] [[0.78634423 0.21365574]]\n",
      "['Y', 'M', 'R', 'R', 'S', 'T', 'C', 'T', 'I', 'N', 'Y', 'S', 'K', 'D', 'L', 'P', 'L', 'A', 'Q', 'G', 'I', 'K', 'F', 'Q', 'O'] [[0.60014504 0.39985493]]\n",
      "['A', 'E', 'V', 'K', 'L', 'E', 'E', 'E', 'N', 'R', 'S', 'L', 'K', 'A', 'D', 'L', 'Q', 'K', 'L', 'K', 'D', 'E', 'L', 'A', 'S'] [[0.5219106  0.47808936]]\n",
      "['F', 'K', 'S', 'H', 'R', 'T', 'E', 'M', 'D', 'W', 'V', 'L', 'K', 'H', 'S', 'G', 'P', 'N', 'S', 'A', 'D', 'S', 'A', 'N', 'D'] [[0.558048   0.44195196]]\n",
      "['D', 'Y', 'S', 'W', 'A', 'R', 'E', 'L', 'G', 'L', 'I', 'R', 'K', 'P', 'A', 'S', 'F', 'M', 'T', 'S', 'I', 'C', 'D', 'E', 'R'] [[0.58637035 0.41362965]]\n",
      "['V', 'S', 'N', 'D', 'S', 'G', 'I', 'Y', 'V', 'S', 'R', 'I', 'K', 'E', 'N', 'G', 'A', 'A', 'A', 'L', 'D', 'G', 'R', 'L', 'Q'] [[0.6333985 0.3666015]]\n",
      "['K', 'E', 'R', 'A', 'C', 'Y', 'L', 'S', 'I', 'N', 'P', 'Q', 'K', 'D', 'E', 'T', 'L', 'E', 'T', 'E', 'K', 'A', 'Q', 'Y', 'Y'] [[0.8760233  0.12397669]]\n",
      "['D', 'K', 'P', 'L', 'R', 'L', 'P', 'L', 'Q', 'D', 'V', 'Y', 'K', 'I', 'G', 'G', 'I', 'G', 'T', 'V', 'P', 'V', 'G', 'R', 'V'] [[0.67797726 0.3220227 ]]\n",
      "['F', 'R', 'E', 'R', 'A', 'N', 'Q', 'K', 'H', 'Q', 'G', 'L', 'K', 'L', 'A', 'T', 'T', 'I', 'L', 'Q', 'H', 'W', 'K', 'K', 'C'] [[0.51607746 0.4839225 ]]\n",
      "['K', 'I', 'K', 'K', 'D', 'K', 'E', 'P', 'K', 'E', 'E', 'V', 'K', 'S', 'F', 'M', 'D', 'R', 'K', 'K', 'G', 'F', 'T', 'E', 'V'] [[0.51670784 0.48329213]]\n",
      "['V', 'T', 'G', 'S', 'P', 'E', 'A', 'S', 'I', 'S', 'G', 'S', 'K', 'G', 'D', 'L', 'K', 'S', 'S', 'K', 'A', 'S', 'L', 'G', 'S'] [[0.50538105 0.49461892]]\n",
      "['S', 'L', 'S', 'A', 'M', 'H', 'S', 'S', 'G', 'S', 'S', 'G', 'K', 'G', 'A', 'G', 'P', 'L', 'R', 'G', 'K', 'T', 'S', 'G', 'T'] [[0.5976476  0.40235236]]\n",
      "['P', 'K', 'Q', 'A', 'A', 'A', 'D', 'R', 'R', 'T', 'V', 'E', 'K', 'T', 'W', 'K', 'L', 'M', 'D', 'K', 'V', 'V', 'R', 'L', 'C'] [[0.5966429 0.4033571]]\n",
      "['V', 'E', 'D', 'S', 'K', 'D', 'V', 'N', 'V', 'N', 'F', 'E', 'K', 'S', 'K', 'L', 'T', 'F', 'S', 'C', 'L', 'G', 'G', 'S', 'D'] [[0.50668025 0.49331972]]\n",
      "['V', 'Q', 'V', 'H', 'E', 'L', 'G', 'C', 'E', 'G', 'I', 'S', 'K', 'S', 'Y', 'V', 'F', 'R', 'G', 'T', 'K', 'D', 'L', 'S', 'A'] [[0.54454124 0.45545873]]\n",
      "['L', 'A', 'A', 'V', 'T', 'Y', 'N', 'G', 'V', 'D', 'N', 'N', 'K', 'N', 'K', 'G', 'Q', 'L', 'T', 'K', 'S', 'P', 'L', 'A', 'Q'] [[0.5516508 0.4483492]]\n",
      "['V', 'Y', 'E', 'P', 'Q', 'L', 'Q', 'H', 'H', 'V', 'A', 'Q', 'K', 'K', 'I', 'P', 'Y', 'V', 'D', 'T', 'Q', 'G', 'Q', 'L', 'I'] [[0.53547925 0.46452072]]\n",
      "['F', 'A', 'L', 'V', 'G', 'V', 'G', 'S', 'E', 'A', 'S', 'S', 'K', 'K', 'L', 'M', 'D', 'L', 'L', 'P', 'K', 'R', 'E', 'L', 'H'] [[0.562204   0.43779603]]\n",
      "['D', 'G', 'K', 'A', 'D', 'P', 'L', 'A', 'L', 'A', 'A', 'E', 'K', 'D', 'G', 'T', 'P', 'V', 'F', 'K', 'L', 'P', 'K', 'W', 'R'] [[0.500412 0.499588]]\n",
      "['L', 'E', 'A', 'G', 'T', 'V', 'F', 'I', 'N', 'T', 'Y', 'N', 'K', 'T', 'D', 'V', 'A', 'A', 'P', 'F', 'G', 'G', 'V', 'K', 'Q'] [[0.79852504 0.20147498]]\n",
      "['V', 'H', 'R', 'Y', 'P', 'I', 'D', 'T', 'L', 'P', 'T', 'S', 'K', 'E', 'D', 'L', 'Q', 'L', 'W', 'C', 'H', 'K', 'R', 'W', 'E'] [[0.5364875  0.46351248]]\n",
      "['E', 'A', 'T', 'P', 'I', 'V', 'R', 'V', 'A', 'V', 'E', 'P', 'K', 'H', 'P', 'S', 'E', 'M', 'P', 'Q', 'L', 'V', 'K', 'G', 'M'] [[0.6220545  0.37794548]]\n",
      "['Q', 'T', 'I', 'K', 'L', 'C', 'I', 'G', 'N', 'I', 'T', 'N', 'K', 'K', 'G', 'G', 'A', 'S', 'K', 'P', 'R', 'T', 'A', 'R', 'G'] [[0.5388637  0.46113634]]\n",
      "['S', 'R', 'E', 'L', 'A', 'E', 'Q', 'T', 'L', 'N', 'N', 'I', 'K', 'Q', 'F', 'K', 'K', 'Y', 'I', 'D', 'N', 'P', 'K', 'L', 'R'] [[0.54913384 0.45086616]]\n",
      "['I', 'K', 'S', 'N', 'F', 'K', 'P', 'S', 'L', 'L', 'A', 'Q', 'K', 'I', 'E', 'V', 'R', 'I', 'P', 'T', 'P', 'L', 'N', 'T', 'S'] [[0.5239482  0.47605172]]\n",
      "['K', 'P', 'A', 'N', 'F', 'L', 'D', 'L', 'G', 'G', 'G', 'V', 'K', 'E', 'A', 'Q', 'V', 'Y', 'Q', 'A', 'F', 'K', 'L', 'L', 'T'] [[0.6507219 0.3492781]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'R', 'L', 'N', 'L', 'G', 'K', 'K', 'R', 'K', 'M', 'V', 'K', 'V', 'Y', 'T', 'K', 'T', 'D', 'G', 'L', 'V', 'A', 'V', 'H'] [[0.54336005 0.4566399 ]]\n",
      "['P', 'V', 'E', 'P', 'V', 'L', 'T', 'V', 'H', 'P', 'E', 'S', 'K', 'S', 'K', 'T', 'K', 'T', 'R', 'S', 'R', 'S', 'R', 'G', 'R'] [[0.7803018 0.2196982]]\n",
      "['S', 'D', 'V', 'R', 'N', 'T', 'V', 'T', 'Y', 'T', 'S', 'L', 'K', 'T', 'K', 'L', 'S', 'N', 'V', 'I', 'N', 'S', 'A', 'T', 'D'] [[0.54414135 0.45585868]]\n",
      "['T', 'R', 'E', 'L', 'S', 'N', 'F', 'Y', 'F', 'S', 'I', 'I', 'K', 'D', 'R', 'L', 'Y', 'C', 'E', 'K', 'E', 'N', 'D', 'P', 'K'] [[0.6471319  0.35286805]]\n",
      "['O', 'M', 'K', 'H', 'Y', 'E', 'V', 'E', 'I', 'L', 'D', 'A', 'K', 'T', 'R', 'E', 'K', 'L', 'C', 'F', 'L', 'D', 'K', 'V', 'E'] [[0.56747764 0.4325223 ]]\n",
      "['Y', 'V', 'K', 'G', 'W', 'I', 'P', 'G', 'N', 'E', 'E', 'N', 'K', 'Q', 'K', 'T', 'D', 'V', 'H', 'Y', 'R', 'S', 'L', 'D', 'G'] [[0.67633647 0.3236635 ]]\n",
      "['W', 'K', 'E', 'A', 'K', 'P', 'D', 'E', 'L', 'M', 'D', 'S', 'K', 'L', 'R', 'C', 'V', 'F', 'E', 'M', 'P', 'N', 'E', 'N', 'D'] [[0.5634668  0.43653318]]\n",
      "['V', 'I', 'A', 'S', 'E', 'L', 'G', 'S', 'M', 'P', 'E', 'L', 'K', 'K', 'Y', 'M', 'K', 'K', 'V', 'M', 'P', 'F', 'V', 'A', 'M'] [[0.62559485 0.37440518]]\n",
      "['F', 'M', 'S', 'E', 'K', 'E', 'V', 'P', 'L', 'V', 'F', 'P', 'K', 'T', 'Y', 'G', 'E', 'S', 'M', 'L', 'Y', 'L', 'D', 'G', 'Q'] [[0.76035404 0.23964599]]\n",
      "['K', 'E', 'A', 'D', 'L', 'A', 'A', 'Q', 'E', 'E', 'A', 'A', 'K', 'K', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] [[0.51389647 0.48610353]]\n",
      "['L', 'Q', 'S', 'V', 'N', 'Q', 'L', 'L', 'L', 'T', 'A', 'T', 'K', 'E', 'R', 'I', 'D', 'F', 'L', 'P', 'H', 'Y', 'D', 'T', 'L'] [[0.4786998 0.5213002]]\n",
      "['Q', 'P', 'L', 'L', 'L', 'S', 'E', 'D', 'E', 'E', 'D', 'T', 'K', 'R', 'V', 'V', 'R', 'S', 'A', 'K', 'D', 'K', 'R', 'F', 'E'] [[0.440398   0.55960196]]\n",
      "['S', 'A', 'T', 'V', 'D', 'Q', 'R', 'L', 'P', 'E', 'C', 'A', 'K', 'L', 'A', 'K', 'E', 'G', 'R', 'L', 'Q', 'E', 'V', 'I', 'E'] [[0.31913424 0.68086576]]\n",
      "['Q', 'V', 'R', 'V', 'L', 'E', 'L', 'E', 'N', 'E', 'L', 'Q', 'K', 'E', 'R', 'Q', 'K', 'L', 'G', 'E', 'L', 'R', 'K', 'K', 'H'] [[0.46125793 0.53874207]]\n",
      "['V', 'Y', 'E', 'W', 'A', 'R', 'D', 'H', 'R', 'A', 'H', 'H', 'K', 'F', 'S', 'E', 'T', 'H', 'A', 'D', 'P', 'H', 'N', 'S', 'R'] [[0.4651179  0.53488207]]\n",
      "['A', 'E', 'K', 'F', 'P', 'S', 'P', 'H', 'P', 'S', 'P', 'A', 'K', 'L', 'K', 'A', 'T', 'A', 'G', 'H', 'O', 'O', 'O', 'O', 'O'] [[0.3708497 0.6291503]]\n",
      "['K', 'L', 'Y', 'S', 'I', 'L', 'Q', 'G', 'D', 'S', 'P', 'T', 'K', 'W', 'R', 'T', 'E', 'D', 'F', 'R', 'M', 'F', 'K', 'N', 'G'] [[0.44748694 0.5525131 ]]\n",
      "['T', 'N', 'W', 'N', 'K', 'R', 'D', 'F', 'N', 'Q', 'F', 'I', 'K', 'A', 'N', 'E', 'K', 'W', 'G', 'R', 'D', 'D', 'I', 'E', 'N'] [[0.36260706 0.63739294]]\n",
      "['I', 'R', 'Q', 'D', 'I', 'E', 'D', 'S', 'V', 'S', 'R', 'M', 'K', 'P', 'W', 'Q', 'S', 'E', 'Y', 'G', 'G', 'V', 'V', 'F', 'G'] [[0.44168004 0.5583199 ]]\n",
      "['K', 'A', 'T', 'V', 'K', 'A', 'M', 'Q', 'E', 'A', 'L', 'A', 'K', 'L', 'K', 'E', 'E', 'E', 'E', 'R', 'Q', 'K', 'R', 'E', 'E'] [[0.4459632 0.5540368]]\n",
      "['K', 'L', 'R', 'E', 'N', 'K', 'E', 'F', 'L', 'E', 'F', 'R', 'K', 'A', 'R', 'S', 'D', 'M', 'L', 'L', 'S', 'R', 'K', 'N', 'Q'] [[0.43724385 0.5627562 ]]\n",
      "['Q', 'P', 'V', 'R', 'K', 'V', 'Q', 'S', 'A', 'T', 'H', 'F', 'K', 'K', 'V', 'R', 'G', 'P', 'S', 'R', 'A', 'D', 'P', 'N', 'H'] [[0.49578372 0.5042164 ]]\n",
      "['F', 'P', 'S', 'I', 'G', 'S', 'G', 'R', 'N', 'G', 'F', 'P', 'K', 'Q', 'T', 'A', 'A', 'Q', 'L', 'I', 'L', 'K', 'A', 'I', 'S'] [[0.35495263 0.6450474 ]]\n",
      "['S', 'G', 'T', 'K', 'A', 'E', 'V', 'S', 'I', 'Q', 'N', 'N', 'K', 'D', 'G', 'T', 'Y', 'A', 'V', 'T', 'Y', 'V', 'P', 'L', 'T'] [[0.4244962 0.5755038]]\n",
      "['D', 'W', 'I', 'E', 'N', 'H', 'G', 'E', 'A', 'F', 'L', 'S', 'K', 'H', 'T', 'G', 'V', 'G', 'K', 'S', 'L', 'H', 'R', 'A', 'R'] [[0.3832436 0.6167564]]\n",
      "['N', 'T', 'S', 'T', 'A', 'E', 'E', 'E', 'L', 'C', 'R', 'L', 'K', 'L', 'L', 'A', 'K', 'H', 'P', 'C', 'H', 'I', 'K', 'K', 'F'] [[0.37078795 0.629212  ]]\n",
      "['A', 'L', 'K', 'N', 'K', 'A', 'A', 'K', 'G', 'S', 'A', 'T', 'K', 'D', 'F', 'S', 'V', 'F', 'F', 'Q', 'K', 'I', 'R', 'E', 'T'] [[0.33252466 0.6674753 ]]\n",
      "['Q', 'L', 'K', 'I', 'K', 'E', 'L', 'D', 'H', 'N', 'I', 'S', 'K', 'H', 'K', 'R', 'E', 'A', 'E', 'D', 'G', 'A', 'A', 'K', 'V'] [[0.41056627 0.5894337 ]]\n",
      "['O', 'O', 'O', 'O', 'M', 'E', 'I', 'I', 'R', 'S', 'N', 'F', 'K', 'S', 'N', 'L', 'H', 'K', 'V', 'Y', 'Q', 'A', 'I', 'E', 'E'] [[0.48301482 0.5169852 ]]\n",
      "['L', 'L', 'P', 'D', 'N', 'F', 'I', 'A', 'A', 'C', 'T', 'E', 'K', 'K', 'I', 'P', 'V', 'V', 'F', 'R', 'L', 'Q', 'E', 'G', 'Y'] [[0.4045393 0.5954608]]\n",
      "['N', 'K', 'R', 'I', 'N', 'K', 'Y', 'L', 'D', 'E', 'I', 'V', 'K', 'E', 'V', 'E', 'A', 'K', 'A', 'P', 'I', 'L', 'K', 'R', 'Q'] [[0.26386675 0.7361333 ]]\n",
      "['Q', 'D', 'V', 'D', 'M', 'V', 'F', 'A', 'S', 'F', 'I', 'R', 'K', 'A', 'S', 'D', 'V', 'H', 'E', 'V', 'R', 'K', 'V', 'L', 'G'] [[0.29424402 0.705756  ]]\n",
      "['N', 'S', 'Q', 'G', 'S', 'E', 'M', 'F', 'G', 'D', 'D', 'D', 'K', 'R', 'K', 'I', 'Q', 'S', 'Q', 'F', 'T', 'D', 'A', 'Q', 'K'] [[0.34961554 0.6503845 ]]\n",
      "['Q', 'V', 'I', 'M', 'S', 'I', 'R', 'T', 'K', 'L', 'Q', 'N', 'K', 'E', 'H', 'V', 'I', 'E', 'A', 'L', 'R', 'R', 'A', 'K', 'F'] [[0.20429897 0.795701  ]]\n",
      "['Q', 'L', 'L', 'K', 'E', 'Q', 'E', 'R', 'T', 'L', 'A', 'L', 'K', 'L', 'Q', 'E', 'Q', 'E', 'Q', 'L', 'L', 'K', 'E', 'G', 'F'] [[0.1472733  0.85272676]]\n",
      "['A', 'M', 'T', 'I', 'P', 'F', 'V', 'R', 'Q', 'Q', 'V', 'Y', 'K', 'K', 'V', 'E', 'E', 'K', 'V', 'R', 'K', 'Q', 'T', 'K', 'G'] [[0.35449448 0.64550555]]\n",
      "['P', 'L', 'V', 'L', 'K', 'T', 'G', 'V', 'Q', 'F', 'T', 'V', 'K', 'L', 'R', 'L', 'L', 'V', 'K', 'L', 'Q', 'E', 'L', 'N', 'Y'] [[0.33325303 0.666747  ]]\n",
      "['T', 'G', 'E', 'L', 'E', 'A', 'A', 'K', 'A', 'L', 'V', 'L', 'K', 'R', 'I', 'Q', 'I', 'W', 'K', 'R', 'Q', 'Q', 'Q', 'L', 'A'] [[0.3749568 0.6250432]]\n",
      "['K', 'P', 'F', 'S', 'L', 'M', 'K', 'A', 'S', 'S', 'R', 'F', 'K', 'A', 'H', 'Q', 'D', 'A', 'L', 'P', 'R', 'L', 'P', 'V', 'P'] [[0.45423728 0.5457627 ]]\n",
      "['L', 'K', 'K', 'E', 'F', 'L', 'H', 'A', 'Q', 'E', 'E', 'V', 'K', 'R', 'I', 'Q', 'S', 'I', 'P', 'L', 'V', 'I', 'G', 'Q', 'F'] [[0.41069034 0.58930963]]\n",
      "['Q', 'R', 'E', 'L', 'T', 'N', 'L', 'L', 'G', 'L', 'H', 'P', 'K', 'I', 'E', 'M', 'A', 'R', 'A', 'S', 'C', 'S', 'A', 'L', 'M'] [[0.43414164 0.5658584 ]]\n",
      "['G', 'G', 'L', 'K', 'A', 'L', 'S', 'K', 'E', 'K', 'R', 'E', 'K', 'L', 'E', 'A', 'Y', 'Q', 'H', 'L', 'F', 'Y', 'L', 'L', 'Q'] [[0.40712637 0.5928737 ]]\n",
      "['G', 'M', 'Y', 'E', 'Q', 'L', 'K', 'G', 'E', 'W', 'N', 'R', 'K', 'S', 'P', 'N', 'L', 'S', 'K', 'C', 'G', 'E', 'E', 'L', 'G'] [[0.40785754 0.5921424 ]]\n",
      "['L', 'L', 'E', 'L', 'N', 'F', 'L', 'P', 'T', 'T', 'G', 'T', 'K', 'L', 'T', 'K', 'Q', 'Q', 'L', 'I', 'L', 'A', 'R', 'D', 'I'] [[0.4755947  0.52440536]]\n",
      "['G', 'L', 'A', 'A', 'A', 'A', 'G', 'T', 'R', 'I', 'M', 'G', 'K', 'E', 'I', 'E', 'A', 'E', 'A', 'Q', 'R', 'P', 'L', 'R', 'Q'] [[0.33519873 0.66480124]]\n",
      "['N', 'Q', 'Y', 'V', 'N', 'K', 'K', 'F', 'S', 'N', 'Q', 'Y', 'K', 'A', 'T', 'I', 'G', 'A', 'D', 'F', 'L', 'T', 'K', 'E', 'V'] [[0.47575223 0.52424777]]\n",
      "['Y', 'Q', 'E', 'G', 'L', 'R', 'V', 'M', 'G', 'E', 'V', 'G', 'K', 'T', 'T', 'G', 'I', 'P', 'I', 'H', 'V', 'F', 'G', 'T', 'E'] [[0.1597369 0.8402631]]\n",
      "['A', 'A', 'K', 'A', 'L', 'D', 'D', 'K', 'N', 'C', 'W', 'E', 'K', 'L', 'G', 'E', 'V', 'A', 'L', 'L', 'Q', 'G', 'N', 'H', 'Q'] [[0.39822656 0.6017735 ]]\n",
      "['L', 'E', 'S', 'K', 'K', 'P', 'K', 'G', 'F', 'F', 'G', 'Y', 'K', 'S', 'E', 'I', 'F', 'N', 'E', 'N', 'F', 'G', 'P', 'D', 'F'] [[0.36483267 0.63516736]]\n",
      "['F', 'L', 'S', 'R', 'K', 'T', 'L', 'V', 'E', 'F', 'P', 'Q', 'K', 'V', 'L', 'S', 'P', 'F', 'R', 'K', 'Q', 'G', 'S', 'D', 'S'] [[0.47610208 0.5238979 ]]\n",
      "['N', 'W', 'D', 'A', 'A', 'M', 'E', 'D', 'L', 'T', 'R', 'L', 'K', 'E', 'T', 'I', 'D', 'N', 'N', 'S', 'V', 'S', 'S', 'P', 'L'] [[0.4455759  0.55442417]]\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'M', 'A', 'P', 'I', 'G', 'L', 'K', 'A', 'V', 'V', 'G', 'E', 'K', 'I', 'M', 'H', 'D', 'V', 'I'] [[0.11894645 0.88105357]]\n",
      "['W', 'D', 'L', 'E', 'G', 'K', 'I', 'I', 'V', 'D', 'E', 'L', 'K', 'Q', 'E', 'V', 'I', 'S', 'T', 'S', 'S', 'K', 'A', 'E', 'P'] [[0.49039185 0.5096081 ]]\n",
      "['R', 'R', 'Y', 'Q', 'K', 'S', 'T', 'E', 'L', 'L', 'I', 'R', 'K', 'L', 'P', 'F', 'Q', 'R', 'L', 'V', 'R', 'E', 'I', 'A', 'Q'] [[0.37997776 0.62002224]]\n",
      "['Q', 'G', 'Q', 'S', 'K', 'D', 'M', 'P', 'P', 'R', 'F', 'S', 'K', 'K', 'G', 'Q', 'L', 'N', 'A', 'D', 'E', 'I', 'S', 'L', 'R'] [[0.4994169  0.50058305]]\n",
      "['Q', 'E', 'R', 'E', 'D', 'V', 'L', 'A', 'G', 'M', 'S', 'G', 'K', 'A', 'I', 'K', 'G', 'K', 'V', 'G', 'K', 'P', 'K', 'V', 'K'] [[0.40702954 0.5929705 ]]\n",
      "['G', 'I', 'W', 'R', 'R', 'V', 'A', 'L', 'G', 'H', 'G', 'L', 'K', 'L', 'L', 'T', 'K', 'N', 'G', 'H', 'V', 'Y', 'K', 'Y', 'D'] [[0.4775936  0.52240634]]\n",
      "['S', 'A', 'T', 'P', 'R', 'S', 'K', 'P', 'V', 'C', 'I', 'H', 'K', 'N', 'S', 'E', 'C', 'L', 'K', 'E', 'Q', 'Q', 'K', 'R', 'Y'] [[0.41724074 0.58275926]]\n",
      "['Q', 'D', 'L', 'R', 'R', 'T', 'E', 'S', 'D', 'S', 'G', 'L', 'K', 'K', 'G', 'G', 'N', 'A', 'N', 'L', 'V', 'F', 'M', 'L', 'K'] [[0.45340294 0.54659706]]\n",
      "['C', 'L', 'L', 'I', 'A', 'D', 'Q', 'H', 'C', 'R', 'T', 'R', 'K', 'Y', 'F', 'L', 'C', 'L', 'A', 'S', 'G', 'I', 'P', 'C', 'V'] [[0.3338789  0.66612107]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E', 'G', 'T', 'V', 'K', 'A', 'Y', 'V', 'W', 'D', 'N', 'N', 'K', 'D', 'L', 'A', 'E', 'W', 'L', 'E', 'K', 'Q', 'L', 'T', 'E'] [[0.39408723 0.6059128 ]]\n",
      "['K', 'L', 'E', 'K', 'L', 'D', 'T', 'D', 'L', 'K', 'N', 'Y', 'K', 'G', 'N', 'S', 'I', 'K', 'E', 'S', 'I', 'R', 'R', 'G', 'H'] [[0.48107937 0.51892066]]\n",
      "['A', 'A', 'V', 'F', 'R', 'S', 'M', 'N', 'S', 'A', 'L', 'G', 'K', 'S', 'P', 'W', 'L', 'A', 'G', 'N', 'E', 'L', 'T', 'V', 'A'] [[0.4862997 0.5137003]]\n",
      "['R', 'K', 'F', 'F', 'G', 'D', 'K', 'T', 'I', 'V', 'P', 'W', 'K', 'V', 'F', 'R', 'Q', 'C', 'L', 'H', 'E', 'V', 'H', 'Q', 'I'] [[0.2619514 0.7380487]]\n",
      "['G', 'S', 'V', 'K', 'S', 'F', 'S', 'L', 'G', 'P', 'L', 'R', 'K', 'A', 'V', 'T', 'L', 'N', 'P', 'D', 'N', 'S', 'Y', 'I', 'K'] [[0.46246025 0.5375398 ]]\n",
      "['L', 'K', 'N', 'Y', 'N', 'Q', 'Q', 'K', 'D', 'I', 'E', 'H', 'K', 'E', 'L', 'V', 'Q', 'K', 'L', 'Q', 'H', 'F', 'Q', 'E', 'L'] [[0.39150417 0.60849583]]\n",
      "['A', 'I', 'G', 'P', 'F', 'S', 'G', 'L', 'K', 'E', 'V', 'R', 'K', 'V', 'V', 'L', 'D', 'T', 'M', 'K', 'N', 'I', 'H', 'P', 'I'] [[0.30474526 0.6952547 ]]\n",
      "['G', 'L', 'E', 'L', 'Y', 'K', 'R', 'L', 'K', 'E', 'F', 'L', 'K', 'N', 'Y', 'L', 'T', 'N', 'L', 'L', 'K', 'D', 'G', 'E', 'D'] [[0.49312305 0.5068769 ]]\n",
      "['H', 'V', 'A', 'V', 'T', 'E', 'M', 'A', 'A', 'L', 'F', 'P', 'K', 'K', 'P', 'K', 'S', 'D', 'M', 'V', 'R', 'T', 'S', 'L', 'R'] [[0.45419803 0.545802  ]]\n",
      "['Q', 'K', 'L', 'K', 'Q', 'D', 'G', 'D', 'S', 'F', 'R', 'M', 'K', 'L', 'N', 'T', 'Q', 'E', 'I', 'F', 'D', 'D', 'W', 'A', 'R'] [[0.44017348 0.55982655]]\n",
      "['I', 'T', 'Q', 'A', 'V', 'I', 'F', 'L', 'N', 'T', 'R', 'R', 'K', 'V', 'D', 'W', 'L', 'T', 'E', 'K', 'M', 'H', 'A', 'R', 'D'] [[0.10472324 0.8952767 ]]\n",
      "['T', 'A', 'N', 'Q', 'W', 'D', 'Y', 'K', 'N', 'I', 'I', 'E', 'K', 'L', 'Q', 'D', 'I', 'I', 'T', 'A', 'L', 'E', 'E', 'R', 'L'] [[0.39268658 0.60731345]]\n",
      "['L', 'K', 'E', 'K', 'K', 'E', 'R', 'L', 'T', 'E', 'E', 'L', 'K', 'E', 'Q', 'M', 'K', 'A', 'K', 'R', 'K', 'E', 'A', 'E', 'L'] [[0.33925474 0.66074526]]\n",
      "['K', 'D', 'I', 'K', 'K', 'E', 'K', 'V', 'L', 'L', 'R', 'R', 'K', 'S', 'E', 'L', 'P', 'Q', 'D', 'V', 'Y', 'T', 'I', 'K', 'A'] [[0.48522854 0.5147714 ]]\n",
      "['E', 'L', 'N', 'F', 'H', 'K', 'A', 'Q', 'E', 'I', 'Y', 'E', 'K', 'N', 'L', 'D', 'E', 'K', 'A', 'K', 'E', 'I', 'S', 'N', 'L'] [[0.4802872  0.51971275]]\n",
      "['E', 'D', 'V', 'K', 'G', 'R', 'I', 'Y', 'Q', 'L', 'L', 'A', 'K', 'A', 'S', 'Y', 'K', 'K', 'A', 'I', 'I', 'L', 'T', 'R', 'E'] [[0.42129302 0.578707  ]]\n",
      "['L', 'D', 'S', 'G', 'N', 'E', 'S', 'K', 'E', 'K', 'L', 'L', 'K', 'G', 'E', 'S', 'A', 'L', 'Q', 'R', 'V', 'Q', 'C', 'I', 'P'] [[0.24410005 0.75589997]]\n",
      "['Q', 'L', 'T', 'G', 'L', 'S', 'L', 'L', 'P', 'L', 'S', 'E', 'K', 'A', 'A', 'R', 'A', 'R', 'Q', 'E', 'E', 'L', 'Y', 'S', 'E'] [[0.3324505  0.66754943]]\n",
      "['C', 'F', 'A', 'K', 'T', 'L', 'V', 'E', 'H', 'V', 'G', 'M', 'K', 'N', 'L', 'K', 'S', 'W', 'A', 'S', 'V', 'N', 'R', 'G', 'A'] [[0.3535612 0.6464388]]\n",
      "['A', 'L', 'L', 'G', 'V', 'F', 'C', 'H', 'T', 'D', 'L', 'R', 'K', 'N', 'L', 'T', 'V', 'D', 'E', 'G', 'T', 'M', 'K', 'V', 'E'] [[0.44896543 0.55103457]]\n",
      "['Q', 'L', 'K', 'D', 'L', 'N', 'L', 'L', 'D', 'R', 'C', 'I', 'K', 'E', 'T', 'L', 'R', 'L', 'R', 'P', 'P', 'I', 'M', 'I', 'M'] [[0.3456902 0.6543098]]\n",
      "['F', 'L', 'G', 'G', 'A', 'R', 'I', 'T', 'V', 'L', 'A', 'S', 'K', 'T', 'S', 'Q', 'R', 'Y', 'R', 'I', 'Q', 'S', 'E', 'Q', 'F'] [[0.29877836 0.70122164]]\n",
      "['I', 'N', 'I', 'S', 'L', 'D', 'H', 'K', 'R', 'P', 'L', 'I', 'K', 'V', 'L', 'G', 'I', 'S', 'R', 'D', 'V', 'M', 'Q', 'A', 'R'] [[0.3882252 0.6117748]]\n",
      "['R', 'I', 'E', 'V', 'E', 'N', 'K', 'E', 'V', 'L', 'H', 'G', 'K', 'K', 'W', 'K', 'G', 'L', 'T', 'H', 'N', 'L', 'L', 'K', 'K'] [[0.42733273 0.57266724]]\n",
      "['L', 'P', 'H', 'P', 'R', 'W', 'S', 'A', 'E', 'A', 'S', 'G', 'K', 'P', 'S', 'P', 'S', 'D', 'P', 'G', 'S', 'G', 'T', 'A', 'T'] [[0.46419087 0.53580916]]\n",
      "['A', 'M', 'S', 'T', 'T', 'A', 'K', 'G', 'S', 'K', 'S', 'L', 'K', 'V', 'E', 'L', 'I', 'E', 'D', 'K', 'I', 'D', 'Y', 'T', 'K'] [[0.45919278 0.5408071 ]]\n",
      "['P', 'S', 'P', 'S', 'S', 'A', 'E', 'K', 'V', 'K', 'A', 'N', 'K', 'D', 'V', 'A', 'S', 'P', 'L', 'K', 'E', 'L', 'G', 'L', 'R'] [[0.35884127 0.64115876]]\n",
      "['N', 'N', 'G', 'T', 'V', 'L', 'R', 'A', 'S', 'H', 'G', 'T', 'K', 'M', 'M', 'T', 'P', 'E', 'V', 'L', 'A', 'E', 'A', 'Y', 'G'] [[0.435092   0.56490797]]\n",
      "['P', 'F', 'E', 'A', 'V', 'M', 'R', 'T', 'L', 'C', 'E', 'C', 'K', 'E', 'T', 'A', 'S', 'K', 'T', 'L', 'S', 'R', 'F', 'G', 'I'] [[0.47539893 0.52460104]]\n",
      "['D', 'I', 'V', 'Y', 'M', 'K', 'P', 'H', 'G', 'R', 'L', 'Q', 'K', 'V', 'M', 'N', 'H', 'I', 'T', 'D', 'G', 'P', 'R', 'K', 'D'] [[0.43899438 0.5610056 ]]\n",
      "['V', 'S', 'R', 'T', 'S', 'T', 'A', 'P', 'L', 'D', 'R', 'L', 'K', 'I', 'M', 'M', 'Q', 'V', 'H', 'G', 'S', 'K', 'S', 'D', 'K'] [[0.21638389 0.7836161 ]]\n",
      "['K', 'A', 'R', 'L', 'G', 'R', 'M', 'V', 'V', 'A', 'S', 'D', 'K', 'S', 'G', 'Q', 'P', 'V', 'T', 'A', 'D', 'D', 'L', 'G', 'V'] [[0.41608787 0.5839121 ]]\n",
      "['P', 'P', 'A', 'L', 'R', 'P', 'K', 'P', 'A', 'V', 'L', 'P', 'K', 'T', 'N', 'P', 'T', 'I', 'G', 'P', 'A', 'P', 'P', 'P', 'Q'] [[0.3188672 0.6811328]]\n",
      "['F', 'K', 'H', 'T', 'V', 'D', 'D', 'G', 'L', 'D', 'I', 'R', 'K', 'A', 'A', 'F', 'E', 'C', 'M', 'Y', 'T', 'L', 'L', 'D', 'S'] [[0.38580397 0.61419606]]\n",
      "['D', 'I', 'K', 'G', 'P', 'K', 'L', 'D', 'L', 'K', 'D', 'P', 'K', 'V', 'E', 'M', 'R', 'V', 'P', 'D', 'V', 'E', 'V', 'S', 'L'] [[0.41239774 0.58760226]]\n",
      "['G', 'Y', 'R', 'W', 'E', 'R', 'Q', 'L', 'V', 'F', 'R', 'S', 'K', 'L', 'T', 'M', 'H', 'T', 'A', 'F', 'D', 'R', 'K', 'D', 'N'] [[0.16897193 0.8310281 ]]\n",
      "['F', 'S', 'S', 'M', 'V', 'E', 'S', 'E', 'L', 'H', 'A', 'A', 'K', 'T', 'K', 'Q', 'A', 'W', 'N', 'F', 'L', 'S', 'H', 'L', 'P'] [[0.49472252 0.50527745]]\n",
      "['F', 'P', 'T', 'Q', 'G', 'H', 'D', 'Y', 'V', 'L', 'A', 'E', 'K', 'Q', 'V', 'Q', 'R', 'S', 'R', 'N', 'K', 'Q', 'V', 'R', 'E'] [[0.4724279  0.52757215]]\n",
      "['A', 'V', 'K', 'K', 'L', 'K', 'N', 'S', 'L', 'P', 'L', 'R', 'K', 'E', 'L', 'D', 'R', 'L', 'K', 'D', 'E', 'L', 'S', 'H', 'Q'] [[0.380222 0.619778]]\n",
      "['G', 'E', 'G', 'E', 'V', 'K', 'L', 'N', 'M', 'A', 'I', 'G', 'K', 'G', 'E', 'Q', 'A', 'L', 'R', 'S', 'S', 'N', 'K', 'E', 'G'] [[0.33290687 0.6670931 ]]\n",
      "['D', 'A', 'E', 'S', 'T', 'A', 'V', 'H', 'L', 'E', 'A', 'L', 'K', 'K', 'L', 'A', 'L', 'A', 'L', 'Q', 'E', 'R', 'K', 'Y', 'A'] [[0.3305789 0.6694211]]\n",
      "['I', 'G', 'R', 'L', 'L', 'S', 'E', 'D', 'F', 'V', 'S', 'V', 'K', 'V', 'D', 'R', 'E', 'E', 'R', 'P', 'D', 'V', 'D', 'K', 'V'] [[0.32905975 0.6709402 ]]\n",
      "['G', 'L', 'S', 'A', 'F', 'L', 'S', 'Q', 'E', 'E', 'I', 'N', 'K', 'S', 'L', 'D', 'L', 'A', 'R', 'R', 'A', 'I', 'A', 'D', 'S'] [[0.38978395 0.61021614]]\n",
      "['S', 'P', 'S', 'V', 'I', 'S', 'D', 'L', 'F', 'T', 'D', 'I', 'K', 'K', 'G', 'H', 'V', 'L', 'L', 'D', 'L', 'L', 'E', 'V', 'L'] [[0.4685817 0.5314183]]\n",
      "['L', 'G', 'R', 'L', 'R', 'R', 'A', 'T', 'E', 'Y', 'A', 'P', 'K', 'K', 'R', 'I', 'E', 'P', 'L', 'S', 'P', 'E', 'L', 'V', 'A'] [[0.46383524 0.53616476]]\n",
      "['R', 'T', 'I', 'L', 'P', 'M', 'S', 'R', 'A', 'F', 'R', 'G', 'K', 'H', 'L', 'S', 'F', 'V', 'V', 'R', 'F', 'P', 'N', 'Q', 'G'] [[0.1997282  0.80027187]]\n",
      "['S', 'K', 'V', 'D', 'D', 'K', 'W', 'E', 'K', 'K', 'C', 'Q', 'K', 'I', 'F', 'S', 'F', 'A', 'H', 'Q', 'T', 'I', 'S', 'A', 'L'] [[0.28775802 0.712242  ]]\n",
      "['N', 'T', 'D', 'K', 'N', 'G', 'E', 'E', 'L', 'H', 'G', 'G', 'K', 'R', 'V', 'M', 'E', 'C', 'L', 'K', 'K', 'A', 'L', 'K', 'I'] [[0.4870892 0.5129108]]\n",
      "['H', 'K', 'A', 'A', 'I', 'E', 'V', 'Y', 'N', 'E', 'A', 'A', 'K', 'L', 'N', 'Q', 'K', 'D', 'W', 'E', 'I', 'S', 'H', 'N', 'L'] [[0.2846322  0.71536785]]\n",
      "['A', 'I', 'V', 'D', 'A', 'E', 'W', 'N', 'I', 'L', 'Y', 'D', 'K', 'L', 'E', 'K', 'I', 'H', 'H', 'S', 'G', 'A', 'K', 'V', 'V'] [[0.44556484 0.5544352 ]]\n",
      "['L', 'V', 'K', 'D', 'Q', 'E', 'A', 'L', 'M', 'K', 'S', 'V', 'K', 'L', 'L', 'Q', 'A', 'L', 'A', 'Q', 'Y', 'Q', 'N', 'H', 'L'] [[0.19735527 0.8026447 ]]\n",
      "['S', 'I', 'R', 'R', 'I', 'K', 'D', 'Y', 'D', 'A', 'N', 'F', 'K', 'I', 'K', 'D', 'F', 'P', 'E', 'K', 'A', 'K', 'D', 'I', 'F'] [[0.36709073 0.6329093 ]]\n",
      "['P', 'W', 'V', 'R', 'A', 'K', 'K', 'P', 'E', 'N', 'C', 'E', 'K', 'L', 'V', 'T', 'L', 'L', 'E', 'N', 'Y', 'K', 'E', 'M', 'Y'] [[0.2796541 0.720346 ]]\n",
      "['T', 'I', 'G', 'K', 'L', 'E', 'P', 'S', 'Y', 'V', 'I', 'R', 'K', 'F', 'L', 'D', 'A', 'Q', 'R', 'I', 'H', 'N', 'L', 'T', 'A'] [[0.38068897 0.61931103]]\n",
      "['E', 'C', 'A', 'I', 'Q', 'T', 'C', 'P', 'E', 'L', 'L', 'R', 'K', 'D', 'F', 'E', 'S', 'L', 'F', 'P', 'E', 'V', 'A', 'N', 'G'] [[0.47491896 0.5250811 ]]\n",
      "['G', 'Q', 'G', 'R', 'D', 'N', 'A', 'L', 'T', 'L', 'L', 'I', 'K', 'A', 'V', 'P', 'R', 'K', 'S', 'L', 'K', 'D', 'P', 'N', 'N'] [[0.3152474  0.68475264]]\n",
      "['K', 'G', 'K', 'M', 'W', 'E', 'K', 'A', 'I', 'K', 'L', 'S', 'K', 'E', 'L', 'A', 'E', 'T', 'Y', 'E', 'S', 'K', 'V', 'F', 'D'] [[0.28346053 0.7165395 ]]\n",
      "['V', 'E', 'K', 'F', 'F', 'T', 'E', 'E', 'V', 'D', 'S', 'R', 'K', 'I', 'D', 'Q', 'E', 'G', 'K', 'I', 'P', 'D', 'E', 'T', 'L'] [[0.3985732 0.6014268]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['G', 'S', 'G', 'D', 'T', 'N', 'N', 'F', 'P', 'Y', 'L', 'E', 'K', 'T', 'A', 'K', 'K', 'G', 'R', 'P', 'M', 'V', 'I', 'S', 'S'] [[0.4388657  0.56113434]]\n",
      "['K', 'K', 'R', 'K', 'L', 'P', 'S', 'D', 'V', 'N', 'E', 'G', 'K', 'T', 'V', 'F', 'I', 'R', 'N', 'L', 'S', 'F', 'D', 'S', 'E'] [[0.4242846 0.5757154]]\n",
      "['R', 'T', 'G', 'L', 'G', 'R', 'L', 'G', 'V', 'S', 'L', 'S', 'K', 'G', 'L', 'H', 'H', 'K', 'A', 'V', 'L', 'A', 'V', 'R', 'R'] [[0.47055385 0.5294461 ]]\n",
      "['E', 'Y', 'R', 'G', 'Q', 'A', 'Q', 'A', 'I', 'E', 'F', 'L', 'K', 'E', 'Q', 'I', 'S', 'L', 'A', 'E', 'K', 'K', 'M', 'L', 'D'] [[0.3817962  0.61820376]]\n",
      "['F', 'K', 'R', 'D', 'G', 'S', 'N', 'I', 'I', 'Y', 'T', 'A', 'K', 'I', 'S', 'L', 'R', 'E', 'A', 'L', 'C', 'G', 'C', 'S', 'I'] [[0.49371776 0.50628227]]\n",
      "['S', 'V', 'V', 'R', 'D', 'L', 'G', 'F', 'F', 'G', 'I', 'Y', 'K', 'G', 'A', 'K', 'A', 'C', 'F', 'L', 'R', 'D', 'I', 'P', 'F'] [[0.44260418 0.5573958 ]]\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'M', 'S', 'L', 'K', 'L', 'Q', 'A', 'S', 'N', 'V', 'T', 'N', 'K', 'N', 'D', 'P'] [[0.20612545 0.79387456]]\n",
      "['A', 'G', 'L', 'Q', 'L', 'V', 'V', 'V', 'I', 'L', 'P', 'G', 'K', 'T', 'P', 'V', 'Y', 'A', 'E', 'V', 'K', 'R', 'V', 'G', 'D'] [[0.20248117 0.79751885]]\n",
      "['L', 'K', 'G', 'D', 'L', 'K', 'G', 'V', 'K', 'G', 'D', 'L', 'K', 'K', 'P', 'F', 'D', 'K', 'A', 'W', 'K', 'D', 'Y', 'E', 'T'] [[0.49016318 0.5098368 ]]\n",
      "['I', 'R', 'V', 'A', 'A', 'K', 'W', 'Y', 'N', 'E', 'H', 'L', 'K', 'K', 'M', 'S', 'A', 'D', 'N', 'Q', 'L', 'Q', 'V', 'I', 'F'] [[0.4050391 0.5949609]]\n",
      "['K', 'K', 'Y', 'A', 'T', 'L', 'S', 'L', 'F', 'N', 'T', 'Y', 'K', 'G', 'K', 'S', 'L', 'E', 'T', 'Q', 'K', 'T', 'T', 'V', 'A'] [[0.46583107 0.534169  ]]\n",
      "acc: 69.66666666666667\n",
      "sn: 66.57303370786516\n",
      "sp: 74.18032786885246\n",
      "mcc: 0.40037052280992086\n"
     ]
    }
   ],
   "source": [
    "PATH = './Path/dlmal_h_net.pth'\n",
    "net = torch.load(PATH, map_location=\"cpu\")\n",
    "net.eval()\n",
    "\n",
    "print(r_test_x[0])\n",
    "print([int_to_char[i] for i in r_test_x[0][0]])\n",
    "y = net(torch.from_numpy(np.array([r_test_x[0]])))\n",
    "print(F.softmax(y, dim=1))\n",
    "\n",
    "print(r_test_x[-1])\n",
    "print([int_to_char[i] for i in r_test_x[-1][0]])\n",
    "y = net(torch.from_numpy(np.array([r_test_x[-1]])))\n",
    "print(F.softmax(y, dim=1))\n",
    "\n",
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "for i in range(len(r_test_x)):\n",
    "    y = net(torch.from_numpy(np.array([r_test_x[i]])))\n",
    "    y = F.softmax(y, dim=1)\n",
    "    y = y.detach().cpu().numpy()\n",
    "    if (y[0][0] > y[0][1] and r_test_y[i] == 0):\n",
    "        TN += 1\n",
    "    elif (y[0][0] < y[0][1] and r_test_y[i] == 1):\n",
    "        TP += 1\n",
    "    elif r_test_y[i] == 0:\n",
    "        FN += 1\n",
    "        print([int_to_char[i] for i in r_test_x[i][0]], y)\n",
    "    else:\n",
    "        FP +=1\n",
    "        print([int_to_char[i] for i in r_test_x[i][0]], y)\n",
    "       \n",
    "print(\"acc:\", (TP+TN)/(TP+TN+FP+FN)*100)\n",
    "print(\"sn:\", (TP)/(TP+FN)*100)\n",
    "print(\"sp:\", TN/(TN+FP)*100)\n",
    "print(\"mcc:\", (TP*TN-FP*FN)/((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))**(1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ce7630",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
